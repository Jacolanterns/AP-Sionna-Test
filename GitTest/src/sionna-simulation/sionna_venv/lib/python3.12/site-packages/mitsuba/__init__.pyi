from collections.abc import Callable, Iterator, Sequence
import enum
import types
from typing import Annotated, TypeAlias, Union, overload

import drjit
import drjit.auto
import drjit.auto.ad
import drjit.scalar
from numpy.typing import ArrayLike

from . import (
    detail as detail,
    filesystem as filesystem,
    math as math,
    misc as misc,
    mueller as mueller,
    python as python,
    quad as quad,
    spline as spline,
    warp as warp
)
from .python.util import (
    SceneParameters as SceneParameters,
    cornell_box as cornell_box,
    render as render,
    traverse as traverse,
    variant_context as scoped_set_variant,
    variant_context as variant_context
)




from .python import (
    ad as ad,
    chi2 as chi2,
    math_py as math_py,
    util as util,
    xml as xml
)

_UnpolarizedSpectrumCp: TypeAlias = Union['UnpolarizedSpectrum', 'drjit.auto.ad._FloatCp', 'drjit.scalar._ArrayXfCp', 'drjit.auto._ArrayXfCp', 'drjit.auto.ad._ArrayXf16Cp']

_Spectrum_vtCp: TypeAlias = Union['Spectrum_vt', '_UnpolarizedSpectrumCp', 'drjit.scalar._ArrayXfCp', 'drjit.auto._ArrayXfCp', 'drjit.auto.ad._ArrayXf16Cp']

_SpectrumCp: TypeAlias = Union['Spectrum', '_Spectrum_vtCp', 'drjit.scalar._ArrayXfCp', 'drjit.auto._ArrayXfCp', 'drjit.auto.ad._ArrayXf16Cp']

class Spectrum_vt(drjit.ArrayBase['Spectrum_vt', '_Spectrum_vtCp', UnpolarizedSpectrum, '_UnpolarizedSpectrumCp', UnpolarizedSpectrum, 'Spectrum_vt', drjit.auto.ad.ArrayXb]):
    pass

class Spectrum(drjit.ArrayBase['Spectrum', '_SpectrumCp', Spectrum_vt, '_Spectrum_vtCp', Spectrum_vt, drjit.auto.ad.ArrayXf, drjit.auto.ad.ArrayXb]):
    pass

class UnpolarizedSpectrum(drjit.ArrayBase['UnpolarizedSpectrum', '_UnpolarizedSpectrumCp', drjit.auto.ad.Float, 'drjit.auto.ad._FloatCp', drjit.auto.ad.Float, 'UnpolarizedSpectrum', drjit.auto.ad.ArrayXb]):
    pass

class AdjointIntegrator(Integrator):
    """
    Abstract adjoint integrator that performs Monte Carlo sampling
    starting from the emitters.

    Subclasses of this interface must implement the sample() method, which
    performs recursive Monte Carlo integration starting from an emitter
    and directly accumulates the product of radiance and importance into
    the film. The render() method then repeatedly invokes this estimator
    to compute the rendered image.

    Remark:
        The adjoint integrator does not support renderings with arbitrary
        output variables (AOVs).
    """

    def __init__(self, arg: Properties, /) -> None: ...

    @overload
    def render_forward(self, scene: Scene, params: object, sensor: Sensor, seed: int = 0, spp: int = 0) -> drjit.scalar.TensorXf: ...

    @overload
    def render_forward(self, scene: Scene, params: object, sensor: int = 0, seed: int = 0, spp: int = 0) -> drjit.scalar.TensorXf: ...

    @overload
    def render_backward(self, scene: Scene, params: object, grad_in: drjit.scalar.TensorXf, sensor: Sensor, seed: int = 0, spp: int = 0) -> None: ...

    @overload
    def render_backward(self, scene: Scene, params: object, grad_in: drjit.scalar.TensorXf, sensor: int = 0, seed: int = 0, spp: int = 0) -> None: ...

    def sample(self, scene: Scene, sensor: Sensor, sampler: Sampler, block: ImageBlock, sample_scale: float) -> None:
        """
        Sample the incident importance and splat the product of importance and
        radiance to the film.

        Parameter ``scene``:
            The underlying scene

        Parameter ``sensor``:
            A sensor from which rays should be sampled

        Parameter ``sampler``:
            A source of (pseudo-/quasi-) random numbers

        Parameter ``block``:
            An image block that will be updated during the sampling process

        Parameter ``sample_scale``:
            A scale factor that must be applied to each sample to account for
            the film resolution and number of samples.
        """

class Appender(Object):
    """
    This class defines an abstract destination for logging-relevant
    information
    """

    def __init__(self) -> None: ...

    def append(self, level: LogLevel, text: str) -> None:
        """Append a line of text with the given log level"""

    def log_progress(self, progress: float, name: str, formatted: str, eta: str, ptr: object | None = None) -> None:
        """
        Process a progress message

        Parameter ``progress``:
            Percentage value in [0, 100]

        Parameter ``name``:
            Title of the progress message

        Parameter ``formatted``:
            Formatted string representation of the message

        Parameter ``eta``:
            Estimated time until 100% is reached.

        Parameter ``ptr``:
            Custom pointer payload. This is used to express the context of a
            progress message. When rendering a scene, it will usually contain
            a pointer to the associated ``RenderJob``.
        """

class ArgParser:
    """
    Minimal command line argument parser

    This class provides a minimal cross-platform command line argument
    parser in the spirit of to GNU getopt. Both short and long arguments
    that accept an optional extra value are supported.

    The typical usage is

    ```
    ArgParser p;
    auto arg0 = p.register("--myParameter");
    auto arg1 = p.register("-f", true);
    p.parse(argc, argv);
    if (*arg0)
        std::cout << "Got --myParameter" << std::endl;
    if (*arg1)
        std::cout << "Got -f " << arg1->value() << std::endl;
    ```
    """

    def __init__(self) -> None: ...

    class Arg:
        def __bool__(self) -> bool:
            """Returns whether the argument has been specified"""

        def extra(self) -> bool:
            """Specifies whether the argument takes an extra value"""

        def count(self) -> int:
            """Specifies how many times the argument has been specified"""

        def next(self) -> ArgParser.Arg:
            """
            For arguments that are specified multiple times, advance to the next
            one.
            """

        def as_string(self) -> str:
            """Return the extra argument associated with this argument"""

        def as_int(self) -> int:
            """Return the extra argument associated with this argument"""

        def as_float(self) -> float:
            """Return the extra argument associated with this argument"""

    @overload
    def add(self, prefix: str, extra: bool = False) -> ArgParser.Arg:
        """
        Register a new argument with the given list of prefixes

        Parameter ``prefixes``:
            A list of command prefixes (i.e. {"-f", "--fast"})

        Parameter ``extra``:
            Indicates whether the argument accepts an extra argument value
        """

    @overload
    def add(self, prefixes: Sequence[str], extra: bool = False) -> ArgParser.Arg:
        """
        Register a new argument with the given prefix

        Parameter ``prefix``:
            A single command prefix (i.e. "-f")

        Parameter ``extra``:
            Indicates whether the argument accepts an extra argument value
        """

    def parse(self, arg: Sequence[str], /) -> None:
        """Parse the given set of command line arguments"""

    def executable_name(self) -> str: ...

class AtomicFloat:
    """
    Atomic floating point data type

    The class implements an an atomic floating point data type (which is
    not possible with the existing overloads provided by ``std::atomic``).
    It internally casts floating point values to an integer storage format
    and uses atomic integer compare and exchange operations to perform
    changes.
    """

    def __init__(self, arg: float, /) -> None:
        """Initialize the AtomicFloat with a given floating point value"""

    def __iadd__(self, arg: float, /) -> AtomicFloat:
        """Atomically add a floating point value"""

    def __isub__(self, arg: float, /) -> AtomicFloat:
        """Atomically subtract a floating point value"""

    def __imul__(self, arg: float, /) -> AtomicFloat:
        """Atomically multiply by a floating point value"""

    def __itruediv__(self, arg: float, /) -> AtomicFloat:
        """Atomically divide by a floating point value"""

    def __float__(self) -> float:
        """Convert the AtomicFloat into a normal floating point value"""

class BSDF(Object):
    """
    Bidirectional Scattering Distribution Function (BSDF) interface

    This class provides an abstract interface to all %BSDF plugins in
    Mitsuba. It exposes functions for evaluating and sampling the model,
    and for querying associated probability densities.

    By default, functions in class sample and evaluate the complete BSDF,
    but it also allows to pick and choose individual components of multi-
    lobed BSDFs based on their properties and component indices. This
    selection is specified using a context data structure that is provided
    along with every operation.

    When polarization is enabled, BSDF sampling and evaluation returns 4x4
    Mueller matrices that describe how scattering changes the polarization
    state of incident light. Mueller matrices (e.g. for mirrors) are
    expressed with respect to a reference coordinate system for the
    incident and outgoing direction. The convention used here is that
    these coordinate systems are given by ``coordinate_system(wi)`` and
    ``coordinate_system(wo)``, where 'wi' and 'wo' are the incident and
    outgoing direction in local coordinates.

    See also:
        mitsuba.BSDFContext

    See also:
        mitsuba.BSDFSample3f
    """

    def __init__(self, props: Properties) -> None: ...

    @overload
    def flags(self, index: int, active: bool = True) -> int:
        """Flags for a specific component of this BSDF."""

    @overload
    def flags(self) -> int:
        """Flags for all components combined."""

    def component_count(self, active: bool = True) -> int:
        """Number of components this BSDF is comprised of."""

    def id(self) -> str:
        """Return a string identifier"""

    @property
    def m_flags(self) -> int:
        """Combined flags for all components of this BSDF."""

    @m_flags.setter
    def m_flags(self, arg: int, /) -> None: ...

    @property
    def m_components(self) -> list[int]:
        """Flags for each component of this BSDF."""

    @m_components.setter
    def m_components(self, arg: Sequence[int], /) -> None: ...

    def __repr__(self) -> str:
        """Return a human-readable representation of the BSDF"""

    def sample(self, ctx: BSDFContext, si: SurfaceInteraction3f, sample1: float, sample2: ScalarPoint2f, active: bool = True) -> tuple[BSDFSample3f, ScalarColor3f]:
        """
        Importance sample the BSDF model

        The function returns a sample data structure along with the importance
        weight, which is the value of the BSDF divided by the probability
        density, and multiplied by the cosine foreshortening factor (if needed
        --- it is omitted for degenerate BSDFs like smooth
        mirrors/dielectrics).

        If the supplied context data structures selects subset of components
        in a multi-lobe BRDF model, the sampling is restricted to this subset.
        Depending on the provided transport type, either the BSDF or its
        adjoint version is sampled.

        When sampling a continuous/non-delta component, this method also
        multiplies by the cosine foreshortening factor with respect to the
        sampled direction.

        Parameter ``ctx``:
            A context data structure describing which lobes to sample, and
            whether radiance or importance are being transported.

        Parameter ``si``:
            A surface interaction data structure describing the underlying
            surface position. The incident direction is obtained from the
            field ``si.wi``.

        Parameter ``sample1``:
            A uniformly distributed sample on :math:`[0,1]`. It is used to
            select the BSDF lobe in multi-lobe models.

        Parameter ``sample2``:
            A uniformly distributed sample on :math:`[0,1]^2`. It is used to
            generate the sampled direction.

        Returns:
            A pair (bs, value) consisting of

        bs: Sampling record, indicating the sampled direction, PDF values and
        other information. The contents are undefined if sampling failed.

        value: The BSDF value divided by the probability (multiplied by the
        cosine foreshortening factor when a non-delta component is sampled). A
        zero spectrum indicates that sampling failed.
        """

    def eval(self, ctx: BSDFContext, si: SurfaceInteraction3f, wo: ScalarVector3f, active: bool = True) -> ScalarColor3f:
        """
        Evaluate the BSDF f(wi, wo) or its adjoint version f^{*}(wi, wo) and
        multiply by the cosine foreshortening term.

        Based on the information in the supplied query context ``ctx``, this
        method will either evaluate the entire BSDF or query individual
        components (e.g. the diffuse lobe). Only smooth (i.e. non Dirac-delta)
        components are supported: calling ``eval()`` on a perfectly specular
        material will return zero.

        Note that the incident direction does not need to be explicitly
        specified. It is obtained from the field ``si.wi``.

        Parameter ``ctx``:
            A context data structure describing which lobes to evaluate, and
            whether radiance or importance are being transported.

        Parameter ``si``:
            A surface interaction data structure describing the underlying
            surface position. The incident direction is obtained from the
            field ``si.wi``.

        Parameter ``wo``:
            The outgoing direction
        """

    def pdf(self, ctx: BSDFContext, si: SurfaceInteraction3f, wo: ScalarVector3f, active: bool = True) -> float:
        """
        Compute the probability per unit solid angle of sampling a given
        direction

        This method provides access to the probability density that would
        result when supplying the same BSDF context and surface interaction
        data structures to the sample() method. It correctly handles changes
        in probability when only a subset of the components is chosen for
        sampling (this can be done using the BSDFContext::component and
        BSDFContext::type_mask fields).

        Note that the incident direction does not need to be explicitly
        specified. It is obtained from the field ``si.wi``.

        Parameter ``ctx``:
            A context data structure describing which lobes to evaluate, and
            whether radiance or importance are being transported.

        Parameter ``si``:
            A surface interaction data structure describing the underlying
            surface position. The incident direction is obtained from the
            field ``si.wi``.

        Parameter ``wo``:
            The outgoing direction
        """

    def eval_pdf(self, ctx: BSDFContext, si: SurfaceInteraction3f, wo: ScalarVector3f, active: bool = True) -> tuple[ScalarColor3f, float]:
        """
        Jointly evaluate the BSDF f(wi, wo) and the probability per unit solid
        angle of sampling the given direction. The result from the evaluated
        BSDF is multiplied by the cosine foreshortening term.

        Based on the information in the supplied query context ``ctx``, this
        method will either evaluate the entire BSDF or query individual
        components (e.g. the diffuse lobe). Only smooth (i.e. non Dirac-delta)
        components are supported: calling ``eval()`` on a perfectly specular
        material will return zero.

        This method provides access to the probability density that would
        result when supplying the same BSDF context and surface interaction
        data structures to the sample() method. It correctly handles changes
        in probability when only a subset of the components is chosen for
        sampling (this can be done using the BSDFContext::component and
        BSDFContext::type_mask fields).

        Note that the incident direction does not need to be explicitly
        specified. It is obtained from the field ``si.wi``.

        Parameter ``ctx``:
            A context data structure describing which lobes to evaluate, and
            whether radiance or importance are being transported.

        Parameter ``si``:
            A surface interaction data structure describing the underlying
            surface position. The incident direction is obtained from the
            field ``si.wi``.

        Parameter ``wo``:
            The outgoing direction
        """

    def eval_pdf_sample(self, ctx: BSDFContext, si: SurfaceInteraction3f, wo: ScalarVector3f, sample1: float, sample2: ScalarPoint2f, active: bool = True) -> tuple[ScalarColor3f, float, BSDFSample3f, ScalarColor3f]:
        """
        Jointly evaluate the BSDF f(wi, wo) and the probability per unit solid
        angle of sampling the given direction. The result from the evaluated
        BSDF is multiplied by the cosine foreshortening term.

        Based on the information in the supplied query context ``ctx``, this
        method will either evaluate the entire BSDF or query individual
        components (e.g. the diffuse lobe). Only smooth (i.e. non Dirac-delta)
        components are supported: calling ``eval()`` on a perfectly specular
        material will return zero.

        This method provides access to the probability density that would
        result when supplying the same BSDF context and surface interaction
        data structures to the sample() method. It correctly handles changes
        in probability when only a subset of the components is chosen for
        sampling (this can be done using the BSDFContext::component and
        BSDFContext::type_mask fields).

        Note that the incident direction does not need to be explicitly
        specified. It is obtained from the field ``si.wi``.

        Parameter ``ctx``:
            A context data structure describing which lobes to evaluate, and
            whether radiance or importance are being transported.

        Parameter ``si``:
            A surface interaction data structure describing the underlying
            surface position. The incident direction is obtained from the
            field ``si.wi``.

        Parameter ``wo``:
            The outgoing direction
        """

    def eval_null_transmission(self, si: SurfaceInteraction3f, active: bool = True) -> ScalarColor3f:
        """
        Evaluate un-scattered transmission component of the BSDF

        This method will evaluate the un-scattered transmission
        (BSDFFlags::Null) of the BSDF for light arriving from direction ``w``.
        The default implementation returns zero.

        Parameter ``si``:
            A surface interaction data structure describing the underlying
            surface position. The incident direction is obtained from the
            field ``si.wi``.
        """

    def eval_diffuse_reflectance(self, si: SurfaceInteraction3f, active: bool = True) -> ScalarColor3f:
        """
        Evaluate the diffuse reflectance

        This method approximates the total diffuse reflectance for a given
        direction. For some materials, an exact value can be computed
        inexpensively. When this is not possible, the value is approximated by
        evaluating the BSDF for a normal outgoing direction and returning this
        value multiplied by pi. This is the default behaviour of this method.

        Parameter ``si``:
            A surface interaction data structure describing the underlying
            surface position.
        """

    def has_attribute(self, name: str, active: bool = True) -> bool:
        """
        Returns whether this BSDF contains the specified attribute.

        Parameter ``name``:
            Name of the attribute
        """

    def eval_attribute(self, name: str, si: SurfaceInteraction3f, active: bool = True) -> ScalarColor3f:
        """
        Evaluate a specific BSDF attribute at the given surface interaction.

        BSDF attributes are user-provided fields that provide extra
        information at an intersection. An example of this would be a per-
        vertex or per-face color on a triangle mesh.

        Parameter ``name``:
            Name of the attribute to evaluate

        Parameter ``si``:
            Surface interaction associated with the query

        Returns:
            An unpolarized spectral power distribution or reflectance value
        """

    def eval_attribute_1(self, name: str, si: SurfaceInteraction3f, active: bool = True) -> float:
        """
        Monochromatic evaluation of a BSDF attribute at the given surface
        interaction

        This function differs from eval_attribute() in that it provided raw
        access to scalar intensity/reflectance values without any color
        processing (e.g. spectral upsampling).

        Parameter ``name``:
            Name of the attribute to evaluate

        Parameter ``si``:
            Surface interaction associated with the query

        Returns:
            An scalar intensity or reflectance value
        """

    def eval_attribute_3(self, name: str, si: SurfaceInteraction3f, active: bool = True) -> ScalarColor3f:
        """
        Trichromatic evaluation of a BSDF attribute at the given surface
        interaction

        This function differs from eval_attribute() in that it provided raw
        access to RGB intensity/reflectance values without any additional
        color processing (e.g. RGB-to-spectral upsampling).

        Parameter ``name``:
            Name of the attribute to evaluate

        Parameter ``si``:
            Surface interaction associated with the query

        Returns:
            An trichromatic intensity or reflectance value
        """

    def needs_differentials(self) -> bool:
        """Does the implementation require access to texture-space differentials?"""

class BSDFContext:
    """
    Context data structure for BSDF evaluation and sampling

    BSDF models in Mitsuba can be queried and sampled using a variety of
    different modes -- for instance, a rendering algorithm can indicate
    whether radiance or importance is being transported, and it can also
    restrict evaluation and sampling to a subset of lobes in a a multi-
    lobe BSDF model.

    The BSDFContext data structure encodes these preferences and is
    supplied to most BSDF methods.
    """

    @overload
    def __init__(self, mode: TransportMode = TransportMode.Radiance) -> None:
        """//! @}"""

    @overload
    def __init__(self, mode: TransportMode, type_mask: int, component: int) -> None: ...

    @overload
    def __init__(self, mode: TransportMode, type_mask: int, component: int | None = None) -> None: ...

    def reverse(self) -> None:
        """
        Reverse the direction of light transport in the record

        This updates the transport mode (radiance to importance and vice
        versa).
        """

    def is_enabled(self, type: BSDFFlags, component: int = 0) -> bool:
        """
        Checks whether a given BSDF component type and BSDF component index
        are enabled in this context.
        """

    @property
    def mode(self) -> TransportMode:
        """Transported mode (radiance or importance)"""

    @mode.setter
    def mode(self, arg: TransportMode, /) -> None: ...

    @property
    def type_mask(self) -> int: ...

    @type_mask.setter
    def type_mask(self, arg: int, /) -> None: ...

    @property
    def component(self) -> int:
        """
        Integer value of requested BSDF component index to be
        sampled/evaluated.
        """

    @component.setter
    def component(self, arg: int, /) -> None: ...

    def __repr__(self) -> str: ...

class BSDFFlags(enum.IntEnum):
    """
    This list of flags is used to classify the different types of lobes
    that are implemented in a BSDF instance.

    They are also useful for picking out individual components, e.g., by
    setting combinations in BSDFContext::type_mask.
    """

    Empty = 0
    """No flags set (default value)"""

    Null = 1
    """'null' scattering event, i.e. particles do not undergo deflection"""

    DiffuseReflection = 2
    """Ideally diffuse reflection"""

    DiffuseTransmission = 4
    """Ideally diffuse transmission"""

    GlossyReflection = 8
    """Glossy reflection"""

    GlossyTransmission = 16
    """Glossy transmission"""

    DeltaReflection = 32
    """Reflection into a discrete set of directions"""

    DeltaTransmission = 64
    """Transmission into a discrete set of directions"""

    Anisotropic = 4096
    """The lobe is not invariant to rotation around the normal"""

    SpatiallyVarying = 8192
    """The BSDF depends on the UV coordinates"""

    NonSymmetric = 16384
    """Flags non-symmetry (e.g. transmission in dielectric materials)"""

    FrontSide = 32768
    """Supports interactions on the front-facing side"""

    BackSide = 65536
    """Supports interactions on the back-facing side"""

    Reflection = 170
    """
    Any reflection component (scattering into discrete, 1D, or 2D set of
    directions)
    """

    Transmission = 341
    """
    Any transmission component (scattering into discrete, 1D, or 2D set of
    directions)
    """

    Diffuse = 6
    """Diffuse scattering into a 2D set of directions"""

    Glossy = 24
    """Non-diffuse scattering into a 2D set of directions"""

    Smooth = 30
    """Scattering into a 2D set of directions"""

    Delta = 97
    """Scattering into a discrete set of directions"""

    Delta1D = 384
    """Scattering into a 1D space of directions"""

    All = 511
    """Any kind of scattering"""

class BSDFPtr(drjit.ArrayBase[BSDFPtr, _BSDFPtrCp, BSDF, BSDF, BSDFPtr, BSDFPtr, drjit.auto.ad.Bool]):
    Variant: str = 'llvm_ad_spectral_polarized'

    @overload
    def sample(self, ctx: BSDFContext, si: SurfaceInteraction3f, sample1: drjit.auto.ad.Float, sample2: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[BSDFSample3f, Spectrum]:
        """
        Importance sample the BSDF model

        The function returns a sample data structure along with the importance
        weight, which is the value of the BSDF divided by the probability
        density, and multiplied by the cosine foreshortening factor (if needed
        --- it is omitted for degenerate BSDFs like smooth
        mirrors/dielectrics).

        If the supplied context data structures selects subset of components
        in a multi-lobe BRDF model, the sampling is restricted to this subset.
        Depending on the provided transport type, either the BSDF or its
        adjoint version is sampled.

        When sampling a continuous/non-delta component, this method also
        multiplies by the cosine foreshortening factor with respect to the
        sampled direction.

        Parameter ``ctx``:
            A context data structure describing which lobes to sample, and
            whether radiance or importance are being transported.

        Parameter ``si``:
            A surface interaction data structure describing the underlying
            surface position. The incident direction is obtained from the
            field ``si.wi``.

        Parameter ``sample1``:
            A uniformly distributed sample on :math:`[0,1]`. It is used to
            select the BSDF lobe in multi-lobe models.

        Parameter ``sample2``:
            A uniformly distributed sample on :math:`[0,1]^2`. It is used to
            generate the sampled direction.

        Returns:
            A pair (bs, value) consisting of

        bs: Sampling record, indicating the sampled direction, PDF values and
        other information. The contents are undefined if sampling failed.

        value: The BSDF value divided by the probability (multiplied by the
        cosine foreshortening factor when a non-delta component is sampled). A
        zero spectrum indicates that sampling failed.
        """

    @overload
    def sample(self, ctx: BSDFContext, si: SurfaceInteraction3f, sample1: drjit.auto.ad.Float, sample2: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[BSDFSample3f, Spectrum]: ...

    @overload
    def eval(self, ctx: BSDFContext, si: SurfaceInteraction3f, wo: Vector3f, active: drjit.auto.ad.Bool = True) -> Spectrum:
        """
        Evaluate the BSDF f(wi, wo) or its adjoint version f^{*}(wi, wo) and
        multiply by the cosine foreshortening term.

        Based on the information in the supplied query context ``ctx``, this
        method will either evaluate the entire BSDF or query individual
        components (e.g. the diffuse lobe). Only smooth (i.e. non Dirac-delta)
        components are supported: calling ``eval()`` on a perfectly specular
        material will return zero.

        Note that the incident direction does not need to be explicitly
        specified. It is obtained from the field ``si.wi``.

        Parameter ``ctx``:
            A context data structure describing which lobes to evaluate, and
            whether radiance or importance are being transported.

        Parameter ``si``:
            A surface interaction data structure describing the underlying
            surface position. The incident direction is obtained from the
            field ``si.wi``.

        Parameter ``wo``:
            The outgoing direction
        """

    @overload
    def eval(self, ctx: BSDFContext, si: SurfaceInteraction3f, wo: Vector3f, active: drjit.auto.ad.Bool = True) -> Spectrum: ...

    @overload
    def pdf(self, ctx: BSDFContext, si: SurfaceInteraction3f, wo: Vector3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Compute the probability per unit solid angle of sampling a given
        direction

        This method provides access to the probability density that would
        result when supplying the same BSDF context and surface interaction
        data structures to the sample() method. It correctly handles changes
        in probability when only a subset of the components is chosen for
        sampling (this can be done using the BSDFContext::component and
        BSDFContext::type_mask fields).

        Note that the incident direction does not need to be explicitly
        specified. It is obtained from the field ``si.wi``.

        Parameter ``ctx``:
            A context data structure describing which lobes to evaluate, and
            whether radiance or importance are being transported.

        Parameter ``si``:
            A surface interaction data structure describing the underlying
            surface position. The incident direction is obtained from the
            field ``si.wi``.

        Parameter ``wo``:
            The outgoing direction
        """

    @overload
    def pdf(self, ctx: BSDFContext, si: SurfaceInteraction3f, wo: Vector3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float: ...

    @overload
    def eval_pdf(self, ctx: BSDFContext, si: SurfaceInteraction3f, wo: Vector3f, active: drjit.auto.ad.Bool = True) -> tuple[Spectrum, drjit.auto.ad.Float]:
        """
        Jointly evaluate the BSDF f(wi, wo) and the probability per unit solid
        angle of sampling the given direction. The result from the evaluated
        BSDF is multiplied by the cosine foreshortening term.

        Based on the information in the supplied query context ``ctx``, this
        method will either evaluate the entire BSDF or query individual
        components (e.g. the diffuse lobe). Only smooth (i.e. non Dirac-delta)
        components are supported: calling ``eval()`` on a perfectly specular
        material will return zero.

        This method provides access to the probability density that would
        result when supplying the same BSDF context and surface interaction
        data structures to the sample() method. It correctly handles changes
        in probability when only a subset of the components is chosen for
        sampling (this can be done using the BSDFContext::component and
        BSDFContext::type_mask fields).

        Note that the incident direction does not need to be explicitly
        specified. It is obtained from the field ``si.wi``.

        Parameter ``ctx``:
            A context data structure describing which lobes to evaluate, and
            whether radiance or importance are being transported.

        Parameter ``si``:
            A surface interaction data structure describing the underlying
            surface position. The incident direction is obtained from the
            field ``si.wi``.

        Parameter ``wo``:
            The outgoing direction
        """

    @overload
    def eval_pdf(self, ctx: BSDFContext, si: SurfaceInteraction3f, wo: Vector3f, active: drjit.auto.ad.Bool = True) -> tuple[Spectrum, drjit.auto.ad.Float]: ...

    @overload
    def eval_pdf_sample(self, ctx: BSDFContext, si: SurfaceInteraction3f, wo: Vector3f, sample1: drjit.auto.ad.Float, sample2: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[Spectrum, drjit.auto.ad.Float, BSDFSample3f, Spectrum]:
        """
        Jointly evaluate the BSDF f(wi, wo) and the probability per unit solid
        angle of sampling the given direction. The result from the evaluated
        BSDF is multiplied by the cosine foreshortening term.

        Based on the information in the supplied query context ``ctx``, this
        method will either evaluate the entire BSDF or query individual
        components (e.g. the diffuse lobe). Only smooth (i.e. non Dirac-delta)
        components are supported: calling ``eval()`` on a perfectly specular
        material will return zero.

        This method provides access to the probability density that would
        result when supplying the same BSDF context and surface interaction
        data structures to the sample() method. It correctly handles changes
        in probability when only a subset of the components is chosen for
        sampling (this can be done using the BSDFContext::component and
        BSDFContext::type_mask fields).

        Note that the incident direction does not need to be explicitly
        specified. It is obtained from the field ``si.wi``.

        Parameter ``ctx``:
            A context data structure describing which lobes to evaluate, and
            whether radiance or importance are being transported.

        Parameter ``si``:
            A surface interaction data structure describing the underlying
            surface position. The incident direction is obtained from the
            field ``si.wi``.

        Parameter ``wo``:
            The outgoing direction
        """

    @overload
    def eval_pdf_sample(self, ctx: BSDFContext, si: SurfaceInteraction3f, wo: Vector3f, sample1: drjit.auto.ad.Float, sample2: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[Spectrum, drjit.auto.ad.Float, BSDFSample3f, Spectrum]: ...

    @overload
    def eval_null_transmission(self, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> Spectrum:
        """
        Evaluate un-scattered transmission component of the BSDF

        This method will evaluate the un-scattered transmission
        (BSDFFlags::Null) of the BSDF for light arriving from direction ``w``.
        The default implementation returns zero.

        Parameter ``si``:
            A surface interaction data structure describing the underlying
            surface position. The incident direction is obtained from the
            field ``si.wi``.
        """

    @overload
    def eval_null_transmission(self, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> Spectrum: ...

    @overload
    def eval_diffuse_reflectance(self, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> Spectrum:
        """
        Evaluate the diffuse reflectance

        This method approximates the total diffuse reflectance for a given
        direction. For some materials, an exact value can be computed
        inexpensively. When this is not possible, the value is approximated by
        evaluating the BSDF for a normal outgoing direction and returning this
        value multiplied by pi. This is the default behaviour of this method.

        Parameter ``si``:
            A surface interaction data structure describing the underlying
            surface position.
        """

    @overload
    def eval_diffuse_reflectance(self, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> Spectrum: ...

    @overload
    def has_attribute(self, name: str, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Bool:
        """
        Returns whether this BSDF contains the specified attribute.

        Parameter ``name``:
            Name of the attribute
        """

    @overload
    def has_attribute(self, name: str, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Bool: ...

    @overload
    def eval_attribute(self, name: str, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> UnpolarizedSpectrum:
        """
        Evaluate a specific BSDF attribute at the given surface interaction.

        BSDF attributes are user-provided fields that provide extra
        information at an intersection. An example of this would be a per-
        vertex or per-face color on a triangle mesh.

        Parameter ``name``:
            Name of the attribute to evaluate

        Parameter ``si``:
            Surface interaction associated with the query

        Returns:
            An unpolarized spectral power distribution or reflectance value
        """

    @overload
    def eval_attribute(self, name: str, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> UnpolarizedSpectrum: ...

    @overload
    def eval_attribute_1(self, name: str, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Monochromatic evaluation of a BSDF attribute at the given surface
        interaction

        This function differs from eval_attribute() in that it provided raw
        access to scalar intensity/reflectance values without any color
        processing (e.g. spectral upsampling).

        Parameter ``name``:
            Name of the attribute to evaluate

        Parameter ``si``:
            Surface interaction associated with the query

        Returns:
            An scalar intensity or reflectance value
        """

    @overload
    def eval_attribute_1(self, name: str, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float: ...

    @overload
    def eval_attribute_3(self, name: str, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> Color3f:
        """
        Trichromatic evaluation of a BSDF attribute at the given surface
        interaction

        This function differs from eval_attribute() in that it provided raw
        access to RGB intensity/reflectance values without any additional
        color processing (e.g. RGB-to-spectral upsampling).

        Parameter ``name``:
            Name of the attribute to evaluate

        Parameter ``si``:
            Surface interaction associated with the query

        Returns:
            An trichromatic intensity or reflectance value
        """

    @overload
    def eval_attribute_3(self, name: str, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> Color3f: ...

    @overload
    def flags(self) -> drjit.auto.ad.UInt:
        """Flags for all components combined."""

    @overload
    def flags(self) -> drjit.auto.ad.UInt: ...

    @overload
    def needs_differentials(self) -> drjit.auto.ad.Bool:
        """Does the implementation require access to texture-space differentials?"""

    @overload
    def needs_differentials(self) -> drjit.auto.ad.Bool: ...

class BSDFSample3f:
    """Data structure holding the result of BSDF sampling operations."""

    @overload
    def __init__(self) -> None: ...

    @overload
    def __init__(self, wo: ScalarVector3f) -> None:
        """
        Given a surface interaction and an incident/exitant direction pair
        (wi, wo), create a query record to evaluate the BSDF or its sampling
        density.

        By default, all components will be sampled regardless of what measure
        they live on.

        Parameter ``wo``:
            An outgoing direction in local coordinates. This should be a
            normalized direction vector that points *away* from the scattering
            event.
        """

    @overload
    def __init__(self, bs: BSDFSample3f) -> None:
        """Copy constructor"""

    @property
    def wo(self) -> ScalarVector3f:
        """Normalized outgoing direction in local coordinates"""

    @wo.setter
    def wo(self, arg: ScalarVector3f, /) -> None: ...

    @property
    def pdf(self) -> float:
        """Probability density at the sample"""

    @pdf.setter
    def pdf(self, arg: float, /) -> None: ...

    @property
    def eta(self) -> float:
        """Relative index of refraction in the sampled direction"""

    @eta.setter
    def eta(self, arg: float, /) -> None: ...

    @property
    def sampled_type(self) -> int:
        """Stores the component type that was sampled by BSDF::sample()"""

    @sampled_type.setter
    def sampled_type(self, arg: int, /) -> None: ...

    @property
    def sampled_component(self) -> int:
        """Stores the component index that was sampled by BSDF::sample()"""

    @sampled_component.setter
    def sampled_component(self, arg: int, /) -> None: ...

    def __repr__(self) -> str: ...

    def assign(self, arg: BSDFSample3f, /) -> None: ...

    def __setitem__(self, arg0: bool, arg1: BSDFSample3f, /) -> None: ...

class Bitmap(Object):
    """
    General-purpose bitmap class with read and write support for several
    common file formats.

    This class handles loading of PNG, JPEG, BMP, TGA, as well as OpenEXR
    files, and it supports writing of PNG, JPEG and OpenEXR files.

    PNG and OpenEXR files are optionally annotated with string-valued
    metadata, and the gamma setting can be stored as well. Please see the
    class methods and enumerations for further detail.
    """

    @overload
    def __init__(self, pixel_format: Bitmap.PixelFormat, component_format: Struct.Type, size: ScalarVector2u, channel_count: int = 0, channel_names: Sequence[str] = []) -> None:
        """
        Create a bitmap of the specified type and allocate the necessary
        amount of memory

        Parameter ``pixel_format``:
            Specifies the pixel format (e.g. RGBA or Luminance-only)

        Parameter ``component_format``:
            Specifies how the per-pixel components are encoded (e.g. unsigned
            8 bit integers or 32-bit floating point values). The component
            format struct_type_v<Float> will be translated to the
            corresponding compile-time precision type (Float32 or Float64).

        Parameter ``size``:
            Specifies the horizontal and vertical bitmap size in pixels

        Parameter ``channel_count``:
            Channel count of the image. This parameter is only required when
            ``pixel_format`` = PixelFormat::MultiChannel

        Parameter ``channel_names``:
            Channel names of the image. This parameter is optional, and only
            used when ``pixel_format`` = PixelFormat::MultiChannel

        Parameter ``data``:
            External pointer to the image data. If set to ``nullptr``, the
            implementation will allocate memory itself.
        """

    @overload
    def __init__(self, arg: Bitmap) -> None: ...

    @overload
    def __init__(self, path: str, format: Bitmap.FileFormat = Bitmap.FileFormat.Auto) -> None: ...

    @overload
    def __init__(self, stream: Stream, format: Bitmap.FileFormat = Bitmap.FileFormat.Auto) -> None: ...

    @overload
    def __init__(self, array: Annotated[ArrayLike, dict(order='C', device='cpu')], pixel_format: object | None = None, channel_names: Sequence[str] = []) -> None:
        """
        Initialize a Bitmap from any array that implements the buffer or DLPack protocol.
        """

    @overload
    def __init__(self, array: drjit.ArrayBase, pixel_format: object | None = None, channel_names: Sequence[str] = []) -> None:
        """
        Initialize a Bitmap from any array that implements the buffer or DLPack protocol.
        """

    class PixelFormat(enum.Enum):
        """
        This enumeration lists all pixel format types supported by the Bitmap
        class. This both determines the number of channels, and how they
        should be interpreted
        """

        Y = 0
        """Single-channel luminance bitmap"""

        YA = 1
        """Two-channel luminance + alpha bitmap"""

        RGB = 2
        """RGB bitmap"""

        RGBA = 3
        """RGB bitmap + alpha channel"""

        RGBW = 3
        """RGB bitmap + weight (used by ImageBlock)"""

        RGBAW = 5
        """RGB bitmap + alpha channel + weight (used by ImageBlock)"""

        XYZ = 6
        """XYZ tristimulus bitmap"""

        XYZA = 7
        """XYZ tristimulus + alpha channel"""

        MultiChannel = 8
        """Arbitrary multi-channel bitmap without a fixed interpretation"""

    class FileFormat(enum.Enum):
        """Supported image file formats"""

        PNG = 0
        """
        Portable network graphics

        The following is supported:

        * Loading and saving of 8/16-bit per component bitmaps for all pixel
        formats (Y, YA, RGB, RGBA)

        * Loading and saving of 1-bit per component mask bitmaps

        * Loading and saving of string-valued metadata fields
        """

        OpenEXR = 1
        """
        OpenEXR high dynamic range file format developed by Industrial Light &
        Magic (ILM)

        The following is supported:

        * Loading and saving of Float16 / Float32/ UInt32 bitmaps with all
        supported RGB/Luminance/Alpha combinations

        * Loading and saving of spectral bitmaps

        * Loading and saving of XYZ tristimulus bitmaps

        * Loading and saving of string-valued metadata fields

        The following is *not* supported:

        * Saving of tiled images, tile-based read access

        * Display windows that are different than the data window

        * Loading of spectrum-valued bitmaps
        """

        RGBE = 2
        """
        RGBE image format by Greg Ward

        The following is supported

        * Loading and saving of Float32 - based RGB bitmaps
        """

        PFM = 3
        """
        PFM (Portable Float Map) image format

        The following is supported

        * Loading and saving of Float32 - based Luminance or RGB bitmaps
        """

        PPM = 4
        """
        PPM (Portable Pixel Map) image format

        The following is supported

        * Loading and saving of UInt8 and UInt16 - based RGB bitmaps
        """

        JPEG = 5
        """
        Joint Photographic Experts Group file format

        The following is supported:

        * Loading and saving of 8 bit per component RGB and luminance bitmaps
        """

        TGA = 6
        """
        Truevision Advanced Raster Graphics Array file format

        The following is supported:

        * Loading of uncompressed 8-bit RGB/RGBA files
        """

        BMP = 7
        """
        Windows Bitmap file format

        The following is supported:

        * Loading of uncompressed 8-bit luminance and RGBA bitmaps
        """

        Unknown = 8
        """Unknown file format"""

        Auto = 9
        """
        Automatically detect the file format

        Note: this flag only applies when loading a file. In this case, the
        source stream must support the ``seek()`` operation.
        """

    class AlphaTransform(enum.Enum):
        """Type of alpha transformation"""

        Empty = 0
        """No transformation (default)"""

        Premultiply = 1
        """No transformation (default)"""

        Unpremultiply = 2
        """No transformation (default)"""

    def pixel_format(self) -> Bitmap.PixelFormat:
        """Return the pixel format of this bitmap"""

    def component_format(self) -> Struct.Type:
        """Return the component format of this bitmap"""

    def size(self) -> ScalarVector2u:
        """Return the bitmap dimensions in pixels"""

    def width(self) -> int:
        """Return the bitmap's width in pixels"""

    def height(self) -> int:
        """Return the bitmap's height in pixels"""

    def pixel_count(self) -> int:
        """Return the total number of pixels"""

    def channel_count(self) -> int:
        """Return the number of channels used by this bitmap"""

    def has_alpha(self) -> bool:
        """Return whether this image has an alpha channel"""

    def bytes_per_pixel(self) -> int:
        """Return the number bytes of storage used per pixel"""

    def buffer_size(self) -> int:
        """Return the bitmap size in bytes (excluding metadata)"""

    def srgb_gamma(self) -> bool:
        """Return whether the bitmap uses an sRGB gamma encoding"""

    def set_srgb_gamma(self, arg: bool, /) -> None:
        """Specify whether the bitmap uses an sRGB gamma encoding"""

    def premultiplied_alpha(self) -> bool:
        """Return whether the bitmap uses premultiplied alpha"""

    def set_premultiplied_alpha(self, arg: bool, /) -> None:
        """Specify whether the bitmap uses premultiplied alpha"""

    def clear(self) -> None:
        """Clear the bitmap to zero"""

    def metadata(self) -> Properties:
        """Return a Properties object containing the image metadata"""

    @overload
    def resample(self, target: Bitmap, rfilter: BitmapReconstructionFilter | None = None, bc: tuple[FilterBoundaryCondition, FilterBoundaryCondition] = ..., clamp: tuple[float, float] = (float('-inf'), float('inf')), temp: Bitmap | None = None) -> None:
        """
        Up- or down-sample this image to a different resolution

        Uses the provided reconstruction filter and accounts for the requested
        horizontal and vertical boundary conditions when looking up data
        outside of the input domain.

        A minimum and maximum image value can be specified to prevent to
        prevent out-of-range values that are created by the resampling
        process.

        The optional ``temp`` parameter can be used to pass an image of
        resolution ``Vector2u(target->width(), this->height())`` to avoid
        intermediate memory allocations.

        Parameter ``target``:
            Pre-allocated bitmap of the desired target resolution

        Parameter ``rfilter``:
            A separable image reconstruction filter (default: 2-lobe Lanczos
            filter)

        Parameter ``bch``:
            Horizontal and vertical boundary conditions (default: clamp)

        Parameter ``clamp``:
            Filtered image pixels will be clamped to the following range.
            Default: -infinity..infinity (i.e. no clamping is used)

        Parameter ``temp``:
            Optional: image for intermediate computations
        """

    @overload
    def resample(self, res: ScalarVector2u, rfilter: BitmapReconstructionFilter | None = None, bc: tuple[FilterBoundaryCondition, FilterBoundaryCondition] = ..., clamp: tuple[float, float] = (float('-inf'), float('inf'))) -> Bitmap:
        """
        Up- or down-sample this image to a different resolution

        This version is similar to the above resample() function -- the main
        difference is that it does not work with preallocated bitmaps and
        takes the desired output resolution as first argument.

        Uses the provided reconstruction filter and accounts for the requested
        horizontal and vertical boundary conditions when looking up data
        outside of the input domain.

        A minimum and maximum image value can be specified to prevent to
        prevent out-of-range values that are created by the resampling
        process.

        Parameter ``res``:
            Desired output resolution

        Parameter ``rfilter``:
            A separable image reconstruction filter (default: 2-lobe Lanczos
            filter)

        Parameter ``bch``:
            Horizontal and vertical boundary conditions (default: clamp)

        Parameter ``clamp``:
            Filtered image pixels will be clamped to the following range.
            Default: -infinity..infinity (i.e. no clamping is used)
        """

    @overload
    def convert(self, pixel_format: object | None = None, component_format: object | None = None, srgb_gamma: object | None = None, alpha_transform: Bitmap.AlphaTransform = Bitmap.AlphaTransform.Empty) -> Bitmap:
        """
        Convert the bitmap into another pixel and/or component format

        This helper function can be used to efficiently convert a bitmap
        between different underlying representations. For instance, it can
        translate a uint8 sRGB bitmap to a linear float32 XYZ bitmap based on
        half-, single- or double-precision floating point-backed storage.

        This function roughly does the following:

        * For each pixel and channel, it converts the associated value into a
        normalized linear-space form (any gamma of the source bitmap is
        removed)

        * gamma correction (sRGB ramp) is applied if ``srgb_gamma`` is
        ``True``

        * The corrected value is clamped against the representable range of
        the desired component format.

        * The clamped gamma-corrected value is then written to the new bitmap

        If the pixel formats differ, this function will also perform basic
        conversions (e.g. spectrum to rgb, luminance to uniform spectrum
        values, etc.)

        Note that the alpha channel is assumed to be linear in both the source
        and target bitmap, hence it won't be affected by any gamma-related
        transformations.

        Remark:
            This ``convert()`` variant usually returns a new bitmap instance.
            When the conversion would just involve copying the original
            bitmap, the function becomes a no-op and returns the current
            instance.

        pixel_format Specifies the desired pixel format

        component_format Specifies the desired component format

        srgb_gamma Specifies whether a sRGB gamma ramp should be applied to
        the output values.
        """

    @overload
    def convert(self, target: Bitmap) -> None: ...

    @overload
    def accumulate(self, bitmap: Bitmap, source_offset: ScalarPoint2i, target_offset: ScalarPoint2i, size: ScalarVector2i) -> None:
        """
        Accumulate the contents of another bitmap into the region with the
        specified offset

        Out-of-bounds regions are safely ignored. It is assumed that ``bitmap
        != this``.

        Remark:
            This function throws an exception when the bitmaps use different
            component formats or channels.
        """

    @overload
    def accumulate(self, bitmap: Bitmap, target_offset: ScalarPoint2i) -> None:
        """
        Accumulate the contents of another bitmap into the region with the
        specified offset

        This convenience function calls the main ``accumulate()``
        implementation with ``size`` set to ``bitmap->size()`` and
        ``source_offset`` set to zero. Out-of-bounds regions are ignored. It
        is assumed that ``bitmap != this``.

        Remark:
            This function throws an exception when the bitmaps use different
            component formats or channels.
        """

    @overload
    def accumulate(self, bitmap: Bitmap) -> None:
        """
        Accumulate the contents of another bitmap into the region with the
        specified offset

        This convenience function calls the main ``accumulate()``
        implementation with ``size`` set to ``bitmap->size()`` and
        ``source_offset`` and ``target_offset`` set to zero. Out-of-bounds
        regions are ignored. It is assumed that ``bitmap != this``.

        Remark:
            This function throws an exception when the bitmaps use different
            component formats or channels.
        """

    def vflip(self) -> None:
        """Vertically flip the bitmap"""

    UInt8: Struct.Type = Struct.Type.UInt8

    Int8: Struct.Type = Struct.Type.Int8

    UInt16: Struct.Type = Struct.Type.UInt16

    Int16: Struct.Type = Struct.Type.Int16

    UInt32: Struct.Type = Struct.Type.UInt32

    Int32: Struct.Type = Struct.Type.Int32

    UInt64: Struct.Type = Struct.Type.UInt64

    Int64: Struct.Type = Struct.Type.Int64

    Float16: Struct.Type = Struct.Type.Float16

    Float32: Struct.Type = Struct.Type.Float32

    Float64: Struct.Type = Struct.Type.Float64

    Invalid: Struct.Type = Struct.Type.Invalid

    @overload
    def write(self, stream: Stream, format: Bitmap.FileFormat = Bitmap.FileFormat.Auto, quality: int = -1) -> None:
        """
        Write an encoded form of the bitmap to a stream using the specified
        file format

        Parameter ``stream``:
            Target stream that will receive the encoded output

        Parameter ``format``:
            Target file format (OpenEXR, PNG, etc.) Detected from the filename
            by default.

        Parameter ``quality``:
            Depending on the file format, this parameter takes on a slightly
            different meaning:

        * PNG images: Controls how much libpng will attempt to compress the
        output (with 1 being the lowest and 9 denoting the highest
        compression). The default argument uses the compression level 5.

        * JPEG images: denotes the desired quality (between 0 and 100). The
        default argument (-1) uses the highest quality (100).

        * OpenEXR images: denotes the quality level of the DWAB compressor,
        with higher values corresponding to a lower quality. A value of 45 is
        recommended as the default for lossy compression. The default argument
        (-1) causes the implementation to switch to the lossless PIZ
        compressor.
        """

    @overload
    def write(self, path: str, format: Bitmap.FileFormat = Bitmap.FileFormat.Auto, quality: int = -1) -> None:
        """
        Write an encoded form of the bitmap to a file using the specified file
        format

        Parameter ``path``:
            Target file path on disk

        Parameter ``format``:
            Target file format (FileFormat::OpenEXR, FileFormat::PNG, etc.)
            Detected from the filename by default.

        Parameter ``quality``:
            Depending on the file format, this parameter takes on a slightly
            different meaning:

        * PNG images: Controls how much libpng will attempt to compress the
        output (with 1 being the lowest and 9 denoting the highest
        compression). The default argument uses the compression level 5.

        * JPEG images: denotes the desired quality (between 0 and 100). The
        default argument (-1) uses the highest quality (100).

        * OpenEXR images: denotes the quality level of the DWAB compressor,
        with higher values corresponding to a lower quality. A value of 45 is
        recommended as the default for lossy compression. The default argument
        (-1) causes the implementation to switch to the lossless PIZ
        compressor.
        """

    def write_async(self, path: str, format: Bitmap.FileFormat = Bitmap.FileFormat.Auto, quality: int = -1) -> None:
        """
        Equivalent to write(), but executes asynchronously on a different
        thread
        """

    def split(self) -> list[tuple[str, Bitmap]]:
        """
        Split an multi-channel image buffer (e.g. from an OpenEXR image with
        lots of AOVs) into its constituent layers
        """

    @staticmethod
    def detect_file_format(arg: Stream, /) -> Bitmap.FileFormat:
        """Attempt to detect the bitmap file format in a given stream"""

    def __dlpack__(self, stream: object | None = None) -> ArrayLike:
        """Interface for the DLPack protocol."""

    def __dlpack_device__(self) -> tuple:
        """Interface for the DLPack protocol."""

    @property
    def __array_interface__(self) -> object: ...

class BitmapReconstructionFilter(Object):
    """
    Generic interface to separable image reconstruction filters

    When resampling bitmaps or adding samples to a rendering in progress,
    Mitsuba first convolves them with a image reconstruction filter.
    Various kinds are implemented as subclasses of this interface.

    Because image filters are generally too expensive to evaluate for each
    sample, the implementation of this class internally precomputes an
    discrete representation, whose resolution given by
    MI_FILTER_RESOLUTION.
    """

    def border_size(self) -> int:
        """Return the block border size required when rendering with this filter"""

    def is_box_filter(self) -> bool:
        """Check whether this is a box filter?"""

    def radius(self) -> float:
        """Return the filter's width"""

    def eval(self, x: float, active: bool = True) -> float:
        """Evaluate the filter function"""

    def eval_discretized(self, x: float, active: bool = True) -> float:
        """
        Evaluate a discretized version of the filter (generally faster than
        'eval')
        """

class BoundingBox2f:
    """
    Generic n-dimensional bounding box data structure

    Maintains a minimum and maximum position along each dimension and
    provides various convenience functions for querying and modifying
    them.

    This class is parameterized by the underlying point data structure,
    which permits the use of different scalar types and dimensionalities,
    e.g.

    ```
    BoundingBox<Point3i> integer_bbox(Point3i(0, 1, 3), Point3i(4, 5, 6));
    BoundingBox<Point2d> double_bbox(Point2d(0.0, 1.0), Point2d(4.0, 5.0));
    ```

    Template parameter ``T``:
        The underlying point data type (e.g. ``Point2d``)
    """

    @overload
    def __init__(self) -> None:
        r"""
        Create a new invalid bounding box

        Initializes the components of the minimum and maximum position to
        :math:`\infty` and :math:`-\infty`, respectively.
        """

    @overload
    def __init__(self, p: Point2f) -> None:
        """Create a collapsed bounding box from a single point"""

    @overload
    def __init__(self, min: Point2f, max: Point2f) -> None:
        """Create a bounding box from two positions"""

    @overload
    def __init__(self, arg: BoundingBox2f) -> None:
        """Copy constructor"""

    def valid(self) -> drjit.auto.ad.Bool:
        """
        Check whether this is a valid bounding box

        A bounding box ``bbox`` is considered to be valid when

        ```
        bbox.min[i] <= bbox.max[i]
        ```

        holds for each component ``i``.
        """

    def collapsed(self) -> drjit.auto.ad.Bool:
        """
        Check whether this bounding box has collapsed to a point, line, or
        plane
        """

    def major_axis(self) -> drjit.auto.ad.UInt:
        """Return the dimension index with the index associated side length"""

    def minor_axis(self) -> drjit.auto.ad.UInt:
        """Return the dimension index with the shortest associated side length"""

    def center(self) -> Point2f:
        """Return the center point"""

    def extents(self) -> Vector2f:
        """
        Calculate the bounding box extents

        Returns:
            ``max - min``
        """

    def corner(self, arg: int, /) -> Point2f:
        """Return the position of a bounding box corner"""

    def volume(self) -> drjit.auto.ad.Float:
        """Calculate the n-dimensional volume of the bounding box"""

    def surface_area(self) -> drjit.auto.ad.Float:
        """Calculate the 2-dimensional surface area of a 3D bounding box"""

    @overload
    def contains(self, p: Point2f, strict: bool = False) -> drjit.auto.ad.Bool:
        """
        Check whether a point lies *on* or *inside* the bounding box

        Parameter ``p``:
            The point to be tested

        Template parameter ``Strict``:
            Set this parameter to ``True`` if the bounding box boundary should
            be excluded in the test

        Remark:
            In the Python bindings, the 'Strict' argument is a normal function
            parameter with default value ``False``.
        """

    @overload
    def contains(self, bbox: BoundingBox2f, strict: bool = False) -> drjit.auto.ad.Bool:
        r"""
        Check whether a specified bounding box lies *on* or *within* the
        current bounding box

        Note that by definition, an 'invalid' bounding box (where
        min=:math:`\infty` and max=:math:`-\infty`) does not cover any space.
        Hence, this method will always return *true* when given such an
        argument.

        Template parameter ``Strict``:
            Set this parameter to ``True`` if the bounding box boundary should
            be excluded in the test

        Remark:
            In the Python bindings, the 'Strict' argument is a normal function
            parameter with default value ``False``.
        """

    def overlaps(self, bbox: BoundingBox2f, strict: bool = False) -> drjit.auto.ad.Bool:
        """
        Check two axis-aligned bounding boxes for possible overlap.

        Parameter ``Strict``:
            Set this parameter to ``True`` if the bounding box boundary should
            be excluded in the test

        Remark:
            In the Python bindings, the 'Strict' argument is a normal function
            parameter with default value ``False``.

        Returns:
            ``True`` If overlap was detected.
        """

    @overload
    def squared_distance(self, arg: Point2f, /) -> drjit.auto.ad.Float:
        """
        Calculate the shortest squared distance between the axis-aligned
        bounding box and the point ``p``.
        """

    @overload
    def squared_distance(self, arg: BoundingBox2f, /) -> drjit.auto.ad.Float:
        """
        Calculate the shortest squared distance between the axis-aligned
        bounding box and ``bbox``.
        """

    @overload
    def distance(self, arg: Point2f, /) -> drjit.auto.ad.Float:
        """
        Calculate the shortest distance between the axis-aligned bounding box
        and the point ``p``.
        """

    @overload
    def distance(self, arg: BoundingBox2f, /) -> drjit.auto.ad.Float:
        """
        Calculate the shortest distance between the axis-aligned bounding box
        and ``bbox``.
        """

    def reset(self) -> None:
        r"""
        Mark the bounding box as invalid.

        This operation sets the components of the minimum and maximum position
        to :math:`\infty` and :math:`-\infty`, respectively.
        """

    def clip(self, arg: BoundingBox2f, /) -> None:
        """Clip this bounding box to another bounding box"""

    @overload
    def expand(self, arg: Point2f, /) -> None:
        """Expand the bounding box to contain another point"""

    @overload
    def expand(self, arg: BoundingBox2f, /) -> None:
        """Expand the bounding box to contain another bounding box"""

    @staticmethod
    def merge(arg0: BoundingBox2f, arg1: BoundingBox2f, /) -> BoundingBox2f:
        """Merge two bounding boxes"""

    @property
    def min(self) -> Point2f: ...

    @min.setter
    def min(self, arg: Point2f, /) -> None: ...

    @property
    def max(self) -> Point2f: ...

    @max.setter
    def max(self, arg: Point2f, /) -> None: ...

    def __repr__(self) -> str: ...

class BoundingBox3f:
    """
    Generic n-dimensional bounding box data structure

    Maintains a minimum and maximum position along each dimension and
    provides various convenience functions for querying and modifying
    them.

    This class is parameterized by the underlying point data structure,
    which permits the use of different scalar types and dimensionalities,
    e.g.

    ```
    BoundingBox<Point3i> integer_bbox(Point3i(0, 1, 3), Point3i(4, 5, 6));
    BoundingBox<Point2d> double_bbox(Point2d(0.0, 1.0), Point2d(4.0, 5.0));
    ```

    Template parameter ``T``:
        The underlying point data type (e.g. ``Point2d``)
    """

    @overload
    def __init__(self) -> None:
        r"""
        Create a new invalid bounding box

        Initializes the components of the minimum and maximum position to
        :math:`\infty` and :math:`-\infty`, respectively.
        """

    @overload
    def __init__(self, p: Point3f) -> None:
        """Create a collapsed bounding box from a single point"""

    @overload
    def __init__(self, min: Point3f, max: Point3f) -> None:
        """Create a bounding box from two positions"""

    @overload
    def __init__(self, arg: BoundingBox3f) -> None:
        """Copy constructor"""

    def valid(self) -> drjit.auto.ad.Bool:
        """
        Check whether this is a valid bounding box

        A bounding box ``bbox`` is considered to be valid when

        ```
        bbox.min[i] <= bbox.max[i]
        ```

        holds for each component ``i``.
        """

    def collapsed(self) -> drjit.auto.ad.Bool:
        """
        Check whether this bounding box has collapsed to a point, line, or
        plane
        """

    def major_axis(self) -> drjit.auto.ad.UInt:
        """Return the dimension index with the index associated side length"""

    def minor_axis(self) -> drjit.auto.ad.UInt:
        """Return the dimension index with the shortest associated side length"""

    def center(self) -> Point3f:
        """Return the center point"""

    def extents(self) -> Vector3f:
        """
        Calculate the bounding box extents

        Returns:
            ``max - min``
        """

    def corner(self, arg: int, /) -> Point3f:
        """Return the position of a bounding box corner"""

    def volume(self) -> drjit.auto.ad.Float:
        """Calculate the n-dimensional volume of the bounding box"""

    def surface_area(self) -> drjit.auto.ad.Float:
        """Calculate the 2-dimensional surface area of a 3D bounding box"""

    @overload
    def contains(self, p: Point3f, strict: bool = False) -> drjit.auto.ad.Bool:
        """
        Check whether a point lies *on* or *inside* the bounding box

        Parameter ``p``:
            The point to be tested

        Template parameter ``Strict``:
            Set this parameter to ``True`` if the bounding box boundary should
            be excluded in the test

        Remark:
            In the Python bindings, the 'Strict' argument is a normal function
            parameter with default value ``False``.
        """

    @overload
    def contains(self, bbox: BoundingBox3f, strict: bool = False) -> drjit.auto.ad.Bool:
        r"""
        Check whether a specified bounding box lies *on* or *within* the
        current bounding box

        Note that by definition, an 'invalid' bounding box (where
        min=:math:`\infty` and max=:math:`-\infty`) does not cover any space.
        Hence, this method will always return *true* when given such an
        argument.

        Template parameter ``Strict``:
            Set this parameter to ``True`` if the bounding box boundary should
            be excluded in the test

        Remark:
            In the Python bindings, the 'Strict' argument is a normal function
            parameter with default value ``False``.
        """

    def overlaps(self, bbox: BoundingBox3f, strict: bool = False) -> drjit.auto.ad.Bool:
        """
        Check two axis-aligned bounding boxes for possible overlap.

        Parameter ``Strict``:
            Set this parameter to ``True`` if the bounding box boundary should
            be excluded in the test

        Remark:
            In the Python bindings, the 'Strict' argument is a normal function
            parameter with default value ``False``.

        Returns:
            ``True`` If overlap was detected.
        """

    @overload
    def squared_distance(self, arg: Point3f, /) -> drjit.auto.ad.Float:
        """
        Calculate the shortest squared distance between the axis-aligned
        bounding box and the point ``p``.
        """

    @overload
    def squared_distance(self, arg: BoundingBox3f, /) -> drjit.auto.ad.Float:
        """
        Calculate the shortest squared distance between the axis-aligned
        bounding box and ``bbox``.
        """

    @overload
    def distance(self, arg: Point3f, /) -> drjit.auto.ad.Float:
        """
        Calculate the shortest distance between the axis-aligned bounding box
        and the point ``p``.
        """

    @overload
    def distance(self, arg: BoundingBox3f, /) -> drjit.auto.ad.Float:
        """
        Calculate the shortest distance between the axis-aligned bounding box
        and ``bbox``.
        """

    def reset(self) -> None:
        r"""
        Mark the bounding box as invalid.

        This operation sets the components of the minimum and maximum position
        to :math:`\infty` and :math:`-\infty`, respectively.
        """

    def clip(self, arg: BoundingBox3f, /) -> None:
        """Clip this bounding box to another bounding box"""

    @overload
    def expand(self, arg: Point3f, /) -> None:
        """Expand the bounding box to contain another point"""

    @overload
    def expand(self, arg: BoundingBox3f, /) -> None:
        """Expand the bounding box to contain another bounding box"""

    @staticmethod
    def merge(arg0: BoundingBox3f, arg1: BoundingBox3f, /) -> BoundingBox3f:
        """Merge two bounding boxes"""

    @property
    def min(self) -> Point3f: ...

    @min.setter
    def min(self, arg: Point3f, /) -> None: ...

    @property
    def max(self) -> Point3f: ...

    @max.setter
    def max(self, arg: Point3f, /) -> None: ...

    def __repr__(self) -> str: ...

    def ray_intersect(self, ray: Ray3f) -> tuple[drjit.auto.ad.Bool, drjit.auto.ad.Float, drjit.auto.ad.Float]:
        """
        Check if a ray intersects a bounding box

        Note that this function ignores the ``maxt`` value associated with the
        ray.
        """

    def bounding_sphere(self) -> BoundingSphere3f:
        """Create a bounding sphere, which contains the axis-aligned box"""

class BoundingSphere3f:
    """Generic n-dimensional bounding sphere data structure"""

    @overload
    def __init__(self) -> None:
        """Construct bounding sphere(s) at the origin having radius zero"""

    @overload
    def __init__(self, arg0: Point3f, arg1: drjit.auto.ad.Float, /) -> None:
        """
        Create bounding sphere(s) from given center point(s) with given
        size(s)
        """

    @overload
    def __init__(self, arg: BoundingSphere3f) -> None: ...

    def empty(self) -> drjit.auto.ad.Bool:
        """Return whether this bounding sphere has a radius of zero or less."""

    def contains(self, p: Point3f, strict: bool = False) -> drjit.auto.ad.Bool:
        """
        Check whether a point lies *on* or *inside* the bounding sphere

        Parameter ``p``:
            The point to be tested

        Template parameter ``Strict``:
            Set this parameter to ``True`` if the bounding sphere boundary
            should be excluded in the test

        Remark:
            In the Python bindings, the 'Strict' argument is a normal function
            parameter with default value ``False``.
        """

    def expand(self, arg: Point3f, /) -> None:
        """Expand the bounding sphere radius to contain another point."""

    def ray_intersect(self, ray: Ray3f) -> tuple[drjit.auto.ad.Bool, drjit.auto.ad.Float, drjit.auto.ad.Float]:
        """Check if a ray intersects a bounding box"""

    @property
    def center(self) -> Point3f: ...

    @center.setter
    def center(self, arg: Point3f, /) -> None: ...

    @property
    def radius(self) -> drjit.auto.ad.Float: ...

    @radius.setter
    def radius(self, arg: drjit.auto.ad.Float, /) -> None: ...

    def __repr__(self) -> str: ...

class Class:
    """
    Stores meta-information about Object instances.

    This class provides a thin layer of RTTI (run-time type information),
    which is useful for doing things like:

    * Checking if an object derives from a certain class

    * Determining the parent of a class at runtime

    * Instantiating a class by name

    * Unserializing a class from a binary data stream

    See also:
        ref, Object
    """

    def name(self) -> str:
        """Return the name of the class"""

    def variant(self) -> str:
        """Return the variant of the class"""

    def alias(self) -> str:
        """Return the scene description-specific alias, if applicable"""

    def parent(self) -> Class:
        """
        Return the Class object associated with the parent class of nullptr if
        it does not have one.
        """

class Color0d(drjit.ArrayBase[Color0d, _Color0dCp, drjit.auto.ad.Float64, drjit.auto.ad._Float64Cp, drjit.auto.ad.Float64, Color0d, drjit.auto.ad.Array0b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Color0f(drjit.ArrayBase[Color0f, _Color0fCp, drjit.auto.ad.Float, drjit.auto.ad._FloatCp, drjit.auto.ad.Float, Color0f, drjit.auto.ad.Array0b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Color1d(drjit.ArrayBase[Color1d, _Color1dCp, drjit.auto.ad.Float64, drjit.auto.ad._Float64Cp, drjit.auto.ad.Float64, Color1d, drjit.auto.ad.Array1b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Color1f(drjit.ArrayBase[Color1f, _Color1fCp, drjit.auto.ad.Float, drjit.auto.ad._FloatCp, drjit.auto.ad.Float, Color1f, drjit.auto.ad.Array1b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Color3d(drjit.ArrayBase[Color3d, _Color3dCp, drjit.auto.ad.Float64, drjit.auto.ad._Float64Cp, drjit.auto.ad.Float64, Color3d, drjit.auto.ad.Array3b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Color3f(drjit.ArrayBase[Color3f, _Color3fCp, drjit.auto.ad.Float, drjit.auto.ad._FloatCp, drjit.auto.ad.Float, Color3f, drjit.auto.ad.Array3b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class ContinuousDistribution:
    """
    Continuous 1D probability distribution defined in terms of a regularly
    sampled linear interpolant

    This data structure represents a continuous 1D probability
    distribution that is defined as a linear interpolant of a regularly
    discretized signal. The class provides various routines for
    transforming uniformly distributed samples so that they follow the
    stored distribution. Note that unnormalized probability density
    functions (PDFs) will automatically be normalized during
    initialization. The associated scale factor can be retrieved using the
    function normalization().
    """

    @overload
    def __init__(self) -> None:
        """
        Continuous 1D probability distribution defined in terms of a regularly
        sampled linear interpolant

        This data structure represents a continuous 1D probability
        distribution that is defined as a linear interpolant of a regularly
        discretized signal. The class provides various routines for
        transforming uniformly distributed samples so that they follow the
        stored distribution. Note that unnormalized probability density
        functions (PDFs) will automatically be normalized during
        initialization. The associated scale factor can be retrieved using the
        function normalization().
        """

    @overload
    def __init__(self, arg: ContinuousDistribution) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, range: ScalarVector2f, pdf: drjit.auto.ad.Float) -> None:
        """Initialize from a given density function on the interval ``range``"""

    def __len__(self) -> int: ...

    def size(self) -> int:
        """Return the number of discretizations"""

    def empty(self) -> bool:
        """Is the distribution object empty/uninitialized?"""

    @property
    def range(self) -> ScalarVector2f:
        """Return the range of the distribution"""

    @range.setter
    def range(self, arg: ScalarVector2f, /) -> None: ...

    @property
    def pdf(self) -> drjit.auto.ad.Float:
        """Return the unnormalized discretized probability density function"""

    @pdf.setter
    def pdf(self, arg: drjit.auto.ad.Float, /) -> None: ...

    @property
    def cdf(self) -> drjit.auto.ad.Float:
        """
        Return the unnormalized discrete cumulative distribution function over
        intervals
        """

    @cdf.setter
    def cdf(self, arg: drjit.auto.ad.Float, /) -> None: ...

    def eval_pdf(self, x: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the unnormalized probability mass function (PDF) at position
        ``x``
        """

    def eval_pdf_normalized(self, x: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the normalized probability mass function (PDF) at position
        ``x``
        """

    def eval_cdf(self, x: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the unnormalized cumulative distribution function (CDF) at
        position ``p``
        """

    def eval_cdf_normalized(self, x: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the unnormalized cumulative distribution function (CDF) at
        position ``p``
        """

    def update(self) -> None:
        """Update the internal state. Must be invoked when changing the pdf."""

    def integral(self) -> drjit.auto.ad.Float:
        """Return the original integral of PDF entries before normalization"""

    def normalization(self) -> drjit.auto.ad.Float:
        """Return the normalization factor (i.e. the inverse of sum())"""

    def interval_resolution(self) -> float:
        """Return the minimum resolution of the discretization"""

    def max(self) -> float: ...

    def sample(self, value: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        %Transform a uniformly distributed sample to the stored distribution

        Parameter ``sample``:
            A uniformly distributed sample on the interval [0, 1].

        Returns:
            The sampled position.
        """

    def sample_pdf(self, value: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> tuple[drjit.auto.ad.Float, drjit.auto.ad.Float]:
        """
        %Transform a uniformly distributed sample to the stored distribution

        Parameter ``sample``:
            A uniformly distributed sample on the interval [0, 1].

        Returns:
            A tuple consisting of

        1. the sampled position. 2. the normalized probability density of the
        sample.
        """

    def __repr__(self) -> str: ...

class CppADIntegrator(SamplingIntegrator):
    def __init__(self, arg: Properties, /) -> None: ...

class DefaultFormatter(Formatter):
    """
    The default formatter used to turn log messages into a human-readable
    form
    """

    def __init__(self) -> None: ...

    def has_date(self) -> bool:
        """
        See also:
            set_has_date
        """

    def set_has_date(self, arg: bool, /) -> None:
        """Should date information be included? The default is yes."""

    def has_thread(self) -> bool:
        """
        See also:
            set_has_thread
        """

    def set_has_thread(self, arg: bool, /) -> None:
        """Should thread information be included? The default is yes."""

    def has_log_level(self) -> bool:
        """
        See also:
            set_has_log_level
        """

    def set_has_log_level(self, arg: bool, /) -> None:
        """Should log level information be included? The default is yes."""

    def has_class(self) -> bool:
        """
        See also:
            set_has_class
        """

    def set_has_class(self, arg: bool, /) -> None:
        """Should class information be included? The default is yes."""

class DirectionSample3f(PositionSample3f):
    """
    Record for solid-angle based area sampling techniques

    This data structure is used in techniques that sample positions
    relative to a fixed reference position in the scene. For instance,
    *direct illumination strategies* importance sample the incident
    radiance received by a given surface location. Mitsuba uses this
    approach in a wider bidirectional sense: sampling the incident
    importance due to a sensor also uses the same data structures and
    strategies, which are referred to as *direct sampling*.

    This record inherits all fields from PositionSample and extends it
    with two useful quantities that are cached so that they don't need to
    be recomputed: the unit direction and distance from the reference
    position to the sampled point.
    """

    @overload
    def __init__(self) -> None:
        """Construct an uninitialized direct sample"""

    @overload
    def __init__(self, other: PositionSample3f) -> None:
        """Construct from a position sample"""

    @overload
    def __init__(self, other: DirectionSample3f) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, p: ScalarPoint3f, n: ScalarNormal3f, uv: ScalarPoint2f, time: float, pdf: float, delta: bool, d: ScalarVector3f, dist: float, emitter: Emitter) -> None:
        """Element-by-element constructor"""

    @overload
    def __init__(self, scene: Scene | None, si: SurfaceInteraction3f, ref: Interaction3f) -> None:
        """
        Create a position sampling record from a surface intersection

        This is useful to determine the hypothetical sampling density on a
        surface after hitting it using standard ray tracing. This happens for
        instance in path tracing with multiple importance sampling.
        """

    @property
    def d(self) -> ScalarVector3f:
        """Unit direction from the reference point to the target shape"""

    @d.setter
    def d(self, arg: ScalarVector3f, /) -> None: ...

    @property
    def dist(self) -> float:
        """Distance from the reference point to the target shape"""

    @dist.setter
    def dist(self, arg: float, /) -> None: ...

    @property
    def emitter(self) -> Emitter:
        """
        Optional: pointer to an associated object

        In some uses of this record, sampling a position also involves
        choosing one of several objects (shapes, emitters, ..) on which the
        position lies. In that case, the ``object`` attribute stores a pointer
        to this object.
        """

    @emitter.setter
    def emitter(self, arg: Emitter, /) -> None: ...

    def __repr__(self) -> str: ...

    def assign(self, arg: DirectionSample3f, /) -> None: ...

class DiscontinuityFlags(enum.IntEnum):
    """
    This list of flags is used to control the behavior of discontinuity
    related routines.
    """

    Empty = 0
    """No flags set (default value)"""

    PerimeterType = 1
    """Open boundary or jumping normal type of discontinuity"""

    InteriorType = 2
    """Smooth normal type of discontinuity"""

    DirectionLune = 4
    """//! Encoding and projection flags"""

    DirectionSphere = 8
    """//! Encoding and projection flags"""

    HeuristicWalk = 16
    """//! Encoding and projection flags"""

    AllTypes = 3
    """All types of discontinuities"""

class DiscreteDistribution:
    """
    Discrete 1D probability distribution

    This data structure represents a discrete 1D probability distribution
    and provides various routines for transforming uniformly distributed
    samples so that they follow the stored distribution. Note that
    unnormalized probability mass functions (PMFs) will automatically be
    normalized during initialization. The associated scale factor can be
    retrieved using the function normalization().
    """

    @overload
    def __init__(self) -> None:
        """
        Discrete 1D probability distribution

        This data structure represents a discrete 1D probability distribution
        and provides various routines for transforming uniformly distributed
        samples so that they follow the stored distribution. Note that
        unnormalized probability mass functions (PMFs) will automatically be
        normalized during initialization. The associated scale factor can be
        retrieved using the function normalization().
        """

    @overload
    def __init__(self, arg: DiscreteDistribution) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, pmf: drjit.auto.ad.Float) -> None:
        """Initialize from a given probability mass function"""

    def __len__(self) -> int: ...

    def size(self) -> int:
        """Return the number of entries"""

    def empty(self) -> bool:
        """Is the distribution object empty/uninitialized?"""

    @property
    def pmf(self) -> drjit.auto.ad.Float:
        """Return the unnormalized probability mass function"""

    @pmf.setter
    def pmf(self, arg: drjit.auto.ad.Float, /) -> None: ...

    @property
    def cdf(self) -> drjit.auto.ad.Float:
        """Return the unnormalized cumulative distribution function"""

    @cdf.setter
    def cdf(self, arg: drjit.auto.ad.Float, /) -> None: ...

    def eval_pmf(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the unnormalized probability mass function (PMF) at index
        ``index``
        """

    def eval_pmf_normalized(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the normalized probability mass function (PMF) at index
        ``index``
        """

    def eval_cdf(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the unnormalized cumulative distribution function (CDF) at
        index ``index``
        """

    def eval_cdf_normalized(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the normalized cumulative distribution function (CDF) at
        index ``index``
        """

    def update(self) -> None:
        """Update the internal state. Must be invoked when changing the pmf."""

    def normalization(self) -> drjit.auto.ad.Float:
        """Return the normalization factor (i.e. the inverse of sum())"""

    def sum(self) -> drjit.auto.ad.Float:
        """Return the original sum of PMF entries before normalization"""

    def sample(self, value: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.UInt:
        """
        %Transform a uniformly distributed sample to the stored distribution

        Parameter ``sample``:
            A uniformly distributed sample on the interval [0, 1].

        Returns:
            The discrete index associated with the sample
        """

    def sample_pmf(self, value: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> tuple[drjit.auto.ad.UInt, drjit.auto.ad.Float]:
        """
        %Transform a uniformly distributed sample to the stored distribution

        Parameter ``value``:
            A uniformly distributed sample on the interval [0, 1].

        Returns:
            A tuple consisting of

        1. the discrete index associated with the sample, and 2. the
        normalized probability value of the sample.
        """

    def sample_reuse(self, value: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> tuple[drjit.auto.ad.UInt, drjit.auto.ad.Float]:
        """
        %Transform a uniformly distributed sample to the stored distribution

        The original sample is value adjusted so that it can be reused as a
        uniform variate.

        Parameter ``value``:
            A uniformly distributed sample on the interval [0, 1].

        Returns:
            A tuple consisting of

        1. the discrete index associated with the sample, and 2. the re-scaled
        sample value.
        """

    def sample_reuse_pmf(self, value: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> tuple[drjit.auto.ad.UInt, drjit.auto.ad.Float, drjit.auto.ad.Float]:
        """
        %Transform a uniformly distributed sample to the stored distribution.

        The original sample is value adjusted so that it can be reused as a
        uniform variate.

        Parameter ``value``:
            A uniformly distributed sample on the interval [0, 1].

        Returns:
            A tuple consisting of

        1. the discrete index associated with the sample 2. the re-scaled
        sample value 3. the normalized probability value of the sample
        """

    def __repr__(self) -> str: ...

class DiscreteDistribution2D:
    def __init__(self, data: Annotated[ArrayLike, dict(dtype='float32', shape=(None, None))]) -> None: ...

    def eval(self, pos: Point2u, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float: ...

    def pdf(self, pos: Point2u, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float: ...

    def sample(self, sample: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[Point2u, drjit.auto.ad.Float, Point2f]: ...

    def __repr__(self) -> str: ...

class DummyStream(Stream):
    """
    Stream implementation that never writes to disk, but keeps track of
    the size of the content being written. It can be used, for example, to
    measure the precise amount of memory needed to store serialized
    content.
    """

    def __init__(self) -> None: ...

class Emitter(Endpoint):
    def __init__(self, props: Properties) -> None: ...

    def is_environment(self) -> bool:
        """Is this an environment map light emitter?"""

    def sampling_weight(self) -> float:
        """The emitter's sampling weight."""

    def flags(self, active: bool = True) -> int:
        """Flags for all components combined."""

    @property
    def m_needs_sample_2(self) -> bool: ...

    @m_needs_sample_2.setter
    def m_needs_sample_2(self, arg: bool, /) -> None: ...

    @property
    def m_needs_sample_3(self) -> bool: ...

    @m_needs_sample_3.setter
    def m_needs_sample_3(self, arg: bool, /) -> None: ...

    @property
    def m_flags(self) -> int:
        """Combined flags for all properties of this emitter."""

    @m_flags.setter
    def m_flags(self, arg: int, /) -> None: ...

class EmitterFlags(enum.IntEnum):
    """
    This list of flags is used to classify the different types of
    emitters.
    """

    Empty = 0
    """No flags set (default value)"""

    DeltaPosition = 1
    """The emitter lies at a single point in space"""

    DeltaDirection = 2
    """The emitter emits light in a single direction"""

    Infinite = 4
    """The emitter is placed at infinity (e.g. environment maps)"""

    Surface = 8
    """The emitter is attached to a surface (e.g. area emitters)"""

    SpatiallyVarying = 16
    """The emission depends on the UV coordinates"""

    Delta = 3
    """Delta function in either position or direction"""

class EmitterPtr(drjit.ArrayBase[EmitterPtr, _EmitterPtrCp, Emitter, Emitter, EmitterPtr, EmitterPtr, drjit.auto.ad.Bool]):
    Variant: str = 'llvm_ad_spectral_polarized'

    @overload
    def sample_ray(self, time: drjit.auto.ad.Float, sample1: drjit.auto.ad.Float, sample2: Point2f, sample3: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[Ray3f, Spectrum]:
        """
        Importance sample a ray proportional to the endpoint's
        sensitivity/emission profile.

        The endpoint profile is a six-dimensional quantity that depends on
        time, wavelength, surface position, and direction. This function takes
        a given time value and five uniformly distributed samples on the
        interval [0, 1] and warps them so that the returned ray follows the
        profile. Any discrepancies between ideal and actual sampled profile
        are absorbed into a spectral importance weight that is returned along
        with the ray.

        Parameter ``time``:
            The scene time associated with the ray to be sampled

        Parameter ``sample1``:
            A uniformly distributed 1D value that is used to sample the
            spectral dimension of the emission profile.

        Parameter ``sample2``:
            A uniformly distributed sample on the domain ``[0,1]^2``. For
            sensor endpoints, this argument corresponds to the sample position
            in fractional pixel coordinates relative to the crop window of the
            underlying film. This argument is ignored if ``needs_sample_2() ==
            false``.

        Parameter ``sample3``:
            A uniformly distributed sample on the domain ``[0,1]^2``. For
            sensor endpoints, this argument determines the position on the
            aperture of the sensor. This argument is ignored if
            ``needs_sample_3() == false``.

        Returns:
            The sampled ray and (potentially spectrally varying) importance
            weights. The latter account for the difference between the profile
            and the actual used sampling density function.
        """

    @overload
    def sample_ray(self, time: drjit.auto.ad.Float, sample1: drjit.auto.ad.Float, sample2: Point2f, sample3: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[Ray3f, Spectrum]: ...

    @overload
    def sample_direction(self, it: Interaction3f, sample: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[DirectionSample3f, Spectrum]:
        """
        Given a reference point in the scene, sample a direction from the
        reference point towards the endpoint (ideally proportional to the
        emission/sensitivity profile)

        This operation is a generalization of direct illumination techniques
        to both emitters *and* sensors. A direction sampling method is given
        an arbitrary reference position in the scene and samples a direction
        from the reference point towards the endpoint (ideally proportional to
        the emission/sensitivity profile). This reduces the sampling domain
        from 4D to 2D, which often enables the construction of smarter
        specialized sampling techniques.

        Ideally, the implementation should importance sample the product of
        the emission profile and the geometry term between the reference point
        and the position on the endpoint.

        The default implementation throws an exception.

        Parameter ``ref``:
            A reference position somewhere within the scene.

        Parameter ``sample``:
            A uniformly distributed 2D point on the domain ``[0,1]^2``.

        Returns:
            A DirectionSample instance describing the generated sample along
            with a spectral importance weight.
        """

    @overload
    def sample_direction(self, it: Interaction3f, sample: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[DirectionSample3f, Spectrum]: ...

    @overload
    def pdf_direction(self, it: Interaction3f, ds: DirectionSample3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the probability density of the *direct* sampling method
        implemented by the sample_direction() method.

        The returned probability will always be zero when the
        emission/sensitivity profile contains a Dirac delta term (e.g. point
        or directional emitters/sensors).

        Parameter ``ds``:
            A direct sampling record, which specifies the query location.
        """

    @overload
    def pdf_direction(self, it: Interaction3f, ds: DirectionSample3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float: ...

    @overload
    def eval_direction(self, it: Interaction3f, ds: DirectionSample3f, active: drjit.auto.ad.Bool = True) -> Spectrum:
        """
        Re-evaluate the incident direct radiance/importance of the
        sample_direction() method.

        This function re-evaluates the incident direct radiance or importance
        and sample probability due to the endpoint so that division by
        ``ds.pdf`` equals the sampling weight returned by sample_direction().
        This may appear redundant, and indeed such a function would not find
        use in "normal" rendering algorithms.

        However, the ability to re-evaluate the contribution of a generated
        sample is important for differentiable rendering. For example, we
        might want to track derivatives in the sampled direction (``ds.d``)
        without also differentiating the sampling technique.

        In contrast to pdf_direction(), evaluating this function can yield a
        nonzero result in the case of emission profiles containing a Dirac
        delta term (e.g. point or directional lights).

        Parameter ``ref``:
            A 3D reference location within the scene, which may influence the
            sampling process.

        Parameter ``ds``:
            A direction sampling record, which specifies the query location.

        Returns:
            The incident direct radiance/importance associated with the
            sample.
        """

    @overload
    def eval_direction(self, it: Interaction3f, ds: DirectionSample3f, active: drjit.auto.ad.Bool = True) -> Spectrum: ...

    @overload
    def sample_position(self, time: drjit.auto.ad.Float, sample: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[PositionSample3f, drjit.auto.ad.Float]:
        """
        Importance sample the spatial component of the emission or importance
        profile of the endpoint.

        The default implementation throws an exception.

        Parameter ``time``:
            The scene time associated with the position to be sampled.

        Parameter ``sample``:
            A uniformly distributed 2D point on the domain ``[0,1]^2``.

        Returns:
            A PositionSample instance describing the generated sample along
            with an importance weight.
        """

    @overload
    def sample_position(self, time: drjit.auto.ad.Float, sample: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[PositionSample3f, drjit.auto.ad.Float]: ...

    @overload
    def pdf_position(self, ps: PositionSample3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the probability density of the position sampling method
        implemented by sample_position().

        In simple cases, this will be the reciprocal of the endpoint's surface
        area.

        Parameter ``ps``:
            The sampled position record.

        Returns:
            The corresponding sampling density.
        """

    @overload
    def pdf_position(self, ps: PositionSample3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float: ...

    @overload
    def eval(self, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> Spectrum:
        """
        Given a ray-surface intersection, return the emitted radiance or
        importance traveling along the reverse direction

        This function is e.g. used when an area light source has been hit by a
        ray in a path tracing-style integrator, and it subsequently needs to
        be queried for the emitted radiance along the negative ray direction.
        The default implementation throws an exception, which states that the
        method is not implemented.

        Parameter ``si``:
            An intersect record that specifies both the query position and
            direction (using the ``si.wi`` field)

        Returns:
            The emitted radiance or importance
        """

    @overload
    def eval(self, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> Spectrum: ...

    @overload
    def sample_wavelengths(self, si: SurfaceInteraction3f, sample: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> tuple[UnpolarizedSpectrum, Spectrum]:
        """
        Importance sample a set of wavelengths according to the endpoint's
        sensitivity/emission spectrum.

        This function takes a uniformly distributed 1D sample and generates a
        sample that is approximately distributed according to the endpoint's
        spectral sensitivity/emission profile.

        For this, the input 1D sample is first replicated into
        ``Spectrum::Size`` separate samples using simple arithmetic
        transformations (see math::sample_shifted()), which can be interpreted
        as a type of Quasi-Monte-Carlo integration scheme. Following this, a
        standard technique (e.g. inverse transform sampling) is used to find
        the corresponding wavelengths. Any discrepancies between ideal and
        actual sampled profile are absorbed into a spectral importance weight
        that is returned along with the wavelengths.

        This function should not be called in RGB or monochromatic modes.

        Parameter ``si``:
            In the case of a spatially-varying spectral sensitivity/emission
            profile, this parameter conditions sampling on a specific spatial
            position. The ``si.uv`` field must be specified in this case.

        Parameter ``sample``:
            A 1D uniformly distributed random variate

        Returns:
            The set of sampled wavelengths and (potentially spectrally
            varying) importance weights. The latter account for the difference
            between the profile and the actual used sampling density function.
            In the case of emitters, the weight will include the emitted
            radiance.
        """

    @overload
    def sample_wavelengths(self, si: SurfaceInteraction3f, sample: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> tuple[UnpolarizedSpectrum, Spectrum]: ...

    @overload
    def flags(self) -> drjit.auto.ad.UInt:
        """Flags for all components combined."""

    @overload
    def flags(self) -> drjit.auto.ad.UInt: ...

    @overload
    def get_shape(self) -> ShapePtr:
        """Return the shape, to which the emitter is currently attached"""

    @overload
    def get_shape(self) -> ShapePtr: ...

    @overload
    def get_medium(self) -> MediumPtr:
        """Return a pointer to the medium that surrounds the emitter"""

    @overload
    def get_medium(self) -> MediumPtr: ...

    @overload
    def sampling_weight(self) -> drjit.auto.ad.Float:
        """The emitter's sampling weight."""

    @overload
    def sampling_weight(self) -> drjit.auto.ad.Float: ...

    @overload
    def is_environment(self) -> drjit.auto.ad.Bool:
        """Is this an environment map light emitter?"""

    @overload
    def is_environment(self) -> drjit.auto.ad.Bool: ...

class Endpoint(Object):
    """
    Abstract interface subsuming emitters and sensors in Mitsuba.

    This class provides an abstract interface to emitters and sensors in
    Mitsuba, which are named *endpoints* since they represent the first
    and last vertices of a light path. Thanks to symmetries underlying the
    equations of light transport and scattering, sensors and emitters can
    be treated as essentially the same thing, their main difference being
    type of emitted radiation: light sources emit *radiance*, while
    sensors emit a conceptual radiation named *importance*. This class
    casts these symmetries into a unified API that enables access to both
    types of endpoints using the same set of functions.

    Subclasses of this interface must implement functions to evaluate and
    sample the emission/response profile, and to compute probability
    densities associated with the provided sampling techniques.

    In addition to :py:meth:`mitsuba.Endpoint.sample_ray`, which generates
    a sample from the profile, subclasses also provide a specialized
    *direction sampling* method in
    :py:meth:`mitsuba.Endpoint.sample_direction`. This is a generalization
    of direct illumination techniques to both emitters *and* sensors. A
    direction sampling method is given an arbitrary reference position in
    the scene and samples a direction from the reference point towards the
    endpoint (ideally proportional to the emission/sensitivity profile).
    This reduces the sampling domain from 4D to 2D, which often enables
    the construction of smarter specialized sampling techniques.

    When rendering scenes involving participating media, it is important
    to know what medium surrounds the sensors and emitters. For this
    reason, every endpoint instance keeps a reference to a medium (which
    may be set to ``nullptr`` when the endpoint is surrounded by vacuum).

    In the context of polarized simulation, the perfect symmetry between
    emitters and sensors technically breaks down: the former emit 4D
    *Stokes vectors* encoding the polarization state of light, while
    sensors are characterized by 4x4 *Mueller matrices* that transform the
    incident polarization prior to measurement. We sidestep this non-
    symmetry by simply using Mueller matrices everywhere: in the case of
    emitters, only the first column will be used (the remainder being
    filled with zeros). This API simplification comes at a small extra
    cost in terms of register usage and arithmetic. The JIT (LLVM, CUDA)
    variants of Mitsuba can recognize these redundancies and remove them
    retroactively.
    """

    def sample_ray(self, time: float, sample1: float, sample2: ScalarPoint2f, sample3: ScalarPoint2f, active: bool = True) -> tuple[Ray3f, ScalarColor3f]:
        """
        Importance sample a ray proportional to the endpoint's
        sensitivity/emission profile.

        The endpoint profile is a six-dimensional quantity that depends on
        time, wavelength, surface position, and direction. This function takes
        a given time value and five uniformly distributed samples on the
        interval [0, 1] and warps them so that the returned ray follows the
        profile. Any discrepancies between ideal and actual sampled profile
        are absorbed into a spectral importance weight that is returned along
        with the ray.

        Parameter ``time``:
            The scene time associated with the ray to be sampled

        Parameter ``sample1``:
            A uniformly distributed 1D value that is used to sample the
            spectral dimension of the emission profile.

        Parameter ``sample2``:
            A uniformly distributed sample on the domain ``[0,1]^2``. For
            sensor endpoints, this argument corresponds to the sample position
            in fractional pixel coordinates relative to the crop window of the
            underlying film. This argument is ignored if ``needs_sample_2() ==
            false``.

        Parameter ``sample3``:
            A uniformly distributed sample on the domain ``[0,1]^2``. For
            sensor endpoints, this argument determines the position on the
            aperture of the sensor. This argument is ignored if
            ``needs_sample_3() == false``.

        Returns:
            The sampled ray and (potentially spectrally varying) importance
            weights. The latter account for the difference between the profile
            and the actual used sampling density function.
        """

    def sample_direction(self, it: Interaction3f, sample: ScalarPoint2f, active: bool = True) -> tuple[DirectionSample3f, ScalarColor3f]:
        """
        Given a reference point in the scene, sample a direction from the
        reference point towards the endpoint (ideally proportional to the
        emission/sensitivity profile)

        This operation is a generalization of direct illumination techniques
        to both emitters *and* sensors. A direction sampling method is given
        an arbitrary reference position in the scene and samples a direction
        from the reference point towards the endpoint (ideally proportional to
        the emission/sensitivity profile). This reduces the sampling domain
        from 4D to 2D, which often enables the construction of smarter
        specialized sampling techniques.

        Ideally, the implementation should importance sample the product of
        the emission profile and the geometry term between the reference point
        and the position on the endpoint.

        The default implementation throws an exception.

        Parameter ``ref``:
            A reference position somewhere within the scene.

        Parameter ``sample``:
            A uniformly distributed 2D point on the domain ``[0,1]^2``.

        Returns:
            A DirectionSample instance describing the generated sample along
            with a spectral importance weight.
        """

    def pdf_direction(self, it: Interaction3f, ds: DirectionSample3f, active: bool = True) -> float:
        """
        Evaluate the probability density of the *direct* sampling method
        implemented by the sample_direction() method.

        The returned probability will always be zero when the
        emission/sensitivity profile contains a Dirac delta term (e.g. point
        or directional emitters/sensors).

        Parameter ``ds``:
            A direct sampling record, which specifies the query location.
        """

    def eval_direction(self, it: Interaction3f, ds: DirectionSample3f, active: bool = True) -> ScalarColor3f:
        """
        Re-evaluate the incident direct radiance/importance of the
        sample_direction() method.

        This function re-evaluates the incident direct radiance or importance
        and sample probability due to the endpoint so that division by
        ``ds.pdf`` equals the sampling weight returned by sample_direction().
        This may appear redundant, and indeed such a function would not find
        use in "normal" rendering algorithms.

        However, the ability to re-evaluate the contribution of a generated
        sample is important for differentiable rendering. For example, we
        might want to track derivatives in the sampled direction (``ds.d``)
        without also differentiating the sampling technique.

        In contrast to pdf_direction(), evaluating this function can yield a
        nonzero result in the case of emission profiles containing a Dirac
        delta term (e.g. point or directional lights).

        Parameter ``ref``:
            A 3D reference location within the scene, which may influence the
            sampling process.

        Parameter ``ds``:
            A direction sampling record, which specifies the query location.

        Returns:
            The incident direct radiance/importance associated with the
            sample.
        """

    def sample_position(self, ref: float, ds: ScalarPoint2f, active: bool = True) -> tuple[PositionSample3f, float]:
        """
        Importance sample the spatial component of the emission or importance
        profile of the endpoint.

        The default implementation throws an exception.

        Parameter ``time``:
            The scene time associated with the position to be sampled.

        Parameter ``sample``:
            A uniformly distributed 2D point on the domain ``[0,1]^2``.

        Returns:
            A PositionSample instance describing the generated sample along
            with an importance weight.
        """

    def pdf_position(self, ps: PositionSample3f, active: bool = True) -> float:
        """
        Evaluate the probability density of the position sampling method
        implemented by sample_position().

        In simple cases, this will be the reciprocal of the endpoint's surface
        area.

        Parameter ``ps``:
            The sampled position record.

        Returns:
            The corresponding sampling density.
        """

    def eval(self, si: SurfaceInteraction3f, active: bool = True) -> ScalarColor3f:
        """
        Given a ray-surface intersection, return the emitted radiance or
        importance traveling along the reverse direction

        This function is e.g. used when an area light source has been hit by a
        ray in a path tracing-style integrator, and it subsequently needs to
        be queried for the emitted radiance along the negative ray direction.
        The default implementation throws an exception, which states that the
        method is not implemented.

        Parameter ``si``:
            An intersect record that specifies both the query position and
            direction (using the ``si.wi`` field)

        Returns:
            The emitted radiance or importance
        """

    def sample_wavelengths(self, si: SurfaceInteraction3f, sample: float, active: bool = True) -> tuple[ScalarColor0f, ScalarColor3f]:
        """
        Importance sample a set of wavelengths according to the endpoint's
        sensitivity/emission spectrum.

        This function takes a uniformly distributed 1D sample and generates a
        sample that is approximately distributed according to the endpoint's
        spectral sensitivity/emission profile.

        For this, the input 1D sample is first replicated into
        ``Spectrum::Size`` separate samples using simple arithmetic
        transformations (see math::sample_shifted()), which can be interpreted
        as a type of Quasi-Monte-Carlo integration scheme. Following this, a
        standard technique (e.g. inverse transform sampling) is used to find
        the corresponding wavelengths. Any discrepancies between ideal and
        actual sampled profile are absorbed into a spectral importance weight
        that is returned along with the wavelengths.

        This function should not be called in RGB or monochromatic modes.

        Parameter ``si``:
            In the case of a spatially-varying spectral sensitivity/emission
            profile, this parameter conditions sampling on a specific spatial
            position. The ``si.uv`` field must be specified in this case.

        Parameter ``sample``:
            A 1D uniformly distributed random variate

        Returns:
            The set of sampled wavelengths and (potentially spectrally
            varying) importance weights. The latter account for the difference
            between the profile and the actual used sampling density function.
            In the case of emitters, the weight will include the emitted
            radiance.
        """

    def world_transform(self) -> ScalarTransform4f:
        """Return the local space to world space transformation"""

    def needs_sample_2(self) -> bool:
        """
        Does the method sample_ray() require a uniformly distributed 2D sample
        for the ``sample2`` parameter?
        """

    def needs_sample_3(self) -> bool:
        """
        Does the method sample_ray() require a uniformly distributed 2D sample
        for the ``sample3`` parameter?
        """

    def get_shape(self) -> Shape:
        """Return the shape, to which the emitter is currently attached"""

    def get_medium(self) -> Medium:
        """Return a pointer to the medium that surrounds the emitter"""

    def set_shape(self, shape: Shape) -> None:
        """Set the shape associated with this endpoint."""

    def set_medium(self, medium: Medium) -> None:
        """Set the medium that surrounds the emitter."""

    def set_scene(self, scene: Scene) -> None:
        """
        Inform the emitter about the properties of the scene

        Various emitters that surround the scene (e.g. environment emitters)
        must be informed about the scene dimensions to operate correctly. This
        function is invoked by the Scene constructor.
        """

    def bbox(self) -> ScalarBoundingBox3f:
        """Return an axis-aligned box bounding the spatial extents of the emitter"""

class FileResolver(Object):
    """
    Simple class for resolving paths on Linux/Windows/Mac OS

    This convenience class looks for a file or directory given its name
    and a set of search paths. The implementation walks through the search
    paths in order and stops once the file is found.
    """

    @overload
    def __init__(self) -> None:
        """Initialize a new file resolver with the current working directory"""

    @overload
    def __init__(self, arg: FileResolver) -> None:
        """Copy constructor"""

    def __len__(self) -> int:
        """Return the number of search paths"""

    def __iter__(self) -> Iterator[str]: ...

    def __delitem__(self, arg: int, /) -> None: ...

    def __getitem__(self, arg: int, /) -> str: ...

    def __setitem__(self, arg0: int, arg1: str, /) -> None: ...

    def resolve(self, arg: str, /) -> str:
        """
        Walk through the list of search paths and try to resolve the input
        path
        """

    def clear(self) -> None:
        """Clear the list of search paths"""

    def prepend(self, arg: str, /) -> None:
        """Prepend an entry at the beginning of the list of search paths"""

    def append(self, arg: str, /) -> None:
        """Append an entry to the end of the list of search paths"""

class FileStream(Stream):
    """
    Simple Stream implementation backed-up by a file.

    The underlying file abstraction is ``std::fstream``, and so most
    operations can be expected to behave similarly.
    """

    def __init__(self, p: str, mode: FileStream.EMode = FileStream.EMode.ERead) -> None:
        """
        Constructs a new FileStream by opening the file pointed by ``p``.

        The file is opened in read-only or read/write mode as specified by
        ``mode``.

        Throws if trying to open a non-existing file in with write disabled.
        Throws an exception if the file cannot be opened / created.
        """

    def path(self) -> str:
        """Return the path descriptor associated with this FileStream"""

    class EMode(enum.Enum):
        ERead = 0
        """Opens a file in (binary) read-only mode"""

        EReadWrite = 1
        """Opens (but never creates) a file in (binary) read-write mode"""

        ETruncReadWrite = 2
        """Opens (and truncates) a file in (binary) read-write mode"""

    ERead: FileStream.EMode = FileStream.EMode.ERead

    EReadWrite: FileStream.EMode = FileStream.EMode.EReadWrite

    ETruncReadWrite: FileStream.EMode = FileStream.EMode.ETruncReadWrite

class Film(Object):
    """
    Abstract film base class - used to store samples generated by
    Integrator implementations.

    To avoid lock-related bottlenecks when rendering with many cores,
    rendering threads first store results in an "image block", which is
    then committed to the film using the put() method.
    """

    def __init__(self, props: Properties) -> None: ...

    def prepare(self, aovs: Sequence[str]) -> int:
        """
        Configure the film for rendering a specified set of extra channels
        (AOVS). Returns the total number of channels that the film will store
        """

    def put_block(self, block: ImageBlock) -> None:
        """
        Merge an image block into the film. This methods should be thread-
        safe.
        """

    def clear(self) -> None:
        """Clear the film contents to zero."""

    def develop(self, raw: bool = False) -> drjit.scalar.TensorXf:
        """Return a image buffer object storing the developed image"""

    def bitmap(self, raw: bool = False) -> Bitmap:
        """Return a bitmap object storing the developed contents of the film"""

    def write(self, path: str) -> None:
        """Write the developed contents of the film to a file on disk"""

    def sample_border(self) -> bool:
        """
        Should regions slightly outside the image plane be sampled to improve
        the quality of the reconstruction at the edges? This only makes sense
        when reconstruction filters other than the box filter are used.
        """

    def base_channels_count(self) -> int:
        """Return the number of channels for the developed image (excluding AOVS)"""

    def size(self) -> ScalarVector2u:
        """
        Ignoring the crop window, return the resolution of the underlying
        sensor
        """

    def crop_size(self) -> ScalarVector2u:
        """Return the size of the crop window"""

    def crop_offset(self) -> ScalarPoint2u:
        """Return the offset of the crop window"""

    def rfilter(self) -> BitmapReconstructionFilter:
        """Return the image reconstruction filter (const version)"""

    def prepare_sample(self, spec: ScalarColor3f, wavelengths: ScalarColor0f, nChannels: int, weight: float = 1.0, alpha: float = 1.0, active: bool = True) -> list[float]:
        """
        Prepare spectrum samples to be in the format expected by the film

        It will be used if the Film contains the ``Special`` flag enabled.

        This method should be applied with films that deviate from HDR film
        behavior. Normally ``Films`` will store within the ``ImageBlock`` the
        samples following an RGB shape. But ``Films`` may want to store the
        samples with other structures (e.g. store several channels containing
        monochromatic information). In that situation, this method allows
        transforming the sample format generated by the integrators to the one
        that the Film will store inside the ImageBlock.

        Parameter ``spec``:
            Sample value associated with the specified wavelengths

        Parameter ``wavelengths``:
            Sample wavelengths in nanometers

        Parameter ``aovs``:
            Points to an array of length equal to the number of spectral
            sensitivities of the film, which specifies the sample value for
            each channel.

        Parameter ``weight``:
            Value to be added to the weight channel of the sample

        Parameter ``alpha``:
            Alpha value of the sample

        Parameter ``active``:
            Mask indicating if the lanes are active
        """

    def create_block(self, size: ScalarVector2u = ..., normalize: bool = False, borders: bool = False) -> ImageBlock:
        """
        Return an ImageBlock instance, whose internal representation is
        compatible with that of the film.

        Image blocks created using this method can later be merged into the
        film using put_block().

        Parameter ``size``:
            Desired size of the returned image block.

        Parameter ``normalize``:
            Force normalization of filter weights in ImageBlock::put()? See
            the ImageBlock constructor for details.

        Parameter ``border``:
            Should ``ImageBlock`` add an additional border region around
            around the image boundary? See the ImageBlock constructor for
            details.
        """

    def schedule_storage(self) -> None:
        """dr::schedule() variables that represent the internal film storage"""

    def sensor_response_function(self) -> Texture:
        """Returns the specific Sensor Response Function (SRF) used by the film"""

    def flags(self) -> int:
        """Flags for all properties combined."""

    @property
    def m_flags(self) -> int:
        """Combined flags for all properties of this film."""

    @m_flags.setter
    def m_flags(self, arg: int, /) -> None: ...

class FilmFlags(enum.IntEnum):
    """This list of flags is used to classify the different types of films."""

    Empty = 0
    """No flags set (default value)"""

    Alpha = 1
    """The film stores an alpha channel"""

    Spectral = 2
    """The film stores a spectral representation of the image"""

    Special = 4
    """
    The film provides a customized prepare_sample() routine that
    implements a special treatment of the samples before storing them in
    the Image Block.
    """

class FilterBoundaryCondition(enum.Enum):
    """
    When resampling data to a different resolution using
    Resampler::resample(), this enumeration specifies how lookups
    *outside* of the input domain are handled.

    See also:
        Resampler
    """

    Clamp = 0
    """Clamp to the outermost sample position (default)"""

    Repeat = 1
    """Assume that the input repeats in a periodic fashion"""

    Mirror = 2
    """Assume that the input is mirrored along the boundary"""

    Zero = 3
    """Assume that the input function is zero outside of the defined domain"""

    One = 4
    """
    Assume that the input function is equal to one outside of the defined
    domain
    """

class Formatter(Object):
    """
    Abstract interface for converting log information into a human-
    readable format
    """

    def __init__(self) -> None: ...

    def format(self, level: LogLevel, class_: Class, thread: Thread, file: str, line: int, msg: str) -> str:
        """
        Turn a log message into a human-readable format

        Parameter ``level``:
            The importance of the debug message

        Parameter ``class_``:
            Originating class or ``nullptr``

        Parameter ``thread``:
            Thread, which is responsible for creating the message

        Parameter ``file``:
            File, which is responsible for creating the message

        Parameter ``line``:
            Associated line within the source file

        Parameter ``msg``:
            Text content associated with the log message
        """

class Frame3f:
    """
    Stores a three-dimensional orthonormal coordinate frame

    This class is used to convert between different cartesian coordinate
    systems and to efficiently evaluate trigonometric functions in a
    spherical coordinate system whose pole is aligned with the ``n`` axis
    (e.g. cos_theta(), sin_phi(), etc.).
    """

    @overload
    def __init__(self) -> None:
        """Construct a new coordinate frame from a single vector"""

    @overload
    def __init__(self, arg: Frame3f) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, arg0: Vector3f, arg1: Vector3f, arg2: Vector3f, /) -> None: ...

    @overload
    def __init__(self, arg: Vector3f, /) -> None: ...

    def to_local(self, v: Vector3f) -> Vector3f:
        """Convert from world coordinates to local coordinates"""

    def to_world(self, v: Vector3f) -> Vector3f:
        """Convert from local coordinates to world coordinates"""

    @staticmethod
    def cos_theta(v: Vector3f) -> drjit.auto.ad.Float:
        """
        Give a unit direction, this function returns the cosine of the
        elevation angle in a reference spherical coordinate system (see the
        Frame description)
        """

    @staticmethod
    def cos_theta_2(v: Vector3f) -> drjit.auto.ad.Float:
        """
        Give a unit direction, this function returns the square cosine of the
        elevation angle in a reference spherical coordinate system (see the
        Frame description)
        """

    @staticmethod
    def sin_theta(v: Vector3f) -> drjit.auto.ad.Float:
        """
        Give a unit direction, this function returns the sine of the elevation
        angle in a reference spherical coordinate system (see the Frame
        description)
        """

    @staticmethod
    def sin_theta_2(v: Vector3f) -> drjit.auto.ad.Float:
        """
        Give a unit direction, this function returns the square sine of the
        elevation angle in a reference spherical coordinate system (see the
        Frame description)
        """

    @staticmethod
    def tan_theta(v: Vector3f) -> drjit.auto.ad.Float:
        """
        Give a unit direction, this function returns the tangent of the
        elevation angle in a reference spherical coordinate system (see the
        Frame description)
        """

    @staticmethod
    def tan_theta_2(v: Vector3f) -> drjit.auto.ad.Float:
        """
        Give a unit direction, this function returns the square tangent of the
        elevation angle in a reference spherical coordinate system (see the
        Frame description)
        """

    @staticmethod
    def sin_phi(v: Vector3f) -> drjit.auto.ad.Float:
        """
        Give a unit direction, this function returns the sine of the azimuth
        in a reference spherical coordinate system (see the Frame description)
        """

    @staticmethod
    def sin_phi_2(v: Vector3f) -> drjit.auto.ad.Float:
        """
        Give a unit direction, this function returns the squared sine of the
        azimuth in a reference spherical coordinate system (see the Frame
        description)
        """

    @staticmethod
    def cos_phi(v: Vector3f) -> drjit.auto.ad.Float:
        """
        Give a unit direction, this function returns the cosine of the azimuth
        in a reference spherical coordinate system (see the Frame description)
        """

    @staticmethod
    def cos_phi_2(v: Vector3f) -> drjit.auto.ad.Float:
        """
        Give a unit direction, this function returns the squared cosine of the
        azimuth in a reference spherical coordinate system (see the Frame
        description)
        """

    @staticmethod
    def sincos_phi(v: Vector3f) -> tuple[drjit.auto.ad.Float, drjit.auto.ad.Float]:
        """
        Give a unit direction, this function returns the sine and cosine of
        the azimuth in a reference spherical coordinate system (see the Frame
        description)
        """

    @staticmethod
    def sincos_phi_2(v: Vector3f) -> tuple[drjit.auto.ad.Float, drjit.auto.ad.Float]:
        """
        Give a unit direction, this function returns the squared sine and
        cosine of the azimuth in a reference spherical coordinate system (see
        the Frame description)
        """

    @property
    def s(self) -> Vector3f: ...

    @s.setter
    def s(self, arg: Vector3f, /) -> None: ...

    @property
    def t(self) -> Vector3f: ...

    @t.setter
    def t(self, arg: Vector3f, /) -> None: ...

    @property
    def n(self) -> Normal3f: ...

    @n.setter
    def n(self, arg: Normal3f, /) -> None: ...

    def __repr__(self) -> str: ...

    def assign(self, arg: Frame3f, /) -> None: ...

    def __setitem__(self, arg0: drjit.auto.ad.Bool, arg1: Frame3f, /) -> None: ...

class Hierarchical2D0:
    """
    Implements a hierarchical sample warping scheme for 2D distributions
    with linear interpolation and an optional dependence on additional
    parameters

    This class takes a rectangular floating point array as input and
    constructs internal data structures to efficiently map uniform
    variates from the unit square ``[0, 1]^2`` to a function on ``[0,
    1]^2`` that linearly interpolates the input array.

    The mapping is constructed from a sequence of ``log2(max(res))``
    hierarchical sample warping steps, where ``res`` is the input array
    resolution. It is bijective and generally very well-behaved (i.e. low
    distortion), which makes it a good choice for structured point sets
    such as the Halton or Sobol sequence.

    The implementation also supports *conditional distributions*, i.e. 2D
    distributions that depend on an arbitrary number of parameters
    (indicated via the ``Dimension`` template parameter).

    In this case, the input array should have dimensions ``N0 x N1 x ... x
    Nn x res.y() x res.x()`` (where the last dimension is contiguous in
    memory), and the ``param_res`` should be set to ``{ N0, N1, ..., Nn
    }``, and ``param_values`` should contain the parameter values where
    the distribution is discretized. Linear interpolation is used when
    sampling or evaluating the distribution for in-between parameter
    values.

    Remark:
        The Python API exposes explicitly instantiated versions of this
        class named Hierarchical2D0, Hierarchical2D1, and Hierarchical2D2
        for data that depends on 0, 1, and 2 parameters, respectively.
    """

    def __init__(self, data: Annotated[ArrayLike, dict(dtype='float32', shape=(None, None), order='C')], param_values: Sequence[Sequence[float]] = [], normalize: bool = True, enable_sampling: bool = True) -> None:
        """
        Construct a hierarchical sample warping scheme for floating point data
        of resolution ``size``.

        ``param_res`` and ``param_values`` are only needed for conditional
        distributions (see the text describing the Hierarchical2D class).

        If ``normalize`` is set to ``False``, the implementation will not re-
        scale the distribution so that it integrates to ``1``. It can still be
        sampled (proportionally), but returned density values will reflect the
        unnormalized values.

        If ``enable_sampling`` is set to ``False``, the implementation will
        not construct the hierarchy needed for sample warping, which saves
        memory in case this functionality is not needed (e.g. if only the
        interpolation in ``eval()`` is used). In this case, ``sample()`` and
        ``invert()`` can still be called without triggering undefined
        behavior, but they will not return meaningful results.
        """

    def sample(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array0f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """
        Given a uniformly distributed 2D sample, draw a sample from the
        distribution (parameterized by ``param`` if applicable)

        Returns the warped sample and associated probability density.
        """

    def invert(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array0f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """Inverse of the mapping implemented in ``sample()``"""

    def eval(self, pos: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array0f = ..., active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the density at position ``pos``. The distribution is
        parameterized by ``param`` if applicable.
        """

    def __repr__(self) -> str: ...

class Hierarchical2D1:
    """
    Implements a hierarchical sample warping scheme for 2D distributions
    with linear interpolation and an optional dependence on additional
    parameters

    This class takes a rectangular floating point array as input and
    constructs internal data structures to efficiently map uniform
    variates from the unit square ``[0, 1]^2`` to a function on ``[0,
    1]^2`` that linearly interpolates the input array.

    The mapping is constructed from a sequence of ``log2(max(res))``
    hierarchical sample warping steps, where ``res`` is the input array
    resolution. It is bijective and generally very well-behaved (i.e. low
    distortion), which makes it a good choice for structured point sets
    such as the Halton or Sobol sequence.

    The implementation also supports *conditional distributions*, i.e. 2D
    distributions that depend on an arbitrary number of parameters
    (indicated via the ``Dimension`` template parameter).

    In this case, the input array should have dimensions ``N0 x N1 x ... x
    Nn x res.y() x res.x()`` (where the last dimension is contiguous in
    memory), and the ``param_res`` should be set to ``{ N0, N1, ..., Nn
    }``, and ``param_values`` should contain the parameter values where
    the distribution is discretized. Linear interpolation is used when
    sampling or evaluating the distribution for in-between parameter
    values.

    Remark:
        The Python API exposes explicitly instantiated versions of this
        class named Hierarchical2D0, Hierarchical2D1, and Hierarchical2D2
        for data that depends on 0, 1, and 2 parameters, respectively.
    """

    def __init__(self, data: Annotated[ArrayLike, dict(dtype='float32', shape=(None, None, None), order='C')], param_values: Sequence[Sequence[float]], normalize: bool = True, build_hierarchy: bool = True) -> None:
        """
        Construct a hierarchical sample warping scheme for floating point data
        of resolution ``size``.

        ``param_res`` and ``param_values`` are only needed for conditional
        distributions (see the text describing the Hierarchical2D class).

        If ``normalize`` is set to ``False``, the implementation will not re-
        scale the distribution so that it integrates to ``1``. It can still be
        sampled (proportionally), but returned density values will reflect the
        unnormalized values.

        If ``enable_sampling`` is set to ``False``, the implementation will
        not construct the hierarchy needed for sample warping, which saves
        memory in case this functionality is not needed (e.g. if only the
        interpolation in ``eval()`` is used). In this case, ``sample()`` and
        ``invert()`` can still be called without triggering undefined
        behavior, but they will not return meaningful results.
        """

    def sample(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array1f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """
        Given a uniformly distributed 2D sample, draw a sample from the
        distribution (parameterized by ``param`` if applicable)

        Returns the warped sample and associated probability density.
        """

    def invert(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array1f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """Inverse of the mapping implemented in ``sample()``"""

    def eval(self, pos: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array1f = ..., active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the density at position ``pos``. The distribution is
        parameterized by ``param`` if applicable.
        """

    def __repr__(self) -> str: ...

class Hierarchical2D2:
    """
    Implements a hierarchical sample warping scheme for 2D distributions
    with linear interpolation and an optional dependence on additional
    parameters

    This class takes a rectangular floating point array as input and
    constructs internal data structures to efficiently map uniform
    variates from the unit square ``[0, 1]^2`` to a function on ``[0,
    1]^2`` that linearly interpolates the input array.

    The mapping is constructed from a sequence of ``log2(max(res))``
    hierarchical sample warping steps, where ``res`` is the input array
    resolution. It is bijective and generally very well-behaved (i.e. low
    distortion), which makes it a good choice for structured point sets
    such as the Halton or Sobol sequence.

    The implementation also supports *conditional distributions*, i.e. 2D
    distributions that depend on an arbitrary number of parameters
    (indicated via the ``Dimension`` template parameter).

    In this case, the input array should have dimensions ``N0 x N1 x ... x
    Nn x res.y() x res.x()`` (where the last dimension is contiguous in
    memory), and the ``param_res`` should be set to ``{ N0, N1, ..., Nn
    }``, and ``param_values`` should contain the parameter values where
    the distribution is discretized. Linear interpolation is used when
    sampling or evaluating the distribution for in-between parameter
    values.

    Remark:
        The Python API exposes explicitly instantiated versions of this
        class named Hierarchical2D0, Hierarchical2D1, and Hierarchical2D2
        for data that depends on 0, 1, and 2 parameters, respectively.
    """

    def __init__(self, data: Annotated[ArrayLike, dict(dtype='float32', shape=(None, None, None, None), order='C')], param_values: Sequence[Sequence[float]], normalize: bool = True, build_hierarchy: bool = True) -> None:
        """
        Construct a hierarchical sample warping scheme for floating point data
        of resolution ``size``.

        ``param_res`` and ``param_values`` are only needed for conditional
        distributions (see the text describing the Hierarchical2D class).

        If ``normalize`` is set to ``False``, the implementation will not re-
        scale the distribution so that it integrates to ``1``. It can still be
        sampled (proportionally), but returned density values will reflect the
        unnormalized values.

        If ``enable_sampling`` is set to ``False``, the implementation will
        not construct the hierarchy needed for sample warping, which saves
        memory in case this functionality is not needed (e.g. if only the
        interpolation in ``eval()`` is used). In this case, ``sample()`` and
        ``invert()`` can still be called without triggering undefined
        behavior, but they will not return meaningful results.
        """

    def sample(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array2f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """
        Given a uniformly distributed 2D sample, draw a sample from the
        distribution (parameterized by ``param`` if applicable)

        Returns the warped sample and associated probability density.
        """

    def invert(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array2f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """Inverse of the mapping implemented in ``sample()``"""

    def eval(self, pos: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array2f = ..., active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the density at position ``pos``. The distribution is
        parameterized by ``param`` if applicable.
        """

    def __repr__(self) -> str: ...

class Hierarchical2D3:
    """
    Implements a hierarchical sample warping scheme for 2D distributions
    with linear interpolation and an optional dependence on additional
    parameters

    This class takes a rectangular floating point array as input and
    constructs internal data structures to efficiently map uniform
    variates from the unit square ``[0, 1]^2`` to a function on ``[0,
    1]^2`` that linearly interpolates the input array.

    The mapping is constructed from a sequence of ``log2(max(res))``
    hierarchical sample warping steps, where ``res`` is the input array
    resolution. It is bijective and generally very well-behaved (i.e. low
    distortion), which makes it a good choice for structured point sets
    such as the Halton or Sobol sequence.

    The implementation also supports *conditional distributions*, i.e. 2D
    distributions that depend on an arbitrary number of parameters
    (indicated via the ``Dimension`` template parameter).

    In this case, the input array should have dimensions ``N0 x N1 x ... x
    Nn x res.y() x res.x()`` (where the last dimension is contiguous in
    memory), and the ``param_res`` should be set to ``{ N0, N1, ..., Nn
    }``, and ``param_values`` should contain the parameter values where
    the distribution is discretized. Linear interpolation is used when
    sampling or evaluating the distribution for in-between parameter
    values.

    Remark:
        The Python API exposes explicitly instantiated versions of this
        class named Hierarchical2D0, Hierarchical2D1, and Hierarchical2D2
        for data that depends on 0, 1, and 2 parameters, respectively.
    """

    def __init__(self, data: Annotated[ArrayLike, dict(dtype='float32', shape=(None, None, None, None, None), order='C')], param_values: Sequence[Sequence[float]], normalize: bool = True, build_hierarchy: bool = True) -> None:
        """
        Construct a hierarchical sample warping scheme for floating point data
        of resolution ``size``.

        ``param_res`` and ``param_values`` are only needed for conditional
        distributions (see the text describing the Hierarchical2D class).

        If ``normalize`` is set to ``False``, the implementation will not re-
        scale the distribution so that it integrates to ``1``. It can still be
        sampled (proportionally), but returned density values will reflect the
        unnormalized values.

        If ``enable_sampling`` is set to ``False``, the implementation will
        not construct the hierarchy needed for sample warping, which saves
        memory in case this functionality is not needed (e.g. if only the
        interpolation in ``eval()`` is used). In this case, ``sample()`` and
        ``invert()`` can still be called without triggering undefined
        behavior, but they will not return meaningful results.
        """

    def sample(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array3f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """
        Given a uniformly distributed 2D sample, draw a sample from the
        distribution (parameterized by ``param`` if applicable)

        Returns the warped sample and associated probability density.
        """

    def invert(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array3f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """Inverse of the mapping implemented in ``sample()``"""

    def eval(self, pos: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array3f = ..., active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the density at position ``pos``. The distribution is
        parameterized by ``param`` if applicable.
        """

    def __repr__(self) -> str: ...

class ImageBlock(Object):
    """
    Intermediate storage for an image or image sub-region being rendered

    This class facilitates parallel rendering of images in both scalar and
    JIT-based variants of Mitsuba.

    In scalar mode, image blocks represent independent rectangular image
    regions that are simultaneously processed by worker threads. They are
    finally merged into a master ImageBlock controlled by the Film
    instance via the put_block() method. The smaller image blocks can
    include a border region storing contributions that are slightly
    outside of the block, which is required to correctly account for image
    reconstruction filters.

    In JIT variants there is only a single ImageBlock, whose contents are
    computed in parallel. A border region is usually not needed in this
    case.

    In addition to receiving samples via the put() method, the image block
    can also be queried via the read() method, in which case the
    reconstruction filter is used to compute suitable interpolation
    weights. This is feature is useful for differentiable rendering, where
    one needs to evaluate the reverse-mode derivative of the put() method.
    """

    @overload
    def __init__(self, size: ScalarVector2u, offset: ScalarPoint2i, channel_count: int, rfilter: BitmapReconstructionFilter | None = None, border: bool = True, normalize: bool = False, coalesce: bool = False, compensate: bool = False, warn_negative: bool = True, warn_invalid: bool = True) -> None: ...

    @overload
    def __init__(self, tensor: drjit.scalar.TensorXf, offset: ScalarPoint2i = ..., rfilter: BitmapReconstructionFilter | None = None, border: bool = True, normalize: bool = False, coalesce: bool = False, compensate: bool = False, warn_negative: bool = True, warn_invalid: bool = True) -> None: ...

    def put_block(self, block: ImageBlock) -> None:
        """Accumulate another image block into this one"""

    @overload
    def put(self, pos: ScalarPoint2f, wavelengths: ScalarColor0f, value: ScalarColor3f, alpha: float = 1.0, weight: float = 1, active: bool = True) -> None:
        """
        Accumulate a single sample or a wavefront of samples into the image
        block.

        Parameter ``pos``:
            Denotes the sample position in fractional pixel coordinates

        Parameter ``values``:
            Points to an array of length channel_count(), which specifies the
            sample value for each channel.
        """

    @overload
    def put(self, pos: ScalarPoint2f, values: Sequence[float], active: bool = True) -> None: ...

    def read(self, pos: ScalarPoint2f, active: bool = True) -> list[float]: ...

    def clear(self) -> None:
        """Clear the image block contents to zero."""

    def offset(self) -> ScalarPoint2i:
        """Return the current block offset"""

    def set_offset(self, offset: ScalarPoint2i) -> None:
        """
        Set the current block offset.

        This corresponds to the offset from the top-left corner of a larger
        image (e.g. a Film) to the top-left corner of this ImageBlock
        instance.
        """

    def size(self) -> ScalarVector2u:
        """Return the current block size"""

    def set_size(self, size: ScalarVector2u) -> None:
        """Set the block size. This potentially destroys the block's content."""

    def coalesce(self) -> bool:
        """Try to coalesce reads/writes in JIT modes?"""

    def set_coalesce(self, arg: bool, /) -> None:
        """Try to coalesce reads/writes in JIT modes?"""

    def compensate(self) -> bool:
        """Use Kahan-style error-compensated floating point accumulation?"""

    def set_compensate(self, arg: bool, /) -> None:
        """Use Kahan-style error-compensated floating point accumulation?"""

    def width(self) -> int:
        """Return the bitmap's width in pixels"""

    def height(self) -> int:
        """Return the bitmap's height in pixels"""

    def rfilter(self) -> BitmapReconstructionFilter:
        """Return the image reconstruction filter underlying the ImageBlock"""

    def normalize(self) -> bool:
        """Re-normalize filter weights in put() and read()"""

    def set_normalize(self, arg: bool, /) -> None:
        """Re-normalize filter weights in put() and read()"""

    def warn_invalid(self) -> bool:
        """Warn when writing invalid (NaN, +/- infinity) sample values?"""

    def warn_negative(self) -> bool:
        """Warn when writing negative sample values?"""

    def set_warn_invalid(self, value: bool) -> None:
        """Warn when writing invalid (NaN, +/- infinity) sample values?"""

    def set_warn_negative(self, value: bool) -> None:
        """Warn when writing negative sample values?"""

    def border_size(self) -> int:
        """Return the border region used by the reconstruction filter"""

    def has_border(self) -> bool:
        """Does the image block have a border region?"""

    def channel_count(self) -> int:
        """Return the number of channels stored by the image block"""

    def tensor(self) -> drjit.scalar.TensorXf:
        """Return the underlying image tensor"""

class Integrator(Object):
    """
    Abstract integrator base class, which does not make any assumptions
    with regards to how radiance is computed.

    In Mitsuba, the different rendering techniques are collectively
    referred to as *integrators*, since they perform integration over a
    high-dimensional space. Each integrator represents a specific approach
    for solving the light transport equation---usually favored in certain
    scenarios, but at the same time affected by its own set of intrinsic
    limitations. Therefore, it is important to carefully select an
    integrator based on user-specified accuracy requirements and
    properties of the scene to be rendered.

    This is the base class of all integrators; it does not make any
    assumptions on how radiance is computed, which allows for many
    different kinds of implementations.
    """

    @overload
    def render(self, scene: Scene, sensor: Sensor, seed: int = 0, spp: int = 0, develop: bool = True, evaluate: bool = True) -> drjit.scalar.TensorXf:
        """
        Render the scene

        This function renders the scene from the viewpoint of ``sensor``. All
        other parameters are optional and control different aspects of the
        rendering process. In particular:

        Parameter ``seed``:
            This parameter controls the initialization of the random number
            generator. It is crucial that you specify different seeds (e.g.,
            an increasing sequence) if subsequent ``render``() calls should
            produce statistically independent images.

        Parameter ``spp``:
            Set this parameter to a nonzero value to override the number of
            samples per pixel. This value then takes precedence over whatever
            was specified in the construction of ``sensor->sampler()``. This
            parameter may be useful in research applications where an image
            must be rendered multiple times using different quality levels.

        Parameter ``develop``:
            If set to ``True``, the implementation post-processes the data
            stored in ``sensor->film()``, returning the resulting image as a
            TensorXf. Otherwise, it returns an empty tensor.

        Parameter ``evaluate``:
            This parameter is only relevant for JIT variants of Mitsuba (LLVM,
            CUDA). If set to ``True``, the rendering step evaluates the
            generated image and waits for its completion. A log message also
            denotes the rendering time. Otherwise, the returned tensor
            (``develop=true``) or modified film (``develop=false``) represent
            the rendering task as an unevaluated computation graph.
        """

    @overload
    def render(self, scene: Scene, sensor: int = 0, seed: int = 0, spp: int = 0, develop: bool = True, evaluate: bool = True) -> drjit.scalar.TensorXf:
        """
        Render the scene

        This function is just a thin wrapper around the previous render()
        overload. It accepts a sensor *index* instead and renders the scene
        using sensor 0 by default.
        """

    def cancel(self) -> None:
        """Cancel a running render job (e.g. after receiving Ctrl-C)"""

    def should_stop(self) -> bool:
        """
        Indicates whether cancel() or a timeout have occurred. Should be
        checked regularly in the integrator's main loop so that timeouts are
        enforced accurately.

        Note that accurate timeouts rely on m_render_timer, which needs to be
        reset at the beginning of the rendering phase.
        """

    def aov_names(self) -> list[str]:
        """
        For integrators that return one or more arbitrary output variables
        (AOVs), this function specifies a list of associated channel names.
        The default implementation simply returns an empty vector.
        """

class Interaction3f:
    """Generic surface interaction data structure"""

    @overload
    def __init__(self) -> None:
        """Constructor"""

    @overload
    def __init__(self, arg: Interaction3f) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, t: float, time: float, wavelengths: ScalarColor0f, p: ScalarPoint3f, n: ScalarNormal3f = 0) -> None:
        """//! @}"""

    @property
    def t(self) -> float:
        """Distance traveled along the ray"""

    @t.setter
    def t(self, arg: float, /) -> None: ...

    @property
    def time(self) -> float:
        """Time value associated with the interaction"""

    @time.setter
    def time(self, arg: float, /) -> None: ...

    @property
    def wavelengths(self) -> ScalarColor0f:
        """Wavelengths associated with the ray that produced this interaction"""

    @wavelengths.setter
    def wavelengths(self, arg: ScalarColor0f, /) -> None: ...

    @property
    def p(self) -> ScalarPoint3f:
        """Position of the interaction in world coordinates"""

    @p.setter
    def p(self, arg: ScalarPoint3f, /) -> None: ...

    @property
    def n(self) -> ScalarNormal3f:
        """Geometric normal (only valid for ``SurfaceInteraction``)"""

    @n.setter
    def n(self, arg: ScalarNormal3f, /) -> None: ...

    def spawn_ray(self, d: ScalarVector3f) -> Ray3f:
        """Spawn a semi-infinite ray towards the given direction"""

    def spawn_ray_to(self, t: ScalarPoint3f) -> Ray3f:
        """Spawn a finite ray towards the given position"""

    def is_valid(self) -> bool:
        """Is the current interaction valid?"""

    def __repr__(self) -> str: ...

class IrregularContinuousDistribution:
    """
    Continuous 1D probability distribution defined in terms of an
    *irregularly* sampled linear interpolant

    This data structure represents a continuous 1D probability
    distribution that is defined as a linear interpolant of an irregularly
    discretized signal. The class provides various routines for
    transforming uniformly distributed samples so that they follow the
    stored distribution. Note that unnormalized probability density
    functions (PDFs) will automatically be normalized during
    initialization. The associated scale factor can be retrieved using the
    function normalization().
    """

    @overload
    def __init__(self) -> None:
        """
        Continuous 1D probability distribution defined in terms of an
        *irregularly* sampled linear interpolant

        This data structure represents a continuous 1D probability
        distribution that is defined as a linear interpolant of an irregularly
        discretized signal. The class provides various routines for
        transforming uniformly distributed samples so that they follow the
        stored distribution. Note that unnormalized probability density
        functions (PDFs) will automatically be normalized during
        initialization. The associated scale factor can be retrieved using the
        function normalization().
        """

    @overload
    def __init__(self, arg: IrregularContinuousDistribution) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, nodes: drjit.auto.ad.Float, pdf: drjit.auto.ad.Float) -> None:
        """
        Initialize from a given density function discretized on nodes
        ``nodes``
        """

    def __len__(self) -> int: ...

    def size(self) -> int:
        """Return the number of discretizations"""

    def empty(self) -> bool:
        """Is the distribution object empty/uninitialized?"""

    @property
    def range(self) -> drjit.scalar.Array2f:
        """Return the range of the distribution"""

    @range.setter
    def range(self, arg: ScalarVector2f, /) -> None: ...

    @property
    def nodes(self) -> drjit.auto.ad.Float:
        """Return the nodes of the underlying discretization"""

    @nodes.setter
    def nodes(self, arg: drjit.auto.ad.Float, /) -> None: ...

    @property
    def pdf(self) -> drjit.auto.ad.Float:
        """Return the nodes of the underlying discretization"""

    @pdf.setter
    def pdf(self, arg: drjit.auto.ad.Float, /) -> None: ...

    @property
    def cdf(self) -> drjit.auto.ad.Float:
        """Return the nodes of the underlying discretization"""

    @cdf.setter
    def cdf(self, arg: drjit.auto.ad.Float, /) -> None: ...

    def eval_pdf(self, x: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the unnormalized probability mass function (PDF) at position
        ``x``
        """

    def eval_pdf_normalized(self, x: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the normalized probability mass function (PDF) at position
        ``x``
        """

    def eval_cdf(self, x: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the unnormalized cumulative distribution function (CDF) at
        position ``p``
        """

    def eval_cdf_normalized(self, x: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the unnormalized cumulative distribution function (CDF) at
        position ``p``
        """

    def update(self) -> None:
        """
        Update the internal state. Must be invoked when changing the pdf or
        range.
        """

    def integral(self) -> drjit.auto.ad.Float:
        """Return the original integral of PDF entries before normalization"""

    def normalization(self) -> drjit.auto.ad.Float:
        """Return the normalization factor (i.e. the inverse of sum())"""

    def interval_resolution(self) -> float:
        """Return the minimum resolution of the discretization"""

    def max(self) -> float: ...

    def sample(self, value: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        %Transform a uniformly distributed sample to the stored distribution

        Parameter ``sample``:
            A uniformly distributed sample on the interval [0, 1].

        Returns:
            The sampled position.
        """

    def sample_pdf(self, value: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> tuple[drjit.auto.ad.Float, drjit.auto.ad.Float]:
        """
        %Transform a uniformly distributed sample to the stored distribution

        Parameter ``sample``:
            A uniformly distributed sample on the interval [0, 1].

        Returns:
            A tuple consisting of

        1. the sampled position. 2. the normalized probability density of the
        sample.
        """

    def __repr__(self) -> str: ...

class LogLevel(enum.IntEnum):
    """Available Log message types"""

    Trace = 0

    Debug = 100
    """Trace message, for extremely verbose debugging"""

    Info = 200
    """Debug message, usually turned off"""

    Warn = 300
    """More relevant debug / information message"""

    Error = 400
    """Warning message"""

class Logger(Object):
    """
    Responsible for processing log messages

    Upon receiving a log message, the Logger class invokes a Formatter to
    convert it into a human-readable form. Following that, it sends this
    information to every registered Appender.
    """

    def __init__(self, arg: LogLevel, /) -> None:
        """Construct a new logger with the given minimum log level"""

    def log_progress(self, progress: float, name: str, formatted: str, eta: str, ptr: object | None = None) -> None:
        """
        Process a progress message

        Parameter ``progress``:
            Percentage value in [0, 100]

        Parameter ``name``:
            Title of the progress message

        Parameter ``formatted``:
            Formatted string representation of the message

        Parameter ``eta``:
            Estimated time until 100% is reached.

        Parameter ``ptr``:
            Custom pointer payload. This is used to express the context of a
            progress message. When rendering a scene, it will usually contain
            a pointer to the associated ``RenderJob``.
        """

    def set_log_level(self, arg: LogLevel, /) -> None:
        """Set the log level (everything below will be ignored)"""

    def log_level(self) -> LogLevel:
        """Return the current log level"""

    def set_error_level(self, arg: LogLevel, /) -> None:
        """
        Set the error log level (this level and anything above will throw
        exceptions).

        The value provided here can be used for instance to turn warnings into
        errors. But *level* must always be less than Error, i.e. it isn't
        possible to cause errors not to throw an exception.
        """

    def error_level(self) -> LogLevel:
        """Return the current error level"""

    def add_appender(self, arg: Appender, /) -> None:
        """Add an appender to this logger"""

    def remove_appender(self, arg: Appender, /) -> None:
        """Remove an appender from this logger"""

    def clear_appenders(self) -> None:
        """Remove all appenders from this logger"""

    def appender_count(self) -> int:
        """Return the number of registered appenders"""

    def appender(self, arg: int, /) -> Appender:
        """Return one of the appenders"""

    def formatter(self) -> Formatter:
        """Return the logger's formatter implementation"""

    def set_formatter(self, arg: Formatter, /) -> None:
        """Set the logger's formatter implementation"""

    def read_log(self) -> str:
        """
        Return the contents of the log file as a string

        Throws a runtime exception upon failure
        """

MI_CIE_D65_NORMALIZATION: float = 0.010101273599490354

MI_CIE_MAX: float = 830.0

MI_CIE_MIN: float = 360.0

MI_CIE_Y_NORMALIZATION: float = 0.009367658735689113

MI_WAVELENGTH_SAMPLES: int = 4

class MarginalContinuous2D0:
    """
    Implements a marginal sample warping scheme for 2D distributions with
    linear interpolation and an optional dependence on additional
    parameters

    This class takes a rectangular floating point array as input and
    constructs internal data structures to efficiently map uniform
    variates from the unit square ``[0, 1]^2`` to a function on ``[0,
    1]^2`` that linearly interpolates the input array.

    The mapping is constructed via the inversion method, which is applied
    to a marginal distribution over rows, followed by a conditional
    distribution over columns.

    The implementation also supports *conditional distributions*, i.e. 2D
    distributions that depend on an arbitrary number of parameters
    (indicated via the ``Dimension`` template parameter).

    In this case, the input array should have dimensions ``N0 x N1 x ... x
    Nn x res.y() x res.x()`` (where the last dimension is contiguous in
    memory), and the ``param_res`` should be set to ``{ N0, N1, ..., Nn
    }``, and ``param_values`` should contain the parameter values where
    the distribution is discretized. Linear interpolation is used when
    sampling or evaluating the distribution for in-between parameter
    values.

    There are two variants of ``Marginal2D:`` when ``Continuous=false``,
    discrete marginal/conditional distributions are used to select a
    bilinear bilinear patch, followed by a continuous sampling step that
    chooses a specific position inside the patch. When
    ``Continuous=true``, continuous marginal/conditional distributions are
    used instead, and the second step is no longer needed. The latter
    scheme requires more computation and memory accesses but produces an
    overall smoother mapping.

    Remark:
        The Python API exposes explicitly instantiated versions of this
        class named ``MarginalDiscrete2D0`` to ``MarginalDiscrete2D3`` and
        ``MarginalContinuous2D0`` to ``MarginalContinuous2D3`` for data
        that depends on 0 to 3 parameters.
    """

    def __init__(self, data: Annotated[ArrayLike, dict(dtype='float32', shape=(None, None), order='C')], param_values: Sequence[Sequence[float]] = [], normalize: bool = True, enable_sampling: bool = True) -> None:
        """
        Construct a marginal sample warping scheme for floating point data of
        resolution ``size``.

        ``param_res`` and ``param_values`` are only needed for conditional
        distributions (see the text describing the Marginal2D class).

        If ``normalize`` is set to ``False``, the implementation will not re-
        scale the distribution so that it integrates to ``1``. It can still be
        sampled (proportionally), but returned density values will reflect the
        unnormalized values.

        If ``enable_sampling`` is set to ``False``, the implementation will
        not construct the cdf needed for sample warping, which saves memory in
        case this functionality is not needed (e.g. if only the interpolation
        in ``eval()`` is used).
        """

    def sample(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array0f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """
        Given a uniformly distributed 2D sample, draw a sample from the
        distribution (parameterized by ``param`` if applicable)

        Returns the warped sample and associated probability density.
        """

    def invert(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array0f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """Inverse of the mapping implemented in ``sample()``"""

    def eval(self, pos: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array0f = ..., active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the density at position ``pos``. The distribution is
        parameterized by ``param`` if applicable.
        """

    def __repr__(self) -> str: ...

class MarginalContinuous2D1:
    """
    Implements a marginal sample warping scheme for 2D distributions with
    linear interpolation and an optional dependence on additional
    parameters

    This class takes a rectangular floating point array as input and
    constructs internal data structures to efficiently map uniform
    variates from the unit square ``[0, 1]^2`` to a function on ``[0,
    1]^2`` that linearly interpolates the input array.

    The mapping is constructed via the inversion method, which is applied
    to a marginal distribution over rows, followed by a conditional
    distribution over columns.

    The implementation also supports *conditional distributions*, i.e. 2D
    distributions that depend on an arbitrary number of parameters
    (indicated via the ``Dimension`` template parameter).

    In this case, the input array should have dimensions ``N0 x N1 x ... x
    Nn x res.y() x res.x()`` (where the last dimension is contiguous in
    memory), and the ``param_res`` should be set to ``{ N0, N1, ..., Nn
    }``, and ``param_values`` should contain the parameter values where
    the distribution is discretized. Linear interpolation is used when
    sampling or evaluating the distribution for in-between parameter
    values.

    There are two variants of ``Marginal2D:`` when ``Continuous=false``,
    discrete marginal/conditional distributions are used to select a
    bilinear bilinear patch, followed by a continuous sampling step that
    chooses a specific position inside the patch. When
    ``Continuous=true``, continuous marginal/conditional distributions are
    used instead, and the second step is no longer needed. The latter
    scheme requires more computation and memory accesses but produces an
    overall smoother mapping.

    Remark:
        The Python API exposes explicitly instantiated versions of this
        class named ``MarginalDiscrete2D0`` to ``MarginalDiscrete2D3`` and
        ``MarginalContinuous2D0`` to ``MarginalContinuous2D3`` for data
        that depends on 0 to 3 parameters.
    """

    def __init__(self, data: Annotated[ArrayLike, dict(dtype='float32', shape=(None, None, None), order='C')], param_values: Sequence[Sequence[float]], normalize: bool = True, build_hierarchy: bool = True) -> None:
        """
        Construct a marginal sample warping scheme for floating point data of
        resolution ``size``.

        ``param_res`` and ``param_values`` are only needed for conditional
        distributions (see the text describing the Marginal2D class).

        If ``normalize`` is set to ``False``, the implementation will not re-
        scale the distribution so that it integrates to ``1``. It can still be
        sampled (proportionally), but returned density values will reflect the
        unnormalized values.

        If ``enable_sampling`` is set to ``False``, the implementation will
        not construct the cdf needed for sample warping, which saves memory in
        case this functionality is not needed (e.g. if only the interpolation
        in ``eval()`` is used).
        """

    def sample(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array1f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """
        Given a uniformly distributed 2D sample, draw a sample from the
        distribution (parameterized by ``param`` if applicable)

        Returns the warped sample and associated probability density.
        """

    def invert(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array1f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """Inverse of the mapping implemented in ``sample()``"""

    def eval(self, pos: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array1f = ..., active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the density at position ``pos``. The distribution is
        parameterized by ``param`` if applicable.
        """

    def __repr__(self) -> str: ...

class MarginalContinuous2D2:
    """
    Implements a marginal sample warping scheme for 2D distributions with
    linear interpolation and an optional dependence on additional
    parameters

    This class takes a rectangular floating point array as input and
    constructs internal data structures to efficiently map uniform
    variates from the unit square ``[0, 1]^2`` to a function on ``[0,
    1]^2`` that linearly interpolates the input array.

    The mapping is constructed via the inversion method, which is applied
    to a marginal distribution over rows, followed by a conditional
    distribution over columns.

    The implementation also supports *conditional distributions*, i.e. 2D
    distributions that depend on an arbitrary number of parameters
    (indicated via the ``Dimension`` template parameter).

    In this case, the input array should have dimensions ``N0 x N1 x ... x
    Nn x res.y() x res.x()`` (where the last dimension is contiguous in
    memory), and the ``param_res`` should be set to ``{ N0, N1, ..., Nn
    }``, and ``param_values`` should contain the parameter values where
    the distribution is discretized. Linear interpolation is used when
    sampling or evaluating the distribution for in-between parameter
    values.

    There are two variants of ``Marginal2D:`` when ``Continuous=false``,
    discrete marginal/conditional distributions are used to select a
    bilinear bilinear patch, followed by a continuous sampling step that
    chooses a specific position inside the patch. When
    ``Continuous=true``, continuous marginal/conditional distributions are
    used instead, and the second step is no longer needed. The latter
    scheme requires more computation and memory accesses but produces an
    overall smoother mapping.

    Remark:
        The Python API exposes explicitly instantiated versions of this
        class named ``MarginalDiscrete2D0`` to ``MarginalDiscrete2D3`` and
        ``MarginalContinuous2D0`` to ``MarginalContinuous2D3`` for data
        that depends on 0 to 3 parameters.
    """

    def __init__(self, data: Annotated[ArrayLike, dict(dtype='float32', shape=(None, None, None, None), order='C')], param_values: Sequence[Sequence[float]], normalize: bool = True, build_hierarchy: bool = True) -> None:
        """
        Construct a marginal sample warping scheme for floating point data of
        resolution ``size``.

        ``param_res`` and ``param_values`` are only needed for conditional
        distributions (see the text describing the Marginal2D class).

        If ``normalize`` is set to ``False``, the implementation will not re-
        scale the distribution so that it integrates to ``1``. It can still be
        sampled (proportionally), but returned density values will reflect the
        unnormalized values.

        If ``enable_sampling`` is set to ``False``, the implementation will
        not construct the cdf needed for sample warping, which saves memory in
        case this functionality is not needed (e.g. if only the interpolation
        in ``eval()`` is used).
        """

    def sample(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array2f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """
        Given a uniformly distributed 2D sample, draw a sample from the
        distribution (parameterized by ``param`` if applicable)

        Returns the warped sample and associated probability density.
        """

    def invert(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array2f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """Inverse of the mapping implemented in ``sample()``"""

    def eval(self, pos: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array2f = ..., active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the density at position ``pos``. The distribution is
        parameterized by ``param`` if applicable.
        """

    def __repr__(self) -> str: ...

class MarginalContinuous2D3:
    """
    Implements a marginal sample warping scheme for 2D distributions with
    linear interpolation and an optional dependence on additional
    parameters

    This class takes a rectangular floating point array as input and
    constructs internal data structures to efficiently map uniform
    variates from the unit square ``[0, 1]^2`` to a function on ``[0,
    1]^2`` that linearly interpolates the input array.

    The mapping is constructed via the inversion method, which is applied
    to a marginal distribution over rows, followed by a conditional
    distribution over columns.

    The implementation also supports *conditional distributions*, i.e. 2D
    distributions that depend on an arbitrary number of parameters
    (indicated via the ``Dimension`` template parameter).

    In this case, the input array should have dimensions ``N0 x N1 x ... x
    Nn x res.y() x res.x()`` (where the last dimension is contiguous in
    memory), and the ``param_res`` should be set to ``{ N0, N1, ..., Nn
    }``, and ``param_values`` should contain the parameter values where
    the distribution is discretized. Linear interpolation is used when
    sampling or evaluating the distribution for in-between parameter
    values.

    There are two variants of ``Marginal2D:`` when ``Continuous=false``,
    discrete marginal/conditional distributions are used to select a
    bilinear bilinear patch, followed by a continuous sampling step that
    chooses a specific position inside the patch. When
    ``Continuous=true``, continuous marginal/conditional distributions are
    used instead, and the second step is no longer needed. The latter
    scheme requires more computation and memory accesses but produces an
    overall smoother mapping.

    Remark:
        The Python API exposes explicitly instantiated versions of this
        class named ``MarginalDiscrete2D0`` to ``MarginalDiscrete2D3`` and
        ``MarginalContinuous2D0`` to ``MarginalContinuous2D3`` for data
        that depends on 0 to 3 parameters.
    """

    def __init__(self, data: Annotated[ArrayLike, dict(dtype='float32', shape=(None, None, None, None, None), order='C')], param_values: Sequence[Sequence[float]], normalize: bool = True, build_hierarchy: bool = True) -> None:
        """
        Construct a marginal sample warping scheme for floating point data of
        resolution ``size``.

        ``param_res`` and ``param_values`` are only needed for conditional
        distributions (see the text describing the Marginal2D class).

        If ``normalize`` is set to ``False``, the implementation will not re-
        scale the distribution so that it integrates to ``1``. It can still be
        sampled (proportionally), but returned density values will reflect the
        unnormalized values.

        If ``enable_sampling`` is set to ``False``, the implementation will
        not construct the cdf needed for sample warping, which saves memory in
        case this functionality is not needed (e.g. if only the interpolation
        in ``eval()`` is used).
        """

    def sample(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array3f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """
        Given a uniformly distributed 2D sample, draw a sample from the
        distribution (parameterized by ``param`` if applicable)

        Returns the warped sample and associated probability density.
        """

    def invert(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array3f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """Inverse of the mapping implemented in ``sample()``"""

    def eval(self, pos: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array3f = ..., active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the density at position ``pos``. The distribution is
        parameterized by ``param`` if applicable.
        """

    def __repr__(self) -> str: ...

class MarginalDiscrete2D0:
    """
    Implements a marginal sample warping scheme for 2D distributions with
    linear interpolation and an optional dependence on additional
    parameters

    This class takes a rectangular floating point array as input and
    constructs internal data structures to efficiently map uniform
    variates from the unit square ``[0, 1]^2`` to a function on ``[0,
    1]^2`` that linearly interpolates the input array.

    The mapping is constructed via the inversion method, which is applied
    to a marginal distribution over rows, followed by a conditional
    distribution over columns.

    The implementation also supports *conditional distributions*, i.e. 2D
    distributions that depend on an arbitrary number of parameters
    (indicated via the ``Dimension`` template parameter).

    In this case, the input array should have dimensions ``N0 x N1 x ... x
    Nn x res.y() x res.x()`` (where the last dimension is contiguous in
    memory), and the ``param_res`` should be set to ``{ N0, N1, ..., Nn
    }``, and ``param_values`` should contain the parameter values where
    the distribution is discretized. Linear interpolation is used when
    sampling or evaluating the distribution for in-between parameter
    values.

    There are two variants of ``Marginal2D:`` when ``Continuous=false``,
    discrete marginal/conditional distributions are used to select a
    bilinear bilinear patch, followed by a continuous sampling step that
    chooses a specific position inside the patch. When
    ``Continuous=true``, continuous marginal/conditional distributions are
    used instead, and the second step is no longer needed. The latter
    scheme requires more computation and memory accesses but produces an
    overall smoother mapping.

    Remark:
        The Python API exposes explicitly instantiated versions of this
        class named ``MarginalDiscrete2D0`` to ``MarginalDiscrete2D3`` and
        ``MarginalContinuous2D0`` to ``MarginalContinuous2D3`` for data
        that depends on 0 to 3 parameters.
    """

    def __init__(self, data: Annotated[ArrayLike, dict(dtype='float32', shape=(None, None), order='C')], param_values: Sequence[Sequence[float]] = [], normalize: bool = True, enable_sampling: bool = True) -> None:
        """
        Construct a marginal sample warping scheme for floating point data of
        resolution ``size``.

        ``param_res`` and ``param_values`` are only needed for conditional
        distributions (see the text describing the Marginal2D class).

        If ``normalize`` is set to ``False``, the implementation will not re-
        scale the distribution so that it integrates to ``1``. It can still be
        sampled (proportionally), but returned density values will reflect the
        unnormalized values.

        If ``enable_sampling`` is set to ``False``, the implementation will
        not construct the cdf needed for sample warping, which saves memory in
        case this functionality is not needed (e.g. if only the interpolation
        in ``eval()`` is used).
        """

    def sample(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array0f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """
        Given a uniformly distributed 2D sample, draw a sample from the
        distribution (parameterized by ``param`` if applicable)

        Returns the warped sample and associated probability density.
        """

    def invert(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array0f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """Inverse of the mapping implemented in ``sample()``"""

    def eval(self, pos: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array0f = ..., active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the density at position ``pos``. The distribution is
        parameterized by ``param`` if applicable.
        """

    def __repr__(self) -> str: ...

class MarginalDiscrete2D1:
    """
    Implements a marginal sample warping scheme for 2D distributions with
    linear interpolation and an optional dependence on additional
    parameters

    This class takes a rectangular floating point array as input and
    constructs internal data structures to efficiently map uniform
    variates from the unit square ``[0, 1]^2`` to a function on ``[0,
    1]^2`` that linearly interpolates the input array.

    The mapping is constructed via the inversion method, which is applied
    to a marginal distribution over rows, followed by a conditional
    distribution over columns.

    The implementation also supports *conditional distributions*, i.e. 2D
    distributions that depend on an arbitrary number of parameters
    (indicated via the ``Dimension`` template parameter).

    In this case, the input array should have dimensions ``N0 x N1 x ... x
    Nn x res.y() x res.x()`` (where the last dimension is contiguous in
    memory), and the ``param_res`` should be set to ``{ N0, N1, ..., Nn
    }``, and ``param_values`` should contain the parameter values where
    the distribution is discretized. Linear interpolation is used when
    sampling or evaluating the distribution for in-between parameter
    values.

    There are two variants of ``Marginal2D:`` when ``Continuous=false``,
    discrete marginal/conditional distributions are used to select a
    bilinear bilinear patch, followed by a continuous sampling step that
    chooses a specific position inside the patch. When
    ``Continuous=true``, continuous marginal/conditional distributions are
    used instead, and the second step is no longer needed. The latter
    scheme requires more computation and memory accesses but produces an
    overall smoother mapping.

    Remark:
        The Python API exposes explicitly instantiated versions of this
        class named ``MarginalDiscrete2D0`` to ``MarginalDiscrete2D3`` and
        ``MarginalContinuous2D0`` to ``MarginalContinuous2D3`` for data
        that depends on 0 to 3 parameters.
    """

    def __init__(self, data: Annotated[ArrayLike, dict(dtype='float32', shape=(None, None, None), order='C')], param_values: Sequence[Sequence[float]], normalize: bool = True, build_hierarchy: bool = True) -> None:
        """
        Construct a marginal sample warping scheme for floating point data of
        resolution ``size``.

        ``param_res`` and ``param_values`` are only needed for conditional
        distributions (see the text describing the Marginal2D class).

        If ``normalize`` is set to ``False``, the implementation will not re-
        scale the distribution so that it integrates to ``1``. It can still be
        sampled (proportionally), but returned density values will reflect the
        unnormalized values.

        If ``enable_sampling`` is set to ``False``, the implementation will
        not construct the cdf needed for sample warping, which saves memory in
        case this functionality is not needed (e.g. if only the interpolation
        in ``eval()`` is used).
        """

    def sample(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array1f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """
        Given a uniformly distributed 2D sample, draw a sample from the
        distribution (parameterized by ``param`` if applicable)

        Returns the warped sample and associated probability density.
        """

    def invert(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array1f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """Inverse of the mapping implemented in ``sample()``"""

    def eval(self, pos: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array1f = ..., active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the density at position ``pos``. The distribution is
        parameterized by ``param`` if applicable.
        """

    def __repr__(self) -> str: ...

class MarginalDiscrete2D2:
    """
    Implements a marginal sample warping scheme for 2D distributions with
    linear interpolation and an optional dependence on additional
    parameters

    This class takes a rectangular floating point array as input and
    constructs internal data structures to efficiently map uniform
    variates from the unit square ``[0, 1]^2`` to a function on ``[0,
    1]^2`` that linearly interpolates the input array.

    The mapping is constructed via the inversion method, which is applied
    to a marginal distribution over rows, followed by a conditional
    distribution over columns.

    The implementation also supports *conditional distributions*, i.e. 2D
    distributions that depend on an arbitrary number of parameters
    (indicated via the ``Dimension`` template parameter).

    In this case, the input array should have dimensions ``N0 x N1 x ... x
    Nn x res.y() x res.x()`` (where the last dimension is contiguous in
    memory), and the ``param_res`` should be set to ``{ N0, N1, ..., Nn
    }``, and ``param_values`` should contain the parameter values where
    the distribution is discretized. Linear interpolation is used when
    sampling or evaluating the distribution for in-between parameter
    values.

    There are two variants of ``Marginal2D:`` when ``Continuous=false``,
    discrete marginal/conditional distributions are used to select a
    bilinear bilinear patch, followed by a continuous sampling step that
    chooses a specific position inside the patch. When
    ``Continuous=true``, continuous marginal/conditional distributions are
    used instead, and the second step is no longer needed. The latter
    scheme requires more computation and memory accesses but produces an
    overall smoother mapping.

    Remark:
        The Python API exposes explicitly instantiated versions of this
        class named ``MarginalDiscrete2D0`` to ``MarginalDiscrete2D3`` and
        ``MarginalContinuous2D0`` to ``MarginalContinuous2D3`` for data
        that depends on 0 to 3 parameters.
    """

    def __init__(self, data: Annotated[ArrayLike, dict(dtype='float32', shape=(None, None, None, None), order='C')], param_values: Sequence[Sequence[float]], normalize: bool = True, build_hierarchy: bool = True) -> None:
        """
        Construct a marginal sample warping scheme for floating point data of
        resolution ``size``.

        ``param_res`` and ``param_values`` are only needed for conditional
        distributions (see the text describing the Marginal2D class).

        If ``normalize`` is set to ``False``, the implementation will not re-
        scale the distribution so that it integrates to ``1``. It can still be
        sampled (proportionally), but returned density values will reflect the
        unnormalized values.

        If ``enable_sampling`` is set to ``False``, the implementation will
        not construct the cdf needed for sample warping, which saves memory in
        case this functionality is not needed (e.g. if only the interpolation
        in ``eval()`` is used).
        """

    def sample(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array2f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """
        Given a uniformly distributed 2D sample, draw a sample from the
        distribution (parameterized by ``param`` if applicable)

        Returns the warped sample and associated probability density.
        """

    def invert(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array2f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """Inverse of the mapping implemented in ``sample()``"""

    def eval(self, pos: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array2f = ..., active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the density at position ``pos``. The distribution is
        parameterized by ``param`` if applicable.
        """

    def __repr__(self) -> str: ...

class MarginalDiscrete2D3:
    """
    Implements a marginal sample warping scheme for 2D distributions with
    linear interpolation and an optional dependence on additional
    parameters

    This class takes a rectangular floating point array as input and
    constructs internal data structures to efficiently map uniform
    variates from the unit square ``[0, 1]^2`` to a function on ``[0,
    1]^2`` that linearly interpolates the input array.

    The mapping is constructed via the inversion method, which is applied
    to a marginal distribution over rows, followed by a conditional
    distribution over columns.

    The implementation also supports *conditional distributions*, i.e. 2D
    distributions that depend on an arbitrary number of parameters
    (indicated via the ``Dimension`` template parameter).

    In this case, the input array should have dimensions ``N0 x N1 x ... x
    Nn x res.y() x res.x()`` (where the last dimension is contiguous in
    memory), and the ``param_res`` should be set to ``{ N0, N1, ..., Nn
    }``, and ``param_values`` should contain the parameter values where
    the distribution is discretized. Linear interpolation is used when
    sampling or evaluating the distribution for in-between parameter
    values.

    There are two variants of ``Marginal2D:`` when ``Continuous=false``,
    discrete marginal/conditional distributions are used to select a
    bilinear bilinear patch, followed by a continuous sampling step that
    chooses a specific position inside the patch. When
    ``Continuous=true``, continuous marginal/conditional distributions are
    used instead, and the second step is no longer needed. The latter
    scheme requires more computation and memory accesses but produces an
    overall smoother mapping.

    Remark:
        The Python API exposes explicitly instantiated versions of this
        class named ``MarginalDiscrete2D0`` to ``MarginalDiscrete2D3`` and
        ``MarginalContinuous2D0`` to ``MarginalContinuous2D3`` for data
        that depends on 0 to 3 parameters.
    """

    def __init__(self, data: Annotated[ArrayLike, dict(dtype='float32', shape=(None, None, None, None, None), order='C')], param_values: Sequence[Sequence[float]], normalize: bool = True, build_hierarchy: bool = True) -> None:
        """
        Construct a marginal sample warping scheme for floating point data of
        resolution ``size``.

        ``param_res`` and ``param_values`` are only needed for conditional
        distributions (see the text describing the Marginal2D class).

        If ``normalize`` is set to ``False``, the implementation will not re-
        scale the distribution so that it integrates to ``1``. It can still be
        sampled (proportionally), but returned density values will reflect the
        unnormalized values.

        If ``enable_sampling`` is set to ``False``, the implementation will
        not construct the cdf needed for sample warping, which saves memory in
        case this functionality is not needed (e.g. if only the interpolation
        in ``eval()`` is used).
        """

    def sample(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array3f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """
        Given a uniformly distributed 2D sample, draw a sample from the
        distribution (parameterized by ``param`` if applicable)

        Returns the warped sample and associated probability density.
        """

    def invert(self, sample: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array3f = ..., active: drjit.auto.ad.Bool = True) -> tuple[Point2f, drjit.auto.ad.Float]:
        """Inverse of the mapping implemented in ``sample()``"""

    def eval(self, pos: drjit.auto.ad.Array2f, param: drjit.auto.ad.Array3f = ..., active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the density at position ``pos``. The distribution is
        parameterized by ``param`` if applicable.
        """

    def __repr__(self) -> str: ...

class Medium(Object):
    def __init__(self, props: Properties) -> None: ...

    def id(self) -> str:
        """Return a string identifier"""

    def set_id(self, arg: str, /) -> None:
        """Set a string identifier"""

    @property
    def m_sample_emitters(self) -> bool: ...

    @m_sample_emitters.setter
    def m_sample_emitters(self, arg: bool, /) -> None: ...

    @property
    def m_is_homogeneous(self) -> bool: ...

    @m_is_homogeneous.setter
    def m_is_homogeneous(self, arg: bool, /) -> None: ...

    @property
    def m_has_spectral_extinction(self) -> bool: ...

    @m_has_spectral_extinction.setter
    def m_has_spectral_extinction(self, arg: bool, /) -> None: ...

    def __repr__(self) -> str:
        """Return a human-readable representation of the Medium"""

    def phase_function(self) -> PhaseFunction:
        """Return the phase function of this medium"""

    def use_emitter_sampling(self) -> bool:
        """Returns whether this specific medium instance uses emitter sampling"""

    def is_homogeneous(self) -> bool:
        """Returns whether this medium is homogeneous"""

    def has_spectral_extinction(self) -> bool:
        """Returns whether this medium has a spectrally varying extinction"""

    def get_majorant(self, mi: MediumInteraction3f, active: bool = True) -> ScalarColor3f:
        """Returns the medium's majorant used for delta tracking"""

    def intersect_aabb(self, ray: Ray3f) -> tuple[bool, float, float]:
        """Intersects a ray with the medium's bounding box"""

    def sample_interaction(self, ray: Ray3f, sample: float, channel: int, active: bool) -> MediumInteraction3f:
        """
        Sample a free-flight distance in the medium.

        This function samples a (tentative) free-flight distance according to
        an exponential transmittance. It is then up to the integrator to then
        decide whether the MediumInteraction corresponds to a real or null
        scattering event.

        Parameter ``ray``:
            Ray, along which a distance should be sampled

        Parameter ``sample``:
            A uniformly distributed random sample

        Parameter ``channel``:
            The channel according to which we will sample the free-flight
            distance. This argument is only used when rendering in RGB modes.

        Returns:
            This method returns a MediumInteraction. The MediumInteraction
            will always be valid, except if the ray missed the Medium's
            bounding box.
        """

    def transmittance_eval_pdf(self, mi: MediumInteraction3f, si: SurfaceInteraction3f, active: bool) -> tuple[ScalarColor3f, ScalarColor3f]:
        """
        Compute the transmittance and PDF

        This function evaluates the transmittance and PDF of sampling a
        certain free-flight distance The returned PDF takes into account if a
        medium interaction occurred (mi.t <= si.t) or the ray left the medium
        (mi.t > si.t)

        The evaluated PDF is spectrally varying. This allows to account for
        the fact that the free-flight distance sampling distribution can
        depend on the wavelength.

        Returns:
            This method returns a pair of (Transmittance, PDF).
        """

    def get_scattering_coefficients(self, mi: MediumInteraction3f, active: bool = True) -> tuple[ScalarColor3f, ScalarColor3f, ScalarColor3f]:
        """
        Returns the medium coefficients Sigma_s, Sigma_n and Sigma_t evaluated
        at a given MediumInteraction mi
        """

class MediumInteraction3f(Interaction3f):
    """Stores information related to a medium scattering interaction"""

    @overload
    def __init__(self) -> None:
        """//! @}"""

    @overload
    def __init__(self, arg: MediumInteraction3f) -> None:
        """Copy constructor"""

    @property
    def medium(self) -> Medium:
        """Pointer to the associated medium"""

    @medium.setter
    def medium(self, arg: Medium, /) -> None: ...

    @property
    def sh_frame(self) -> Frame3f:
        """Shading frame"""

    @sh_frame.setter
    def sh_frame(self, arg: Frame3f, /) -> None: ...

    @property
    def wi(self) -> ScalarVector3f:
        """Incident direction in world frame"""

    @wi.setter
    def wi(self, arg: ScalarVector3f, /) -> None: ...

    @property
    def sigma_s(self) -> ScalarColor3f: ...

    @sigma_s.setter
    def sigma_s(self, arg: ScalarColor3f, /) -> None: ...

    @property
    def sigma_n(self) -> ScalarColor3f: ...

    @sigma_n.setter
    def sigma_n(self, arg: ScalarColor3f, /) -> None: ...

    @property
    def sigma_t(self) -> ScalarColor3f: ...

    @sigma_t.setter
    def sigma_t(self, arg: ScalarColor3f, /) -> None: ...

    @property
    def combined_extinction(self) -> ScalarColor3f: ...

    @combined_extinction.setter
    def combined_extinction(self, arg: ScalarColor3f, /) -> None: ...

    @property
    def mint(self) -> float:
        """mint used when sampling the given distance ``t``"""

    @mint.setter
    def mint(self, arg: float, /) -> None: ...

    def to_world(self, v: ScalarVector3f) -> ScalarVector3f:
        """
        Convert a local shading-space (defined by ``wi``) vector into world
        space
        """

    def to_local(self, v: ScalarVector3f) -> ScalarVector3f:
        """
        Convert a world-space vector into local shading coordinates (defined
        by ``wi``)
        """

    def __repr__(self) -> str: ...

class MediumPtr(drjit.ArrayBase[MediumPtr, _MediumPtrCp, Medium, Medium, MediumPtr, MediumPtr, drjit.auto.ad.Bool]):
    Variant: str = 'llvm_ad_spectral_polarized'

    @overload
    def phase_function(self) -> PhaseFunctionPtr:
        """Return the phase function of this medium"""

    @overload
    def phase_function(self) -> PhaseFunctionPtr: ...

    @overload
    def use_emitter_sampling(self) -> drjit.auto.ad.Bool:
        """Returns whether this specific medium instance uses emitter sampling"""

    @overload
    def use_emitter_sampling(self) -> drjit.auto.ad.Bool: ...

    @overload
    def is_homogeneous(self) -> drjit.auto.ad.Bool:
        """Returns whether this medium is homogeneous"""

    @overload
    def is_homogeneous(self) -> drjit.auto.ad.Bool: ...

    @overload
    def has_spectral_extinction(self) -> drjit.auto.ad.Bool:
        """Returns whether this medium has a spectrally varying extinction"""

    @overload
    def has_spectral_extinction(self) -> drjit.auto.ad.Bool: ...

    @overload
    def get_majorant(self, mi: MediumInteraction3f, active: drjit.auto.ad.Bool = True) -> UnpolarizedSpectrum:
        """Returns the medium's majorant used for delta tracking"""

    @overload
    def get_majorant(self, mi: MediumInteraction3f, active: drjit.auto.ad.Bool = True) -> UnpolarizedSpectrum: ...

    @overload
    def intersect_aabb(self, ray: Ray3f) -> tuple[drjit.auto.ad.Bool, drjit.auto.ad.Float, drjit.auto.ad.Float]:
        """Intersects a ray with the medium's bounding box"""

    @overload
    def intersect_aabb(self, ray: Ray3f) -> tuple[drjit.auto.ad.Bool, drjit.auto.ad.Float, drjit.auto.ad.Float]: ...

    @overload
    def sample_interaction(self, ray: Ray3f, sample: drjit.auto.ad.Float, channel: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool) -> MediumInteraction3f:
        """
        Sample a free-flight distance in the medium.

        This function samples a (tentative) free-flight distance according to
        an exponential transmittance. It is then up to the integrator to then
        decide whether the MediumInteraction corresponds to a real or null
        scattering event.

        Parameter ``ray``:
            Ray, along which a distance should be sampled

        Parameter ``sample``:
            A uniformly distributed random sample

        Parameter ``channel``:
            The channel according to which we will sample the free-flight
            distance. This argument is only used when rendering in RGB modes.

        Returns:
            This method returns a MediumInteraction. The MediumInteraction
            will always be valid, except if the ray missed the Medium's
            bounding box.
        """

    @overload
    def sample_interaction(self, ray: Ray3f, sample: drjit.auto.ad.Float, channel: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool) -> MediumInteraction3f: ...

    @overload
    def transmittance_eval_pdf(self, mi: MediumInteraction3f, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool) -> tuple[UnpolarizedSpectrum, UnpolarizedSpectrum]:
        """
        Compute the transmittance and PDF

        This function evaluates the transmittance and PDF of sampling a
        certain free-flight distance The returned PDF takes into account if a
        medium interaction occurred (mi.t <= si.t) or the ray left the medium
        (mi.t > si.t)

        The evaluated PDF is spectrally varying. This allows to account for
        the fact that the free-flight distance sampling distribution can
        depend on the wavelength.

        Returns:
            This method returns a pair of (Transmittance, PDF).
        """

    @overload
    def transmittance_eval_pdf(self, mi: MediumInteraction3f, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool) -> tuple[UnpolarizedSpectrum, UnpolarizedSpectrum]: ...

    @overload
    def get_scattering_coefficients(self, mi: MediumInteraction3f, active: drjit.auto.ad.Bool = True) -> tuple[UnpolarizedSpectrum, UnpolarizedSpectrum, UnpolarizedSpectrum]:
        """
        Returns the medium coefficients Sigma_s, Sigma_n and Sigma_t evaluated
        at a given MediumInteraction mi
        """

    @overload
    def get_scattering_coefficients(self, mi: MediumInteraction3f, active: drjit.auto.ad.Bool = True) -> tuple[UnpolarizedSpectrum, UnpolarizedSpectrum, UnpolarizedSpectrum]: ...

class MemoryMappedFile(Object):
    """
    Basic cross-platform abstraction for memory mapped files

    Remark:
        The Python API has one additional constructor
        <tt>MemoryMappedFile(filename, array)<tt>, which creates a new
        file, maps it into memory, and copies the array contents.
    """

    @overload
    def __init__(self, filename: str, size: int) -> None:
        """Create a new memory-mapped file of the specified size"""

    @overload
    def __init__(self, filename: str, write: bool = False) -> None:
        """Map the specified file into memory"""

    @overload
    def __init__(self, filename: str, array: Annotated[ArrayLike, dict(device='cpu')]) -> None: ...

    def size(self) -> int:
        """Return the size of the mapped region"""

    def data(self) -> object:
        """Return a pointer to the file contents in memory"""

    def resize(self, arg: int, /) -> None:
        """
        Resize the memory-mapped file

        This involves remapping the file, which will generally change the
        pointer obtained via data()
        """

    def filename(self) -> str:
        """Return the associated filename"""

    def can_write(self) -> bool:
        """Return whether the mapped memory region can be modified"""

    @staticmethod
    def create_temporary(arg: int, /) -> MemoryMappedFile:
        """
        Create a temporary memory-mapped file

        Remark:
            When closing the mapping, the file is automatically deleted.
            Mitsuba additionally informs the OS that any outstanding changes
            that haven't yet been written to disk can be discarded (Linux/OSX
            only).
        """

    def __array__(self) -> Annotated[ArrayLike, dict(dtype='uint8')]: ...

class MemoryStream(Stream):
    """
    Simple memory buffer-based stream with automatic memory management. It
    always has read & write capabilities.

    The underlying memory storage of this implementation dynamically
    expands as data is written to the stream,  la ``std::vector``.
    """

    def __init__(self, capacity: int = 512) -> None:
        """
        Creates a new memory stream, initializing the memory buffer with a
        capacity of ``capacity`` bytes. For best performance, set this
        argument to the estimated size of the content that will be written to
        the stream.
        """

    def capacity(self) -> int:
        """Return the current capacity of the underlying memory buffer"""

    def owns_buffer(self) -> bool:
        """Return whether or not the memory stream owns the underlying buffer"""

    def raw_buffer(self) -> bytes: ...

class Mesh(Shape):
    @overload
    def __init__(self, props: Properties) -> None: ...

    @overload
    def __init__(self, name: str, vertex_count: int, face_count: int, props: Properties = ..., has_vertex_normals: bool = False, has_vertex_texcoords: bool = False) -> None:
        """
        Creates a zero-initialized mesh with the given vertex and face counts

        The vertex and face buffers can be filled using the ``mi.traverse``
        mechanism. When initializing these buffers through another method, an
        explicit call to initialize must be made once all buffers are filled.
        """

    def initialize(self) -> None:
        """
        Must be called once at the end of the construction of a Mesh

        This method computes internal data structures and notifies the parent
        sensor or emitter (if there is one) that this instance is their
        internal shape.
        """

    @overload
    def write_ply(self, filename: str) -> None:
        """
        Write the mesh to a binary PLY file

        Parameter ``filename``:
            Target file path on disk
        """

    @overload
    def write_ply(self, stream: Stream) -> None:
        """
        Write the mesh encoded in binary PLY format to a stream

        Parameter ``stream``:
            Target stream that will receive the encoded output
        """

    def merge(self, other: Mesh) -> "ref<mitsuba::Mesh<float, mitsuba::Color<float, 3ul> > >":
        """Merge two meshes into one"""

    def vertex_positions_buffer(self) -> drjit.scalar.ArrayXf: ...

    def vertex_normals_buffer(self) -> drjit.scalar.ArrayXf: ...

    def vertex_texcoords_buffer(self) -> drjit.scalar.ArrayXf: ...

    def faces_buffer(self) -> drjit.scalar.ArrayXu: ...

    def attribute_buffer(self, name: str) -> drjit.scalar.ArrayXf:
        """Return the mesh attribute associated with ``name``"""

    def add_attribute(self, name: str, size: int, buffer: Sequence[float]) -> None:
        """Add an attribute buffer with the given ``name`` and ``dim``"""

    def recompute_vertex_normals(self) -> None: ...

    def recompute_bbox(self) -> None: ...

    def build_directed_edges(self) -> None: ...

    def vertex_count(self) -> int:
        """Return the total number of vertices"""

    def face_count(self) -> int:
        """Return the total number of faces"""

    def has_vertex_normals(self) -> bool:
        """Does this mesh have per-vertex normals?"""

    def has_vertex_texcoords(self) -> bool:
        """Does this mesh have per-vertex texture coordinates?"""

    def has_mesh_attributes(self) -> bool:
        """Does this mesh have additional mesh attributes?"""

    def has_face_normals(self) -> bool:
        """Does this mesh use face normals?"""

    def face_indices(self, index: int, active: bool = True) -> drjit.scalar.Array3u:
        """Returns the vertex indices associated with triangle ``index``"""

    def edge_indices(self, tri_index: int, edge_index: int, active: bool = True) -> drjit.scalar.Array2u:
        """
        Returns the vertex indices associated with edge ``edge_index`` (0..2)
        of triangle ``tri_index``.
        """

    def vertex_position(self, index: int, active: bool = True) -> ScalarPoint3f:
        """Returns the world-space position of the vertex with index ``index``"""

    def vertex_normal(self, index: int, active: bool = True) -> ScalarNormal3f:
        """Returns the normal direction of the vertex with index ``index``"""

    def vertex_texcoord(self, index: int, active: bool = True) -> ScalarPoint2f:
        """Returns the UV texture coordinates of the vertex with index ``index``"""

    def face_normal(self, index: int, active: bool = True) -> ScalarVector3f:
        """Returns the normal direction of the face with index ``index``"""

    def opposite_dedge(self, index: int, active: bool = True) -> int:
        """
        Returns the opposite edge index associated with directed edge
        ``index``
        """

    def ray_intersect_triangle(self, index: int, ray: Ray3f, active: bool = True) -> None: ...

class MeshPtr(drjit.ArrayBase[MeshPtr, _MeshPtrCp, Mesh, Mesh, MeshPtr, MeshPtr, drjit.auto.ad.Bool]):
    @overload
    def __init__(self, arg: ShapePtr, /) -> None: ...

    @overload
    def __init__(self, arg: Shape, /) -> None: ...

    @overload
    def __init__(self, arg: Mesh, /) -> None: ...

    @overload
    def __init__(self, arg: ShapePtr, /) -> None: ...

    @overload
    def __init__(self, arg: Shape, /) -> None: ...

    @overload
    def __init__(self, arg: Mesh, /) -> None: ...

    Variant: str = 'llvm_ad_spectral_polarized'

    @overload
    def vertex_count(self) -> drjit.auto.ad.UInt:
        """Return the total number of vertices"""

    @overload
    def vertex_count(self) -> drjit.auto.ad.UInt: ...

    @overload
    def face_count(self) -> drjit.auto.ad.UInt:
        """Return the total number of faces"""

    @overload
    def face_count(self) -> drjit.auto.ad.UInt: ...

    @overload
    def has_vertex_normals(self) -> drjit.auto.ad.Bool:
        """Does this mesh have per-vertex normals?"""

    @overload
    def has_vertex_normals(self) -> drjit.auto.ad.Bool: ...

    @overload
    def has_vertex_texcoords(self) -> drjit.auto.ad.Bool:
        """Does this mesh have per-vertex texture coordinates?"""

    @overload
    def has_vertex_texcoords(self) -> drjit.auto.ad.Bool: ...

    @overload
    def has_mesh_attributes(self) -> drjit.auto.ad.Bool:
        """Does this mesh have additional mesh attributes?"""

    @overload
    def has_mesh_attributes(self) -> drjit.auto.ad.Bool: ...

    @overload
    def has_face_normals(self) -> drjit.auto.ad.Bool:
        """Does this mesh use face normals?"""

    @overload
    def has_face_normals(self) -> drjit.auto.ad.Bool: ...

    @overload
    def face_indices(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Array3u:
        """Returns the vertex indices associated with triangle ``index``"""

    @overload
    def face_indices(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Array3u: ...

    @overload
    def edge_indices(self, tri_index: drjit.auto.ad.UInt, edge_index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Array2u:
        """
        Returns the vertex indices associated with edge ``edge_index`` (0..2)
        of triangle ``tri_index``.
        """

    @overload
    def edge_indices(self, tri_index: drjit.auto.ad.UInt, edge_index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Array2u: ...

    @overload
    def vertex_position(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> Point3f:
        """Returns the world-space position of the vertex with index ``index``"""

    @overload
    def vertex_position(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> Point3f: ...

    @overload
    def vertex_normal(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> Normal3f:
        """Returns the normal direction of the vertex with index ``index``"""

    @overload
    def vertex_normal(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> Normal3f: ...

    @overload
    def vertex_texcoord(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> Point2f:
        """Returns the UV texture coordinates of the vertex with index ``index``"""

    @overload
    def vertex_texcoord(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> Point2f: ...

    @overload
    def face_normal(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> Vector3f:
        """Returns the normal direction of the face with index ``index``"""

    @overload
    def face_normal(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> Vector3f: ...

    @overload
    def opposite_dedge(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.UInt:
        """
        Returns the opposite edge index associated with directed edge
        ``index``
        """

    @overload
    def opposite_dedge(self, index: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.UInt: ...

    @overload
    def ray_intersect_triangle(self, index: drjit.auto.ad.UInt, ray: Ray3f, active: drjit.auto.ad.Bool = True) -> None: ...

    @overload
    def ray_intersect_triangle(self, index: drjit.auto.ad.UInt, ray: Ray3f, active: drjit.auto.ad.Bool = True) -> None: ...

class MicrofacetDistribution:
    """
    Implementation of the Beckman and GGX / Trowbridge-Reitz microfacet
    distributions and various useful sampling routines

    Based on the papers

    "Microfacet Models for Refraction through Rough Surfaces" by Bruce
    Walter, Stephen R. Marschner, Hongsong Li, and Kenneth E. Torrance

    and

    "Importance Sampling Microfacet-Based BSDFs using the Distribution of
    Visible Normals" by Eric Heitz and Eugene D'Eon

    The visible normal sampling code was provided by Eric Heitz and Eugene
    D'Eon. An improvement of the Beckmann model sampling routine is
    discussed in

    "An Improved Visible Normal Sampling Routine for the Beckmann
    Distribution" by Wenzel Jakob

    An improvement of the GGX model sampling routine is discussed in "A
    Simpler and Exact Sampling Routine for the GGX Distribution of Visible
    Normals" by Eric Heitz
    """

    @overload
    def __init__(self, type: MicrofacetType, alpha: float, sample_visible: bool = True) -> None: ...

    @overload
    def __init__(self, type: MicrofacetType, alpha_u: float, alpha_v: float, sample_visible: bool = True) -> None: ...

    @overload
    def __init__(self, type: MicrofacetType, alpha: float, sample_visible: bool = True) -> None: ...

    @overload
    def __init__(self, type: MicrofacetType, alpha_u: float, alpha_v: float, sample_visible: bool = True) -> None: ...

    @overload
    def __init__(self, arg: Properties, /) -> None: ...

    def type(self) -> MicrofacetType:
        """Return the distribution type"""

    def alpha(self) -> float:
        """Return the roughness (isotropic case)"""

    def alpha_u(self) -> float:
        """Return the roughness along the tangent direction"""

    def alpha_v(self) -> float:
        """Return the roughness along the bitangent direction"""

    def sample_visible(self) -> bool:
        """Return whether or not only visible normals are sampled?"""

    def is_anisotropic(self) -> bool:
        """Is this an anisotropic microfacet distribution?"""

    def is_isotropic(self) -> bool:
        """Is this an isotropic microfacet distribution?"""

    def scale_alpha(self, value: float) -> None:
        """Scale the roughness values by some constant"""

    def eval(self, m: ScalarVector3f) -> float:
        """
        Evaluate the microfacet distribution function

        Parameter ``m``:
            The microfacet normal
        """

    def pdf(self, wi: ScalarVector3f, m: ScalarVector3f) -> float:
        """
        Returns the density function associated with the sample() function.

        Parameter ``wi``:
            The incident direction (only relevant if visible normal sampling
            is used)

        Parameter ``m``:
            The microfacet normal
        """

    def smith_g1(self, v: ScalarVector3f, m: ScalarVector3f) -> float:
        """
        Smith's shadowing-masking function for a single direction

        Parameter ``v``:
            An arbitrary direction

        Parameter ``m``:
            The microfacet normal
        """

    def sample(self, wi: ScalarVector3f, sample: ScalarPoint2f) -> tuple[ScalarNormal3f, float]:
        """
        Draw a sample from the microfacet normal distribution and return the
        associated probability density

        Parameter ``wi``:
            The incident direction. Only used if visible normal sampling is
            enabled.

        Parameter ``sample``:
            A uniformly distributed 2D sample

        Returns:
            A tuple consisting of the sampled microfacet normal and the
            associated solid angle density
        """

    def G(self, wi: ScalarVector3f, wo: ScalarVector3f, m: ScalarVector3f) -> float:
        """Smith's separable shadowing-masking approximation"""

    def sample_visible_11(self, cos_theta_i: float, sample: ScalarPoint2f) -> ScalarVector2f:
        """Visible normal sampling code for the alpha=1 case"""

    def __repr__(self) -> str: ...

class MicrofacetType(enum.IntEnum):
    """Supported normal distribution functions"""

    Beckmann = 0
    """Beckmann distribution derived from Gaussian random surfaces"""

    GGX = 1
    """
    GGX: Long-tailed distribution for very rough surfaces (aka.
    Trowbridge-Reitz distr.)
    """

class MonteCarloIntegrator(SamplingIntegrator):
    """
    Abstract integrator that performs *recursive* Monte Carlo sampling
    starting from the sensor

    This class is almost identical to SamplingIntegrator. It stores two
    additional fields that are helpful for recursive Monte Carlo
    techniques: the maximum path depth, and the depth at which the Russian
    Roulette path termination technique should start to become active.
    """

class Normal3d(drjit.ArrayBase[Normal3d, _Normal3dCp, drjit.auto.ad.Float64, drjit.auto.ad._Float64Cp, drjit.auto.ad.Float64, Normal3d, drjit.auto.ad.Array3b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Normal3f(drjit.ArrayBase[Normal3f, _Normal3fCp, drjit.auto.ad.Float, drjit.auto.ad._FloatCp, drjit.auto.ad.Float, Normal3f, drjit.auto.ad.Array3b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Object:
    """
    Object base class with builtin reference counting

    This class (in conjunction with the ``ref`` reference counter)
    constitutes the foundation of an efficient reference-counted object
    hierarchy. The implementation here is an alternative to standard
    mechanisms for reference counting such as ``std::shared_ptr`` from the
    STL.

    Why not simply use ``std::shared_ptr``? To be spec-compliant, such
    shared pointers must associate a special record with every instance,
    which stores at least two counters plus a deletion function.
    Allocating this record naturally incurs further overheads to maintain
    data structures within the memory allocator. In addition to this, the
    size of an individual ``shared_ptr`` references is at least two data
    words. All of this quickly adds up and leads to significant overheads
    for large collections of instances, hence the need for an alternative
    in Mitsuba.

    In contrast, the ``Object`` class allows for a highly efficient
    implementation that only adds 64 bits to the base object (for the
    counter) and has no overhead for references. In addition, when using
    Mitsuba in Python, this counter is shared with Python such that the
    ownerhsip and lifetime of any ``Object`` instance across C++ and
    Python is managed by it.
    """

    @overload
    def __init__(self) -> None:
        """Default constructor"""

    @overload
    def __init__(self, arg: Object) -> None:
        """Copy constructor"""

    def id(self) -> str:
        """Return an identifier of the current instance (if available)"""

    def set_id(self, id: str) -> None:
        """Set an identifier to the current instance (if applicable)"""

    def expand(self) -> list:
        """
        Expand the object into a list of sub-objects and return them

        In some cases, an Object instance is merely a container for a number
        of sub-objects. In the context of Mitsuba, an example would be a
        combined sun & sky emitter instantiated via XML, which recursively
        expands into a separate sun & sky instance. This functionality is
        supported by any Mitsuba object, hence it is located this level.
        """

    def traverse(self, cb: TraversalCallback) -> None:
        """
        Traverse the attributes and object graph of this instance

        Implementing this function enables recursive traversal of C++ scene
        graphs. It is e.g. used to determine the set of differentiable
        parameters when using Mitsuba for optimization.

        Remark:
            The default implementation does nothing.

        See also:
            TraversalCallback
        """

    def parameters_changed(self, keys: Sequence[str] = []) -> None:
        """
        Update internal state after applying changes to parameters

        This function should be invoked when attributes (obtained via
        traverse) are modified in some way. The object can then update its
        internal state so that derived quantities are consistent with the
        change.

        Parameter ``keys``:
            Optional list of names (obtained via traverse) corresponding to
            the attributes that have been modified. Can also be used to notify
            when this function is called from a parent object by adding a
            "parent" key to the list. When empty, the object should assume
            that any attribute might have changed.

        Remark:
            The default implementation does nothing.

        See also:
            TraversalCallback
        """

    @property
    def ptr(self) -> int: ...

    def __repr__(self) -> str:
        """
        Return a human-readable string representation of the object's
        contents.

        This function is mainly useful for debugging purposes and should
        ideally be implemented by all subclasses. The default implementation
        simply returns ``MyObject[<address of 'this' pointer>]``, where
        ``MyObject`` is the name of the class.
        """

class ObjectPtr(drjit.ArrayBase[ObjectPtr, _ObjectPtrCp, Object, Object, ObjectPtr, ObjectPtr, drjit.auto.ad.Bool]):
    Variant: str = ''

class OptixDenoiser(Object):
    """
    Wrapper for the OptiX AI denoiser

    The OptiX AI denoiser is wrapped in this object such that it can work
    directly with Mitsuba types and its conventions.

    The denoiser works best when applied to noisy renderings that were
    produced with a Film which used the `box` ReconstructionFilter. With a
    filter that spans multiple pixels, the denoiser might identify some
    local variance as a feature of the scene and will not denoise it.
    """

    def __init__(self, input_size: ScalarVector2u, albedo: bool = False, normals: bool = False, temporal: bool = False) -> None:
        """
        Constructs an OptiX denoiser

        Parameter ``input_size``:
            Resolution of noisy images that will be fed to the denoiser.

        Parameter ``albedo``:
            Whether or not albedo information will also be given to the
            denoiser.

        Parameter ``normals``:
            Whether or not shading normals information will also be given to
            the Denoiser.

        Returns:
            A callable object which will apply the OptiX denoiser.
        """

    @overload
    def __call__(self, noisy: drjit.scalar.TensorXf, denoise_alpha: bool = True, albedo: drjit.scalar.TensorXf = ..., normals: drjit.scalar.TensorXf = ..., to_sensor: object | None = None, flow: drjit.scalar.TensorXf = ..., previous_denoised: drjit.scalar.TensorXf = ...) -> drjit.scalar.TensorXf:
        """
        Apply denoiser on inputs which are TensorXf objects.

        Parameter ``noisy``:
            The noisy input. (tensor shape: (width, height, 3 | 4))

        Parameter ``denoise_alpha``:
            Whether or not the alpha channel (if specified in the noisy input)
            should be denoised too. This parameter is optional, by default it
            is true.

        Parameter ``albedo``:
            Albedo information of the noisy rendering. This parameter is
            optional unless the OptixDenoiser was built with albedo support.
            (tensor shape: (width, height, 3))

        Parameter ``normals``:
            Shading normal information of the noisy rendering. The normals
            must be in the coordinate frame of the sensor which was used to
            render the noisy input. This parameter is optional unless the
            OptixDenoiser was built with normals support. (tensor shape:
            (width, height, 3))

        Parameter ``to_sensor``:
            A Transform4f which is applied to the ``normals`` parameter before
            denoising. This should be used to transform the normals into the
            correct coordinate frame. This parameter is optional, by default
            no transformation is applied.

        Parameter ``flow``:
            With temporal denoising, this parameter is the optical flow
            between the previous frame and the current one. It should capture
            the 2D motion of each individual pixel. When this parameter is
            unknown, it can been set to a zero-initialized TensorXf of the
            correct size and still produce convincing results. This parameter
            is optional unless the OptixDenoiser was built with temporal
            denoising support. (tensor shape: (width, height, 2))

        Parameter ``previous_denoised``:
            With temporal denoising, the previous denoised frame should be
            passed here. For the very first frame, the OptiX documentation
            recommends passing the noisy input for this argument. This
            parameter is optional unless the OptixDenoiser was built with
            temporal denoising support. (tensor shape: (width, height, 3 | 4))

        Returns:
            The denoised input.
        """

    @overload
    def __call__(self, noisy: Bitmap, denoise_alpha: bool = True, albedo_ch: str = '', normals_ch: str = '', to_sensor: object | None = None, flow_ch: str = '', previous_denoised_ch: str = '', noisy_ch: str = '<root>') -> Bitmap:
        """
        Apply denoiser on inputs which are Bitmap objects.

        Parameter ``noisy``:
            The noisy input. When passing additional information like albedo
            or normals to the denoiser, this Bitmap object must be a
            MultiChannel bitmap.

        Parameter ``denoise_alpha``:
            Whether or not the alpha channel (if specified in the noisy input)
            should be denoised too. This parameter is optional, by default it
            is true.

        Parameter ``albedo_ch``:
            The name of the channel in the ``noisy`` parameter which contains
            the albedo information of the noisy rendering. This parameter is
            optional unless the OptixDenoiser was built with albedo support.

        Parameter ``normals_ch``:
            The name of the channel in the ``noisy`` parameter which contains
            the shading normal information of the noisy rendering. The normals
            must be in the coordinate frame of the sensor which was used to
            render the noisy input. This parameter is optional unless the
            OptixDenoiser was built with normals support.

        Parameter ``to_sensor``:
            A Transform4f which is applied to the ``normals`` parameter before
            denoising. This should be used to transform the normals into the
            correct coordinate frame. This parameter is optional, by default
            no transformation is applied.

        Parameter ``flow_ch``:
            With temporal denoising, this parameter is name of the channel in
            the ``noisy`` parameter which contains the optical flow between
            the previous frame and the current one. It should capture the 2D
            motion of each individual pixel. When this parameter is unknown,
            it can been set to a zero-initialized TensorXf of the correct size
            and still produce convincing results. This parameter is optional
            unless the OptixDenoiser was built with temporal denoising
            support.

        Parameter ``previous_denoised_ch``:
            With temporal denoising, this parameter is name of the channel in
            the ``noisy`` parameter which contains the previous denoised
            frame. For the very first frame, the OptiX documentation
            recommends passing the noisy input for this argument. This
            parameter is optional unless the OptixDenoiser was built with
            temporal denoising support.

        Parameter ``noisy_ch``:
            The name of the channel in the ``noisy`` parameter which contains
            the shading normal information of the noisy rendering.

        Returns:
            The denoised input.
        """

class ParamFlags(enum.IntEnum):
    """
    This list of flags is used to classify the different types of
    parameters exposed by the plugins.

    For instance, in the context of differentiable rendering, it is
    important to know which parameters can be differentiated, and which of
    those might introduce discontinuities in the Monte Carlo simulation.
    """

    Differentiable = 0
    """Tracking gradients w.r.t. this parameter is allowed"""

    NonDifferentiable = 1
    """Tracking gradients w.r.t. this parameter is not allowed"""

    Discontinuous = 2
    """
    Tracking gradients w.r.t. this parameter will introduce
    discontinuities
    """

class PhaseFunction(Object):
    def __init__(self, arg: Properties, /) -> None: ...

    @overload
    def flags(self, index: int, active: bool = True) -> int:
        """Flags for a specific component of this phase function."""

    @overload
    def flags(self, active: bool = True) -> int:
        """Flags for this phase function."""

    def id(self) -> str:
        """Return a string identifier"""

    @property
    def m_flags(self) -> int:
        """Type of phase function (e.g. anisotropic)"""

    @m_flags.setter
    def m_flags(self, arg: int, /) -> None: ...

    def __repr__(self) -> str: ...

    def sample(self, ctx: PhaseFunctionContext, mi: MediumInteraction3f, sample1: float, sample2: ScalarPoint2f, active: bool = True) -> tuple[ScalarVector3f, ScalarColor3f, float]:
        """
        Importance sample the phase function model

        The function returns a sampled direction.

        Parameter ``ctx``:
            A phase function sampling context, contains information about the
            transport mode

        Parameter ``mi``:
            A medium interaction data structure describing the underlying
            medium position. The incident direction is obtained from the field
            ``mi.wi``.

        Parameter ``sample1``:
            A uniformly distributed sample on :math:`[0,1]`. It is used to
            select the phase function component in multi-component models.

        Parameter ``sample2``:
            A uniformly distributed sample on :math:`[0,1]^2`. It is used to
            generate the sampled direction.

        Returns:
            A sampled direction wo and its corresponding weight and PDF
        """

    def eval_pdf(self, ctx: PhaseFunctionContext, mi: MediumInteraction3f, wo: ScalarVector3f, active: bool = True) -> tuple[ScalarColor3f, float]:
        """
        Evaluates the phase function model value and PDF

        The function returns the value (which often equals the PDF) of the
        phase function in the query direction.

        Parameter ``ctx``:
            A phase function sampling context, contains information about the
            transport mode

        Parameter ``mi``:
            A medium interaction data structure describing the underlying
            medium position. The incident direction is obtained from the field
            ``mi.wi``.

        Parameter ``wo``:
            An outgoing direction to evaluate.

        Returns:
            The value and the sampling PDF of the phase function in direction
            wo
        """

    def projected_area(self, mi: MediumInteraction3f, active: bool = True) -> float:
        """
        Returns the microflake projected area

        The function returns the projected area of the microflake distribution
        defining the phase function. For non-microflake phase functions, e.g.
        isotropic or Henyey-Greenstein, this should return a value of 1.

        Parameter ``mi``:
            A medium interaction data structure describing the underlying
            medium position. The incident direction is obtained from the field
            ``mi.wi``.

        Returns:
            The projected area in direction ``mi.wi`` at position ``mi.p``
        """

    def max_projected_area(self) -> float:
        """Return the maximum projected area of the microflake distribution"""

    def component_count(self, active: bool = True) -> int:
        """Number of components this phase function is comprised of."""

class PhaseFunctionContext:
    def __init__(self, sampler: Sampler | None = None, mode: TransportMode = TransportMode.Radiance) -> None:
        """//! @}"""

    @property
    def mode(self) -> TransportMode:
        """Transported mode (radiance or importance)"""

    @mode.setter
    def mode(self, arg: TransportMode, /) -> None: ...

    @property
    def sampler(self) -> Sampler:
        """Sampler object"""

    @sampler.setter
    def sampler(self, arg: Sampler, /) -> None: ...

    @property
    def type_mask(self) -> int: ...

    @type_mask.setter
    def type_mask(self, arg: int, /) -> None: ...

    @property
    def component(self) -> int: ...

    @component.setter
    def component(self, arg: int, /) -> None: ...

    def reverse(self) -> None:
        """
        Reverse the direction of light transport in the record

        This updates the transport mode (radiance to importance and vice
        versa).
        """

    def __repr__(self) -> str: ...

class PhaseFunctionFlags(enum.IntEnum):
    """
    This enumeration is used to classify phase functions into different
    types, i.e. into isotropic, anisotropic and microflake phase
    functions.

    This can be used to optimize implementations to for example have less
    overhead if the phase function is not a microflake phase function.
    """

    Empty = 0

    Isotropic = 1

    Anisotropic = 2

    Microflake = 4

class PhaseFunctionPtr(drjit.ArrayBase[PhaseFunctionPtr, _PhaseFunctionPtrCp, PhaseFunction, PhaseFunction, PhaseFunctionPtr, PhaseFunctionPtr, drjit.auto.ad.Bool]):
    Variant: str = 'llvm_ad_spectral_polarized'

    @overload
    def sample(self, ctx: PhaseFunctionContext, mi: MediumInteraction3f, sample1: drjit.auto.ad.Float, sample2: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[Vector3f, Spectrum, drjit.auto.ad.Float]:
        """
        Importance sample the phase function model

        The function returns a sampled direction.

        Parameter ``ctx``:
            A phase function sampling context, contains information about the
            transport mode

        Parameter ``mi``:
            A medium interaction data structure describing the underlying
            medium position. The incident direction is obtained from the field
            ``mi.wi``.

        Parameter ``sample1``:
            A uniformly distributed sample on :math:`[0,1]`. It is used to
            select the phase function component in multi-component models.

        Parameter ``sample2``:
            A uniformly distributed sample on :math:`[0,1]^2`. It is used to
            generate the sampled direction.

        Returns:
            A sampled direction wo and its corresponding weight and PDF
        """

    @overload
    def sample(self, ctx: PhaseFunctionContext, mi: MediumInteraction3f, sample1: drjit.auto.ad.Float, sample2: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[Vector3f, Spectrum, drjit.auto.ad.Float]: ...

    @overload
    def eval_pdf(self, ctx: PhaseFunctionContext, mi: MediumInteraction3f, wo: Vector3f, active: drjit.auto.ad.Bool = True) -> tuple[Spectrum, drjit.auto.ad.Float]:
        """
        Evaluates the phase function model value and PDF

        The function returns the value (which often equals the PDF) of the
        phase function in the query direction.

        Parameter ``ctx``:
            A phase function sampling context, contains information about the
            transport mode

        Parameter ``mi``:
            A medium interaction data structure describing the underlying
            medium position. The incident direction is obtained from the field
            ``mi.wi``.

        Parameter ``wo``:
            An outgoing direction to evaluate.

        Returns:
            The value and the sampling PDF of the phase function in direction
            wo
        """

    @overload
    def eval_pdf(self, ctx: PhaseFunctionContext, mi: MediumInteraction3f, wo: Vector3f, active: drjit.auto.ad.Bool = True) -> tuple[Spectrum, drjit.auto.ad.Float]: ...

    @overload
    def projected_area(self, mi: MediumInteraction3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Returns the microflake projected area

        The function returns the projected area of the microflake distribution
        defining the phase function. For non-microflake phase functions, e.g.
        isotropic or Henyey-Greenstein, this should return a value of 1.

        Parameter ``mi``:
            A medium interaction data structure describing the underlying
            medium position. The incident direction is obtained from the field
            ``mi.wi``.

        Returns:
            The projected area in direction ``mi.wi`` at position ``mi.p``
        """

    @overload
    def projected_area(self, mi: MediumInteraction3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float: ...

    @overload
    def max_projected_area(self) -> drjit.auto.ad.Float:
        """Return the maximum projected area of the microflake distribution"""

    @overload
    def max_projected_area(self) -> drjit.auto.ad.Float: ...

    @overload
    def flags(self, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.UInt:
        """Flags for this phase function."""

    @overload
    def flags(self, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.UInt: ...

    @overload
    def component_count(self, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.UInt64:
        """Number of components this phase function is comprised of."""

    @overload
    def component_count(self, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.UInt64: ...

class PluginManager:
    """
    The object factory is responsible for loading plugin modules and
    instantiating object instances.

    Ordinarily, this class will be used by making repeated calls to the
    create_object() methods. The generated instances are then assembled
    into a final object graph, such as a scene. One such examples is the
    SceneHandler class, which parses an XML scene file by essentially
    translating the XML elements into calls to create_object().
    """

    @staticmethod
    def instance() -> PluginManager:
        """Return the global plugin manager"""

    def get_plugin_class(self, name: str, variant: str) -> Class:
        """Return the class corresponding to a plugin for a specific variant"""

    def create_object(self, arg: Properties, /) -> object:
        """
        Instantiate a plugin, verify its type, and return the newly created
        object instance.

        Parameter ``props``:
            A Properties instance containing all information required to find
            and construct the plugin.

        Parameter ``class_type``:
            Expected type of the instance. An exception will be thrown if it
            turns out not to derive from this class.
        """

class Point0d(drjit.ArrayBase[Point0d, _Point0dCp, drjit.auto.ad.Float64, drjit.auto.ad._Float64Cp, drjit.auto.ad.Float64, Point0d, drjit.auto.ad.Array0b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point0f(drjit.ArrayBase[Point0f, _Point0fCp, drjit.auto.ad.Float, drjit.auto.ad._FloatCp, drjit.auto.ad.Float, Point0f, drjit.auto.ad.Array0b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point0i(drjit.ArrayBase[Point0i, _Point0iCp, drjit.auto.ad.Int, drjit.auto.ad._IntCp, drjit.auto.ad.Int, Point0i, drjit.auto.ad.Array0b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point0u(drjit.ArrayBase[Point0u, _Point0uCp, drjit.auto.ad.UInt, drjit.auto.ad._UIntCp, drjit.auto.ad.UInt, Point0u, drjit.auto.ad.Array0b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point1d(drjit.ArrayBase[Point1d, _Point1dCp, drjit.auto.ad.Float64, drjit.auto.ad._Float64Cp, drjit.auto.ad.Float64, Point1d, drjit.auto.ad.Array1b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point1f(drjit.ArrayBase[Point1f, _Point1fCp, drjit.auto.ad.Float, drjit.auto.ad._FloatCp, drjit.auto.ad.Float, Point1f, drjit.auto.ad.Array1b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point1i(drjit.ArrayBase[Point1i, _Point1iCp, drjit.auto.ad.Int, drjit.auto.ad._IntCp, drjit.auto.ad.Int, Point1i, drjit.auto.ad.Array1b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point1u(drjit.ArrayBase[Point1u, _Point1uCp, drjit.auto.ad.UInt, drjit.auto.ad._UIntCp, drjit.auto.ad.UInt, Point1u, drjit.auto.ad.Array1b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point2d(drjit.ArrayBase[Point2d, _Point2dCp, drjit.auto.ad.Float64, drjit.auto.ad._Float64Cp, drjit.auto.ad.Float64, Point2d, drjit.auto.ad.Array2b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point2f(drjit.ArrayBase[Point2f, _Point2fCp, drjit.auto.ad.Float, drjit.auto.ad._FloatCp, drjit.auto.ad.Float, Point2f, drjit.auto.ad.Array2b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point2i(drjit.ArrayBase[Point2i, _Point2iCp, drjit.auto.ad.Int, drjit.auto.ad._IntCp, drjit.auto.ad.Int, Point2i, drjit.auto.ad.Array2b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point2u(drjit.ArrayBase[Point2u, _Point2uCp, drjit.auto.ad.UInt, drjit.auto.ad._UIntCp, drjit.auto.ad.UInt, Point2u, drjit.auto.ad.Array2b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point3d(drjit.ArrayBase[Point3d, _Point3dCp, drjit.auto.ad.Float64, drjit.auto.ad._Float64Cp, drjit.auto.ad.Float64, Point3d, drjit.auto.ad.Array3b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point3f(drjit.ArrayBase[Point3f, _Point3fCp, drjit.auto.ad.Float, drjit.auto.ad._FloatCp, drjit.auto.ad.Float, Point3f, drjit.auto.ad.Array3b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point3i(drjit.ArrayBase[Point3i, _Point3iCp, drjit.auto.ad.Int, drjit.auto.ad._IntCp, drjit.auto.ad.Int, Point3i, drjit.auto.ad.Array3b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point3u(drjit.ArrayBase[Point3u, _Point3uCp, drjit.auto.ad.UInt, drjit.auto.ad._UIntCp, drjit.auto.ad.UInt, Point3u, drjit.auto.ad.Array3b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point4d(drjit.ArrayBase[Point4d, _Point4dCp, drjit.auto.ad.Float64, drjit.auto.ad._Float64Cp, drjit.auto.ad.Float64, Point4d, drjit.auto.ad.Array4b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point4f(drjit.ArrayBase[Point4f, _Point4fCp, drjit.auto.ad.Float, drjit.auto.ad._FloatCp, drjit.auto.ad.Float, Point4f, drjit.auto.ad.Array4b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point4i(drjit.ArrayBase[Point4i, _Point4iCp, drjit.auto.ad.Int, drjit.auto.ad._IntCp, drjit.auto.ad.Int, Point4i, drjit.auto.ad.Array4b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class Point4u(drjit.ArrayBase[Point4u, _Point4uCp, drjit.auto.ad.UInt, drjit.auto.ad._UIntCp, drjit.auto.ad.UInt, Point4u, drjit.auto.ad.Array4b]):
    def __getitem__(self, key, /):
        """Return self[key]."""

    def __setitem__(self, key, value, /):
        """Set self[key] to value."""

    def __delitem__(self, key, /):
        """Delete self[key]."""

class PositionSample3f:
    """
    Generic sampling record for positions

    This sampling record is used to implement techniques that draw a
    position from a point, line, surface, or volume domain in 3D and
    furthermore provide auxiliary information about the sample.

    Apart from returning the position and (optionally) the surface normal,
    the responsible sampling method must annotate the record with the
    associated probability density and delta.
    """

    @overload
    def __init__(self) -> None:
        """Construct an uninitialized position sample"""

    @overload
    def __init__(self, other: PositionSample3f) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, si: SurfaceInteraction3f) -> None:
        """
        Create a position sampling record from a surface intersection

        This is useful to determine the hypothetical sampling density on a
        surface after hitting it using standard ray tracing. This happens for
        instance in path tracing with multiple importance sampling.
        """

    @property
    def p(self) -> ScalarPoint3f:
        """Sampled position"""

    @p.setter
    def p(self, arg: ScalarPoint3f, /) -> None: ...

    @property
    def n(self) -> ScalarNormal3f:
        """Sampled surface normal (if applicable)"""

    @n.setter
    def n(self, arg: ScalarNormal3f, /) -> None: ...

    @property
    def uv(self) -> ScalarPoint2f:
        """
        Optional: 2D sample position associated with the record

        In some uses of this record, a sampled position may be associated with
        an important 2D quantity, such as the texture coordinates on a
        triangle mesh or a position on the aperture of a sensor. When
        applicable, such positions are stored in the ``uv`` attribute.
        """

    @uv.setter
    def uv(self, arg: ScalarPoint2f, /) -> None: ...

    @property
    def time(self) -> float:
        """Associated time value"""

    @time.setter
    def time(self, arg: float, /) -> None: ...

    @property
    def pdf(self) -> float:
        """Probability density at the sample"""

    @pdf.setter
    def pdf(self, arg: float, /) -> None: ...

    @property
    def delta(self) -> bool:
        """
        Set if the sample was drawn from a degenerate (Dirac delta)
        distribution
        """

    @delta.setter
    def delta(self, arg: bool, /) -> None: ...

    def __repr__(self) -> str: ...

class PreliminaryIntersection3f:
    """
    Stores preliminary information related to a ray intersection

    This data structure is used as return type for the
    Shape::ray_intersect_preliminary efficient ray intersection routine.
    It stores whether the shape is intersected by a given ray, and cache
    preliminary information about the intersection if that is the case.

    If the intersection is deemed relevant, detailed intersection
    information can later be obtained via the create_surface_interaction()
    method.
    """

    @overload
    def __init__(self) -> None:
        """//! @}"""

    @overload
    def __init__(self, arg: PreliminaryIntersection3f) -> None:
        """Copy constructor"""

    @property
    def t(self) -> float:
        """Distance traveled along the ray"""

    @t.setter
    def t(self, arg: float, /) -> None: ...

    @property
    def prim_uv(self) -> ScalarPoint2f:
        """2D coordinates on the primitive surface parameterization"""

    @prim_uv.setter
    def prim_uv(self, arg: ScalarPoint2f, /) -> None: ...

    @property
    def prim_index(self) -> int:
        """Primitive index, e.g. the triangle ID (if applicable)"""

    @prim_index.setter
    def prim_index(self, arg: int, /) -> None: ...

    @property
    def shape_index(self) -> int:
        """Shape index, e.g. the shape ID in shapegroup (if applicable)"""

    @shape_index.setter
    def shape_index(self, arg: int, /) -> None: ...

    @property
    def shape(self) -> Shape:
        """Pointer to the associated shape"""

    @shape.setter
    def shape(self, arg: Shape, /) -> None: ...

    @property
    def instance(self) -> Shape:
        """Stores a pointer to the parent instance (if applicable)"""

    @instance.setter
    def instance(self, arg: Shape, /) -> None: ...

    def is_valid(self) -> bool:
        """Is the current interaction valid?"""

    def compute_surface_interaction(self, ray: Ray3f, ray_flags: int = 14, active: bool = True) -> SurfaceInteraction3f:
        """
        Compute and return detailed information related to a surface
        interaction

        Parameter ``ray``:
            Ray associated with the ray intersection

        Parameter ``ray_flags``:
            Flags specifying which information should be computed

        Returns:
            A data structure containing the detailed information
        """

    def __repr__(self) -> str: ...

    def assign(self, arg: PreliminaryIntersection3f, /) -> None: ...

    def __setitem__(self, arg0: bool, arg1: PreliminaryIntersection3f, /) -> None: ...

class ProjectiveCamera(Sensor):
    """
    Projective camera interface

    This class provides an abstract interface to several types of sensors
    that are commonly used in computer graphics, such as perspective and
    orthographic camera models.

    The interface is meant to be implemented by any kind of sensor, whose
    world to clip space transformation can be explained using only linear
    operations on homogeneous coordinates.

    A useful feature of ProjectiveCamera sensors is that their view can be
    rendered using the traditional OpenGL pipeline.
    """

    def near_clip(self) -> float:
        """Return the near clip plane distance"""

    def far_clip(self) -> float:
        """Return the far clip plane distance"""

    def focus_distance(self) -> float:
        """Return the distance to the focal plane"""

class Properties:
    @overload
    def __init__(self) -> None:
        """Construct an empty property container"""

    @overload
    def __init__(self, arg: str, /) -> None:
        """Construct an empty property container with a specific plugin name"""

    @overload
    def __init__(self, arg: Properties) -> None:
        """Copy constructor"""

    def has_property(self, arg: str, /) -> bool:
        """Verify if a value with the specified name exists"""

    def remove_property(self, arg: str, /) -> bool:
        """
        Remove a property with the specified name

        Returns:
            ``True`` upon success
        """

    def mark_queried(self, arg: str, /) -> bool:
        """
        Manually mark a certain property as queried

        Returns:
            ``True`` upon success
        """

    def was_queried(self, arg: str, /) -> bool:
        """Check if a certain property was queried"""

    def plugin_name(self) -> str:
        """Get the associated plugin name"""

    def set_plugin_name(self, arg: str, /) -> None:
        """Set the associated plugin name"""

    def id(self) -> str:
        """
        Returns a unique identifier associated with this instance (or an empty
        string)
        """

    def set_id(self, arg: str, /) -> None:
        """Set the unique identifier associated with this instance"""

    def copy_attribute(self, arg0: Properties, arg1: str, arg2: str, /) -> None:
        """
        Copy a single attribute from another Properties object and potentially
        rename it
        """

    def property_names(self) -> list[str]:
        """Return an array containing the names of all stored properties"""

    def unqueried(self) -> list[str]:
        """Return the list of un-queried attributed"""

    def merge(self, arg: Properties, /) -> None:
        """
        Merge another properties record into the current one.

        Existing properties will be overwritten with the values from ``props``
        if they have the same name.
        """

    def type(self, arg: str, /) -> "mitsuba::Properties::Type":
        """
        Returns the type of an existing property. If no property exists under
        that name, an error is logged and type ``void`` is returned.
        """

    def named_references(self) -> list[tuple[str, str]]: ...

    @overload
    def __setitem__(self, arg0: str, arg1: float, /) -> None:
        """Store a floating point value in the Properties instance"""

    @overload
    def __setitem__(self, arg0: str, arg1: bool, /) -> None:
        """Store a boolean value in the Properties instance"""

    @overload
    def __setitem__(self, arg0: str, arg1: int, /) -> None:
        """Store a long value in the Properties instance"""

    @overload
    def __setitem__(self, arg0: str, arg1: str, /) -> None:
        """Store a string in the Properties instance"""

    @overload
    def __setitem__(self, arg0: str, arg1: ScalarColor3f) -> None:
        """Store a color in the Properties instance"""

    @overload
    def __setitem__(self, arg0: str, arg1: ScalarColor3d) -> None:
        """Store a color in the Properties instance"""

    @overload
    def __setitem__(self, arg0: str, arg1: drjit.scalar.Array3f64, /) -> None:
        """Store a 3D array in the Properties instance"""

    @overload
    def __setitem__(self, arg0: str, arg1: ScalarTransform3d, /) -> None:
        """
        Store a 3x3 homogeneous coordinate transformation in the Properties
        instance
        """

    @overload
    def __setitem__(self, arg0: str, arg1: ScalarTransform4d, /) -> None:
        """
        Store a 4x4 homogeneous coordinate transformation in the Properties
        instance
        """

    @overload
    def __setitem__(self, arg0: str, arg1: Object, /) -> None:
        """Store an arbitrary object in the Properties instance"""

    @overload
    def __setitem__(self, arg0: str, arg1: drjit.auto.ad.TensorXf, /) -> None: ...

    def string(self, arg0: str, arg1: str, /) -> object:
        """Retrieve a string value (use default value if no entry exists)"""

    def __getitem__(self, key: str) -> object:
        """Retrieve an existing property given its name"""

    def get(self, key: str, def_value: object | None = None) -> object:
        """
        Return the value for the specified key it exists, otherwise return default value
        """

    def __contains__(self, arg: str, /) -> bool: ...

    def __delitem__(self, arg: str, /) -> bool: ...

    def as_string(self, arg: str, /) -> str:
        """Return one of the parameters (converting it to a string if necessary)"""

    def __repr__(self) -> str: ...

class RadicalInverse(Object):
    """
    Efficient implementation of a radical inverse function with prime
    bases including scrambled versions.

    This class is used to implement Halton and Hammersley sequences for
    QMC integration in Mitsuba.
    """

    def __init__(self, max_base: int = 8161, scramble: int = -1) -> None: ...

    def base(self, arg: int, /) -> int:
        """
        Returns the n-th prime base used by the sequence

        These prime numbers are used as bases in the radical inverse function
        implementation.
        """

    def bases(self) -> int:
        """
        Return the number of prime bases for which precomputed tables are
        available
        """

    def scramble(self) -> int:
        """Return the original scramble value"""

    def eval(self, base_index: int, index: drjit.auto.ad.UInt64) -> drjit.auto.ad.Float:
        """
        Calculate the radical inverse function

        This function is used as a building block to construct Halton and
        Hammersley sequences. Roughly, it computes a b-ary representation of
        the input value ``index``, mirrors it along the decimal point, and
        returns the resulting fractional value. The implementation here uses
        prime numbers for ``b``.

        Parameter ``base_index``:
            Selects the n-th prime that is used as a base when computing the
            radical inverse function (0 corresponds to 2, 1->3, 2->5, etc.).
            The value specified here must be between 0 and 1023.

        Parameter ``index``:
            Denotes the index that should be mapped through the radical
            inverse function
        """

    def permutation(self, arg: int, /) -> Annotated[ArrayLike, dict(dtype='uint16')]:
        """Return the permutation corresponding to the given prime number basis"""

    def inverse_permutation(self, arg: int, /) -> int:
        """
        Return the inverse permutation corresponding to the given prime number
        basis
        """

class Ray2f:
    """
    Simple n-dimensional ray segment data structure

    Along with the ray origin and direction, this data structure
    additionally stores a maximum ray position ``maxt``, a time value
    ``time`` as well a the wavelength information associated with the ray.
    """

    @overload
    def __init__(self) -> None:
        """Create an uninitialized ray"""

    @overload
    def __init__(self, other: Ray2f) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, o: Point2f, d: Vector2f, time: drjit.auto.ad.Float = 0.0, wavelengths: UnpolarizedSpectrum = ...) -> None:
        """Construct a new ray (o, d) with time"""

    @overload
    def __init__(self, o: Point2f, d: Vector2f, maxt: drjit.auto.ad.Float, time: drjit.auto.ad.Float, wavelengths: UnpolarizedSpectrum) -> None:
        """Construct a new ray (o, d) with bounds"""

    @overload
    def __init__(self, other: Ray2f, maxt: drjit.auto.ad.Float) -> None:
        """Copy a ray, but change the maxt value"""

    def __call__(self, t: drjit.auto.ad.Float) -> Point2f:
        """Return the position of a point along the ray"""

    @property
    def o(self) -> Point2f:
        """Ray origin"""

    @o.setter
    def o(self, arg: Point2f, /) -> None: ...

    @property
    def d(self) -> Vector2f:
        """Ray direction"""

    @d.setter
    def d(self, arg: Vector2f, /) -> None: ...

    @property
    def maxt(self) -> drjit.auto.ad.Float:
        """Maximum position on the ray segment"""

    @maxt.setter
    def maxt(self, arg: drjit.auto.ad.Float, /) -> None: ...

    @property
    def time(self) -> drjit.auto.ad.Float:
        """Time value associated with this ray"""

    @time.setter
    def time(self, arg: drjit.auto.ad.Float, /) -> None: ...

    @property
    def wavelengths(self) -> UnpolarizedSpectrum:
        """Wavelength associated with the ray"""

    @wavelengths.setter
    def wavelengths(self, arg: UnpolarizedSpectrum, /) -> None: ...

    def __repr__(self) -> str: ...

    def __setitem__(self, arg0: drjit.auto.ad.Bool, arg1: Ray2f, /) -> None: ...

class Ray3d:
    """
    Simple n-dimensional ray segment data structure

    Along with the ray origin and direction, this data structure
    additionally stores a maximum ray position ``maxt``, a time value
    ``time`` as well a the wavelength information associated with the ray.
    """

    @overload
    def __init__(self) -> None:
        """Create an uninitialized ray"""

    @overload
    def __init__(self, other: Ray3d) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, o: Point3d, d: Vector3d, time: drjit.auto.ad.Float64 = 0.0, wavelengths: UnpolarizedSpectrum = ...) -> None:
        """Construct a new ray (o, d) with time"""

    @overload
    def __init__(self, o: Point3d, d: Vector3d, maxt: drjit.auto.ad.Float64, time: drjit.auto.ad.Float64, wavelengths: UnpolarizedSpectrum) -> None:
        """Construct a new ray (o, d) with bounds"""

    @overload
    def __init__(self, other: Ray3d, maxt: drjit.auto.ad.Float64) -> None:
        """Copy a ray, but change the maxt value"""

    def __call__(self, t: drjit.auto.ad.Float64) -> Point3d:
        """Return the position of a point along the ray"""

    @property
    def o(self) -> Point3d:
        """Ray origin"""

    @o.setter
    def o(self, arg: Point3d, /) -> None: ...

    @property
    def d(self) -> Vector3d:
        """Ray direction"""

    @d.setter
    def d(self, arg: Vector3d, /) -> None: ...

    @property
    def maxt(self) -> drjit.auto.ad.Float64:
        """Maximum position on the ray segment"""

    @maxt.setter
    def maxt(self, arg: drjit.auto.ad.Float64, /) -> None: ...

    @property
    def time(self) -> drjit.auto.ad.Float64:
        """Time value associated with this ray"""

    @time.setter
    def time(self, arg: drjit.auto.ad.Float64, /) -> None: ...

    @property
    def wavelengths(self) -> UnpolarizedSpectrum:
        """Wavelength associated with the ray"""

    @wavelengths.setter
    def wavelengths(self, arg: UnpolarizedSpectrum, /) -> None: ...

    def __repr__(self) -> str: ...

    def __setitem__(self, arg0: drjit.auto.ad.Bool, arg1: Ray3d, /) -> None: ...

class Ray3f:
    """
    Simple n-dimensional ray segment data structure

    Along with the ray origin and direction, this data structure
    additionally stores a maximum ray position ``maxt``, a time value
    ``time`` as well a the wavelength information associated with the ray.
    """

    @overload
    def __init__(self) -> None:
        """Create an uninitialized ray"""

    @overload
    def __init__(self, other: Ray3f) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, o: Point3f, d: Vector3f, time: drjit.auto.ad.Float = 0.0, wavelengths: UnpolarizedSpectrum = ...) -> None:
        """Construct a new ray (o, d) with time"""

    @overload
    def __init__(self, o: Point3f, d: Vector3f, maxt: drjit.auto.ad.Float, time: drjit.auto.ad.Float, wavelengths: UnpolarizedSpectrum) -> None:
        """Construct a new ray (o, d) with bounds"""

    @overload
    def __init__(self, other: Ray3f, maxt: drjit.auto.ad.Float) -> None:
        """Copy a ray, but change the maxt value"""

    def __call__(self, t: drjit.auto.ad.Float) -> Point3f:
        """Return the position of a point along the ray"""

    @property
    def o(self) -> Point3f:
        """Ray origin"""

    @o.setter
    def o(self, arg: Point3f, /) -> None: ...

    @property
    def d(self) -> Vector3f:
        """Ray direction"""

    @d.setter
    def d(self, arg: Vector3f, /) -> None: ...

    @property
    def maxt(self) -> drjit.auto.ad.Float:
        """Maximum position on the ray segment"""

    @maxt.setter
    def maxt(self, arg: drjit.auto.ad.Float, /) -> None: ...

    @property
    def time(self) -> drjit.auto.ad.Float:
        """Time value associated with this ray"""

    @time.setter
    def time(self, arg: drjit.auto.ad.Float, /) -> None: ...

    @property
    def wavelengths(self) -> UnpolarizedSpectrum:
        """Wavelength associated with the ray"""

    @wavelengths.setter
    def wavelengths(self, arg: UnpolarizedSpectrum, /) -> None: ...

    def __repr__(self) -> str: ...

    def __setitem__(self, arg0: drjit.auto.ad.Bool, arg1: Ray3f, /) -> None: ...

class RayDifferential3f(Ray3f):
    """
    Ray differential -- enhances the basic ray class with offset rays for
    two adjacent pixels on the view plane
    """

    @overload
    def __init__(self, arg: Ray3f, /) -> None: ...

    @overload
    def __init__(self) -> None:
        """Create an uninitialized ray"""

    @overload
    def __init__(self, ray: Ray3f) -> None: ...

    @overload
    def __init__(self, o: ScalarPoint3f, d: ScalarVector3f, time: float = 0.0, wavelengths: ScalarColor0f = ...) -> None:
        """Initialize without differentials."""

    def scale_differential(self, amount: float) -> None: ...

    @property
    def o_x(self) -> ScalarPoint3f: ...

    @o_x.setter
    def o_x(self, arg: ScalarPoint3f, /) -> None: ...

    @property
    def o_y(self) -> ScalarPoint3f: ...

    @o_y.setter
    def o_y(self, arg: ScalarPoint3f, /) -> None: ...

    @property
    def d_x(self) -> ScalarVector3f: ...

    @d_x.setter
    def d_x(self, arg: ScalarVector3f, /) -> None: ...

    @property
    def d_y(self) -> ScalarVector3f: ...

    @d_y.setter
    def d_y(self, arg: ScalarVector3f, /) -> None: ...

    @property
    def has_differentials(self) -> bool: ...

    @has_differentials.setter
    def has_differentials(self, arg: bool, /) -> None: ...

class RayFlags(enum.IntEnum):
    """
    This list of flags is used to determine which members of
    SurfaceInteraction should be computed when calling
    compute_surface_interaction().

    It also specifies whether the SurfaceInteraction should be
    differentiable with respect to the shapes parameters.
    """

    Empty = 0
    """No flags set"""

    Minimal = 1
    """Compute position and geometric normal"""

    UV = 2
    """Compute UV coordinates"""

    dPdUV = 4
    """Compute position partials wrt. UV coordinates"""

    dNGdUV = 16
    """Compute the geometric normal partials wrt. the UV coordinates"""

    dNSdUV = 32
    """Compute the shading normal partials wrt. the UV coordinates"""

    ShadingFrame = 8
    """Compute shading normal and shading frame"""

    FollowShape = 128
    """Derivatives of the SurfaceInteraction fields follow shape's motion"""

    DetachShape = 256
    """Derivatives of the SurfaceInteraction fields ignore shape's motion"""

    All = 14
    """//! Compound compute flags"""

    AllNonDifferentiable = 270
    """Compute all fields of the surface interaction ignoring shape's motion"""

class ReconstructionFilter(Object):
    """
    Generic interface to separable image reconstruction filters

    When resampling bitmaps or adding samples to a rendering in progress,
    Mitsuba first convolves them with a image reconstruction filter.
    Various kinds are implemented as subclasses of this interface.

    Because image filters are generally too expensive to evaluate for each
    sample, the implementation of this class internally precomputes an
    discrete representation, whose resolution given by
    MI_FILTER_RESOLUTION.
    """

    def border_size(self) -> int:
        """Return the block border size required when rendering with this filter"""

    def is_box_filter(self) -> bool:
        """Check whether this is a box filter?"""

    def radius(self) -> float:
        """Return the filter's width"""

    def eval(self, x: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """Evaluate the filter function"""

    def eval_discretized(self, x: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate a discretized version of the filter (generally faster than
        'eval')
        """

class Resampler:
    """
    Utility class for efficiently resampling discrete datasets to
    different resolutions

    Template parameter ``Scalar``:
        Denotes the underlying floating point data type (i.e. ``half``,
        ``float``, or ``double``)
    """

    def __init__(self, rfilter: BitmapReconstructionFilter, source_res: int, target_res: int) -> None:
        """
        Create a new Resampler object that transforms between the specified
        resolutions

        This constructor precomputes all information needed to efficiently
        perform the desired resampling operation. For that reason, it is most
        efficient if it can be used over and over again (e.g. to resample the
        equal-sized rows of a bitmap)

        Parameter ``source_res``:
            Source resolution

        Parameter ``target_res``:
            Desired target resolution
        """

    def source_resolution(self) -> int:
        """Return the reconstruction filter's source resolution"""

    def target_resolution(self) -> int:
        """Return the reconstruction filter's target resolution"""

    def boundary_condition(self) -> FilterBoundaryCondition:
        """
        Return the boundary condition that should be used when looking up
        samples outside of the defined input domain
        """

    def set_boundary_condition(self, arg: FilterBoundaryCondition, /) -> None:
        """
        Set the boundary condition that should be used when looking up samples
        outside of the defined input domain

        The default is FilterBoundaryCondition::Clamp
        """

    def set_clamp(self, arg: tuple[float, float], /) -> None:
        """If specified, resampled values will be clamped to the given range"""

    def taps(self) -> int:
        """Return the number of taps used by the reconstruction filter"""

    def clamp(self) -> tuple[float, float]:
        """
        Returns the range to which resampled values will be clamped

        The default is -infinity to infinity (i.e. no clamping is used)
        """

    def __repr__(self) -> str: ...

    def resample(self, source: Annotated[ArrayLike, dict(dtype='float32', order='C', device='cpu')], source_stride: int, target: Annotated[ArrayLike, dict(dtype='float32', order='C', device='cpu')], target_stride: int, channels: int) -> None:
        """
        Resample a multi-channel array and clamp the results to a specified
        valid range

        Parameter ``source``:
            Source array of samples

        Parameter ``target``:
            Target array of samples

        Parameter ``source_stride``:
            Stride of samples in the source array. A value of '1' implies that
            they are densely packed.

        Parameter ``target_stride``:
            Stride of samples in the source array. A value of '1' implies that
            they are densely packed.

        Parameter ``channels``:
            Number of channels to be resampled
        """

class SGGXPhaseFunctionParams:
    @overload
    def __init__(self, arg0: drjit.auto.ad.Array3f, arg1: drjit.auto.ad.Array3f, /) -> None:
        """
        Construct from a pair of 3D vectors [S_xx, S_yy, S_zz] and [S_xy,
        S_xz, S_yz] that correspond to the entries of a symmetric positive
        definite 3x3 matrix.
        """

    @overload
    def __init__(self, arg: SGGXPhaseFunctionParams) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, arg: list, /) -> None: ...

    @property
    def diag(self) -> drjit.auto.ad.Array3f: ...

    @diag.setter
    def diag(self, arg: drjit.auto.ad.Array3f, /) -> None: ...

    @property
    def off_diag(self) -> drjit.auto.ad.Array3f: ...

    @off_diag.setter
    def off_diag(self, arg: drjit.auto.ad.Array3f, /) -> None: ...

    def __repr__(self) -> str: ...

    def assign(self, arg: SGGXPhaseFunctionParams, /) -> None: ...

    def __setitem__(self, arg0: drjit.auto.ad.Bool, arg1: SGGXPhaseFunctionParams, /) -> None: ...

class Sampler(Object):
    r"""
    Base class of all sample generators.

    A *sampler* provides a convenient abstraction around methods that
    generate uniform pseudo- or quasi-random points within a conceptual
    infinite-dimensional unit hypercube \f$[0,1]^\infty$\f. This involves
    two main operations: by querying successive component values of such
    an infinite-dimensional point (next_1d(), next_2d()), or by discarding
    the current point and generating another one (advance()).

    Scalar and vectorized rendering algorithms interact with the sampler
    interface in a slightly different way:

    Scalar rendering algorithm:

    1. The rendering algorithm first invokes seed() to initialize the
    sampler state.

    2. The first pixel sample can now be computed, after which advance()
    needs to be invoked. This repeats until all pixel samples have been
    generated. Note that some implementations need to be configured for a
    certain number of pixel samples, and exceeding these will lead to an
    exception being thrown.

    3. While computing a pixel sample, the rendering algorithm usually
    requests 1D or 2D component blocks using the next_1d() and next_2d()
    functions before moving on to the next sample.

    A vectorized rendering algorithm effectively queries multiple sample
    generators that advance in parallel. This involves the following
    steps:

    1. The rendering algorithm invokes set_samples_per_wavefront() if each
    rendering step is split into multiple passes (in which case fewer
    samples should be returned per sample_1d() or sample_2d() call).

    2. The rendering algorithm then invokes seed() to initialize the
    sampler state, and to inform the sampler of the wavefront size, i.e.,
    how many sampler evaluations should be performed in parallel,
    accounting for all passes. The initialization ensures that the set of
    parallel samplers is mutually statistically independent (in a
    pseudo/quasi-random sense).

    3. advance() can be used to advance to the next point.

    4. As in the scalar approach, the rendering algorithm can request
    batches of (pseudo-) random numbers using the next_1d() and next_2d()
    functions.
    """

    def __init__(self, props: Properties) -> None: ...

    def fork(self) -> Sampler:
        """
        Create a fork of this sampler.

        A subsequent call to ``seed`` is necessary to properly initialize the
        internal state of the sampler.

        May throw an exception if not supported.
        """

    def clone(self) -> Sampler:
        """
        Create a clone of this sampler.

        Subsequent calls to the cloned sampler will produce the same random
        numbers as the original sampler.

        Remark:
            This method relies on the overload of the copy constructor.

        May throw an exception if not supported.
        """

    def sample_count(self) -> int:
        """Return the number of samples per pixel"""

    def wavefront_size(self) -> int:
        """Return the size of the wavefront (or 0, if not seeded)"""

    def set_samples_per_wavefront(self, samples_per_wavefront: int) -> None:
        """
        Set the number of samples per pixel per pass in wavefront modes
        (default is 1)
        """

    def set_sample_count(self, spp: int) -> None:
        """Set the number of samples per pixel"""

    def advance(self) -> None:
        """
        Advance to the next sample.

        A subsequent call to ``next_1d`` or ``next_2d`` will access the first
        1D or 2D components of this sample.
        """

    def schedule_state(self) -> None:
        """dr::schedule() variables that represent the internal sampler state"""

    def seed(self, seed: int, wavefront_size: int = 4294967295) -> None:
        """
        Deterministically seed the underlying RNG, if applicable.

        In the context of wavefront ray tracing & dynamic arrays, this
        function must be called with ``wavefront_size`` matching the size of
        the wavefront.
        """

    def next_1d(self, active: bool = True) -> float:
        """Retrieve the next component value from the current sample"""

    def next_2d(self, active: bool = True) -> ScalarPoint2f:
        """Retrieve the next two component values from the current sample"""

class SamplingIntegrator(Integrator):
    """
    Abstract integrator that performs Monte Carlo sampling starting from
    the sensor

    Subclasses of this interface must implement the sample() method, which
    performs Monte Carlo integration to return an unbiased statistical
    estimate of the radiance value along a given ray.

    The render() method then repeatedly invokes this estimator to compute
    all pixels of the image.
    """

    def __init__(self, arg: Properties, /) -> None: ...

    def sample(self, scene: Scene, sampler: Sampler, ray: RayDifferential3f, medium: Medium | None = None, active: bool = True) -> tuple[ScalarColor3f, bool, list[float]]:
        """
        Sample the incident radiance along a ray.

        Parameter ``scene``:
            The underlying scene in which the radiance function should be
            sampled

        Parameter ``sampler``:
            A source of (pseudo-/quasi-) random numbers

        Parameter ``ray``:
            A ray, optionally with differentials

        Parameter ``medium``:
            If the ray is inside a medium, this parameter holds a pointer to
            that medium

        Parameter ``aov``:
            Integrators may return one or more arbitrary output variables
            (AOVs) via this parameter. If ``nullptr`` is provided to this
            argument, no AOVs should be returned. Otherwise, the caller
            guarantees that space for at least ``aov_names().size()`` entries
            has been allocated.

        Parameter ``active``:
            A mask that indicates which SIMD lanes are active

        Returns:
            A pair containing a spectrum and a mask specifying whether a
            surface or medium interaction was sampled. False mask entries
            indicate that the ray "escaped" the scene, in which case the the
            returned spectrum contains the contribution of environment maps,
            if present. The mask can be used to estimate a suitable alpha
            channel of a rendered image.

        Remark:
            In the Python bindings, this function returns the ``aov`` output
            argument as an additional return value. In other words:

        ```
        (spec, mask, aov) = integrator.sample(scene, sampler, ray, medium, active)
        ```
        """

    @overload
    def render_forward(self, scene: Scene, params: object, sensor: Sensor, seed: int = 0, spp: int = 0) -> drjit.scalar.TensorXf: ...

    @overload
    def render_forward(self, scene: Scene, params: object, sensor: int = 0, seed: int = 0, spp: int = 0) -> drjit.scalar.TensorXf: ...

    @overload
    def render_backward(self, scene: Scene, params: object, grad_in: drjit.scalar.TensorXf, sensor: Sensor, seed: int = 0, spp: int = 0) -> None: ...

    @overload
    def render_backward(self, scene: Scene, params: object, grad_in: drjit.scalar.TensorXf, sensor: int = 0, seed: int = 0, spp: int = 0) -> None: ...

    @property
    def hide_emitters(self) -> bool: ...

    @hide_emitters.setter
    def hide_emitters(self, arg: bool, /) -> None: ...

class ScalarBoundingBox2f:
    """
    Generic n-dimensional bounding box data structure

    Maintains a minimum and maximum position along each dimension and
    provides various convenience functions for querying and modifying
    them.

    This class is parameterized by the underlying point data structure,
    which permits the use of different scalar types and dimensionalities,
    e.g.

    ```
    BoundingBox<Point3i> integer_bbox(Point3i(0, 1, 3), Point3i(4, 5, 6));
    BoundingBox<Point2d> double_bbox(Point2d(0.0, 1.0), Point2d(4.0, 5.0));
    ```

    Template parameter ``T``:
        The underlying point data type (e.g. ``Point2d``)
    """

    @overload
    def __init__(self) -> None:
        r"""
        Create a new invalid bounding box

        Initializes the components of the minimum and maximum position to
        :math:`\infty` and :math:`-\infty`, respectively.
        """

    @overload
    def __init__(self, p: ScalarPoint2f) -> None:
        """Create a collapsed bounding box from a single point"""

    @overload
    def __init__(self, min: ScalarPoint2f, max: ScalarPoint2f) -> None:
        """Create a bounding box from two positions"""

    @overload
    def __init__(self, arg: ScalarBoundingBox2f) -> None:
        """Copy constructor"""

    def valid(self) -> bool:
        """
        Check whether this is a valid bounding box

        A bounding box ``bbox`` is considered to be valid when

        ```
        bbox.min[i] <= bbox.max[i]
        ```

        holds for each component ``i``.
        """

    def collapsed(self) -> bool:
        """
        Check whether this bounding box has collapsed to a point, line, or
        plane
        """

    def major_axis(self) -> int:
        """Return the dimension index with the index associated side length"""

    def minor_axis(self) -> int:
        """Return the dimension index with the shortest associated side length"""

    def center(self) -> ScalarPoint2f:
        """Return the center point"""

    def extents(self) -> ScalarVector2f:
        """
        Calculate the bounding box extents

        Returns:
            ``max - min``
        """

    def corner(self, arg: int, /) -> ScalarPoint2f:
        """Return the position of a bounding box corner"""

    def volume(self) -> float:
        """Calculate the n-dimensional volume of the bounding box"""

    def surface_area(self) -> float:
        """Calculate the 2-dimensional surface area of a 3D bounding box"""

    @overload
    def contains(self, p: ScalarPoint2f, strict: bool = False) -> bool:
        """
        Check whether a point lies *on* or *inside* the bounding box

        Parameter ``p``:
            The point to be tested

        Template parameter ``Strict``:
            Set this parameter to ``True`` if the bounding box boundary should
            be excluded in the test

        Remark:
            In the Python bindings, the 'Strict' argument is a normal function
            parameter with default value ``False``.
        """

    @overload
    def contains(self, bbox: ScalarBoundingBox2f, strict: bool = False) -> bool:
        r"""
        Check whether a specified bounding box lies *on* or *within* the
        current bounding box

        Note that by definition, an 'invalid' bounding box (where
        min=:math:`\infty` and max=:math:`-\infty`) does not cover any space.
        Hence, this method will always return *true* when given such an
        argument.

        Template parameter ``Strict``:
            Set this parameter to ``True`` if the bounding box boundary should
            be excluded in the test

        Remark:
            In the Python bindings, the 'Strict' argument is a normal function
            parameter with default value ``False``.
        """

    def overlaps(self, bbox: ScalarBoundingBox2f, strict: bool = False) -> bool:
        """
        Check two axis-aligned bounding boxes for possible overlap.

        Parameter ``Strict``:
            Set this parameter to ``True`` if the bounding box boundary should
            be excluded in the test

        Remark:
            In the Python bindings, the 'Strict' argument is a normal function
            parameter with default value ``False``.

        Returns:
            ``True`` If overlap was detected.
        """

    @overload
    def squared_distance(self, arg: ScalarPoint2f, /) -> float:
        """
        Calculate the shortest squared distance between the axis-aligned
        bounding box and the point ``p``.
        """

    @overload
    def squared_distance(self, arg: ScalarBoundingBox2f, /) -> float:
        """
        Calculate the shortest squared distance between the axis-aligned
        bounding box and ``bbox``.
        """

    @overload
    def distance(self, arg: ScalarPoint2f, /) -> float:
        """
        Calculate the shortest distance between the axis-aligned bounding box
        and the point ``p``.
        """

    @overload
    def distance(self, arg: ScalarBoundingBox2f, /) -> float:
        """
        Calculate the shortest distance between the axis-aligned bounding box
        and ``bbox``.
        """

    def reset(self) -> None:
        r"""
        Mark the bounding box as invalid.

        This operation sets the components of the minimum and maximum position
        to :math:`\infty` and :math:`-\infty`, respectively.
        """

    def clip(self, arg: ScalarBoundingBox2f, /) -> None:
        """Clip this bounding box to another bounding box"""

    @overload
    def expand(self, arg: ScalarPoint2f, /) -> None:
        """Expand the bounding box to contain another point"""

    @overload
    def expand(self, arg: ScalarBoundingBox2f, /) -> None:
        """Expand the bounding box to contain another bounding box"""

    @staticmethod
    def merge(arg0: ScalarBoundingBox2f, arg1: ScalarBoundingBox2f, /) -> ScalarBoundingBox2f:
        """Merge two bounding boxes"""

    @property
    def min(self) -> ScalarPoint2f: ...

    @min.setter
    def min(self, arg: ScalarPoint2f, /) -> None: ...

    @property
    def max(self) -> ScalarPoint2f: ...

    @max.setter
    def max(self, arg: ScalarPoint2f, /) -> None: ...

    def __repr__(self) -> str: ...

class ScalarBoundingBox3f:
    """
    Generic n-dimensional bounding box data structure

    Maintains a minimum and maximum position along each dimension and
    provides various convenience functions for querying and modifying
    them.

    This class is parameterized by the underlying point data structure,
    which permits the use of different scalar types and dimensionalities,
    e.g.

    ```
    BoundingBox<Point3i> integer_bbox(Point3i(0, 1, 3), Point3i(4, 5, 6));
    BoundingBox<Point2d> double_bbox(Point2d(0.0, 1.0), Point2d(4.0, 5.0));
    ```

    Template parameter ``T``:
        The underlying point data type (e.g. ``Point2d``)
    """

    @overload
    def __init__(self) -> None:
        r"""
        Create a new invalid bounding box

        Initializes the components of the minimum and maximum position to
        :math:`\infty` and :math:`-\infty`, respectively.
        """

    @overload
    def __init__(self, p: ScalarPoint3f) -> None:
        """Create a collapsed bounding box from a single point"""

    @overload
    def __init__(self, min: ScalarPoint3f, max: ScalarPoint3f) -> None:
        """Create a bounding box from two positions"""

    @overload
    def __init__(self, arg: ScalarBoundingBox3f) -> None:
        """Copy constructor"""

    def valid(self) -> bool:
        """
        Check whether this is a valid bounding box

        A bounding box ``bbox`` is considered to be valid when

        ```
        bbox.min[i] <= bbox.max[i]
        ```

        holds for each component ``i``.
        """

    def collapsed(self) -> bool:
        """
        Check whether this bounding box has collapsed to a point, line, or
        plane
        """

    def major_axis(self) -> int:
        """Return the dimension index with the index associated side length"""

    def minor_axis(self) -> int:
        """Return the dimension index with the shortest associated side length"""

    def center(self) -> ScalarPoint3f:
        """Return the center point"""

    def extents(self) -> ScalarVector3f:
        """
        Calculate the bounding box extents

        Returns:
            ``max - min``
        """

    def corner(self, arg: int, /) -> ScalarPoint3f:
        """Return the position of a bounding box corner"""

    def volume(self) -> float:
        """Calculate the n-dimensional volume of the bounding box"""

    def surface_area(self) -> float:
        """Calculate the 2-dimensional surface area of a 3D bounding box"""

    @overload
    def contains(self, p: ScalarPoint3f, strict: bool = False) -> bool:
        """
        Check whether a point lies *on* or *inside* the bounding box

        Parameter ``p``:
            The point to be tested

        Template parameter ``Strict``:
            Set this parameter to ``True`` if the bounding box boundary should
            be excluded in the test

        Remark:
            In the Python bindings, the 'Strict' argument is a normal function
            parameter with default value ``False``.
        """

    @overload
    def contains(self, bbox: ScalarBoundingBox3f, strict: bool = False) -> bool:
        r"""
        Check whether a specified bounding box lies *on* or *within* the
        current bounding box

        Note that by definition, an 'invalid' bounding box (where
        min=:math:`\infty` and max=:math:`-\infty`) does not cover any space.
        Hence, this method will always return *true* when given such an
        argument.

        Template parameter ``Strict``:
            Set this parameter to ``True`` if the bounding box boundary should
            be excluded in the test

        Remark:
            In the Python bindings, the 'Strict' argument is a normal function
            parameter with default value ``False``.
        """

    def overlaps(self, bbox: ScalarBoundingBox3f, strict: bool = False) -> bool:
        """
        Check two axis-aligned bounding boxes for possible overlap.

        Parameter ``Strict``:
            Set this parameter to ``True`` if the bounding box boundary should
            be excluded in the test

        Remark:
            In the Python bindings, the 'Strict' argument is a normal function
            parameter with default value ``False``.

        Returns:
            ``True`` If overlap was detected.
        """

    @overload
    def squared_distance(self, arg: ScalarPoint3f, /) -> float:
        """
        Calculate the shortest squared distance between the axis-aligned
        bounding box and the point ``p``.
        """

    @overload
    def squared_distance(self, arg: ScalarBoundingBox3f, /) -> float:
        """
        Calculate the shortest squared distance between the axis-aligned
        bounding box and ``bbox``.
        """

    @overload
    def distance(self, arg: ScalarPoint3f, /) -> float:
        """
        Calculate the shortest distance between the axis-aligned bounding box
        and the point ``p``.
        """

    @overload
    def distance(self, arg: ScalarBoundingBox3f, /) -> float:
        """
        Calculate the shortest distance between the axis-aligned bounding box
        and ``bbox``.
        """

    def reset(self) -> None:
        r"""
        Mark the bounding box as invalid.

        This operation sets the components of the minimum and maximum position
        to :math:`\infty` and :math:`-\infty`, respectively.
        """

    def clip(self, arg: ScalarBoundingBox3f, /) -> None:
        """Clip this bounding box to another bounding box"""

    @overload
    def expand(self, arg: ScalarPoint3f, /) -> None:
        """Expand the bounding box to contain another point"""

    @overload
    def expand(self, arg: ScalarBoundingBox3f, /) -> None:
        """Expand the bounding box to contain another bounding box"""

    @staticmethod
    def merge(arg0: ScalarBoundingBox3f, arg1: ScalarBoundingBox3f, /) -> ScalarBoundingBox3f:
        """Merge two bounding boxes"""

    @property
    def min(self) -> ScalarPoint3f: ...

    @min.setter
    def min(self, arg: ScalarPoint3f, /) -> None: ...

    @property
    def max(self) -> ScalarPoint3f: ...

    @max.setter
    def max(self, arg: ScalarPoint3f, /) -> None: ...

    def __repr__(self) -> str: ...

    def ray_intersect(self, ray: Ray3f) -> tuple[drjit.auto.ad.Bool, drjit.auto.ad.Float, drjit.auto.ad.Float]:
        """
        Check if a ray intersects a bounding box

        Note that this function ignores the ``maxt`` value associated with the
        ray.
        """

    def bounding_sphere(self) -> ScalarBoundingSphere3f:
        """Create a bounding sphere, which contains the axis-aligned box"""

class ScalarBoundingSphere3f:
    """Generic n-dimensional bounding sphere data structure"""

    @overload
    def __init__(self) -> None:
        """Construct bounding sphere(s) at the origin having radius zero"""

    @overload
    def __init__(self, arg0: ScalarPoint3f, arg1: float, /) -> None:
        """
        Create bounding sphere(s) from given center point(s) with given
        size(s)
        """

    @overload
    def __init__(self, arg: ScalarBoundingSphere3f) -> None: ...

    def empty(self) -> bool:
        """Return whether this bounding sphere has a radius of zero or less."""

    def contains(self, p: ScalarPoint3f, strict: bool = False) -> bool:
        """
        Check whether a point lies *on* or *inside* the bounding sphere

        Parameter ``p``:
            The point to be tested

        Template parameter ``Strict``:
            Set this parameter to ``True`` if the bounding sphere boundary
            should be excluded in the test

        Remark:
            In the Python bindings, the 'Strict' argument is a normal function
            parameter with default value ``False``.
        """

    def expand(self, arg: ScalarPoint3f, /) -> None:
        """Expand the bounding sphere radius to contain another point."""

    def ray_intersect(self, ray: Ray3f) -> tuple[drjit.auto.ad.Bool, drjit.auto.ad.Float, drjit.auto.ad.Float]:
        """Check if a ray intersects a bounding box"""

    @property
    def center(self) -> ScalarPoint3f: ...

    @center.setter
    def center(self, arg: ScalarPoint3f, /) -> None: ...

    @property
    def radius(self) -> float: ...

    @radius.setter
    def radius(self, arg: float, /) -> None: ...

    def __repr__(self) -> str: ...

class ScalarColor0d(drjit.ArrayBase[ScalarColor0d, _ScalarColor0dCp, float, float, float, ScalarColor0d, drjit.scalar.Array0b]):
    pass

class ScalarColor0f(drjit.ArrayBase[ScalarColor0f, _ScalarColor0fCp, float, float, float, ScalarColor0f, drjit.scalar.Array0b]):
    pass

class ScalarColor1d(drjit.ArrayBase[ScalarColor1d, _ScalarColor1dCp, float, float, float, ScalarColor1d, drjit.scalar.Array1b]):
    pass

class ScalarColor1f(drjit.ArrayBase[ScalarColor1f, _ScalarColor1fCp, float, float, float, ScalarColor1f, drjit.scalar.Array1b]):
    pass

class ScalarColor3d(drjit.ArrayBase[ScalarColor3d, _ScalarColor3dCp, float, float, float, ScalarColor3d, drjit.scalar.Array3b]):
    pass

class ScalarColor3f(drjit.ArrayBase[ScalarColor3f, _ScalarColor3fCp, float, float, float, ScalarColor3f, drjit.scalar.Array3b]):
    pass

class ScalarNormal3d(drjit.ArrayBase[ScalarNormal3d, _ScalarNormal3dCp, float, float, float, ScalarNormal3d, drjit.scalar.Array3b]):
    pass

class ScalarNormal3f(drjit.ArrayBase[ScalarNormal3f, _ScalarNormal3fCp, float, float, float, ScalarNormal3f, drjit.scalar.Array3b]):
    pass

class ScalarPoint0d(drjit.ArrayBase[ScalarPoint0d, _ScalarPoint0dCp, float, float, float, ScalarPoint0d, drjit.scalar.Array0b]):
    pass

class ScalarPoint0f(drjit.ArrayBase[ScalarPoint0f, _ScalarPoint0fCp, float, float, float, ScalarPoint0f, drjit.scalar.Array0b]):
    pass

class ScalarPoint0i(drjit.ArrayBase[ScalarPoint0i, _ScalarPoint0iCp, int, int, int, ScalarPoint0i, drjit.scalar.Array0b]):
    pass

class ScalarPoint0u(drjit.ArrayBase[ScalarPoint0u, _ScalarPoint0uCp, int, int, int, ScalarPoint0u, drjit.scalar.Array0b]):
    pass

class ScalarPoint1d(drjit.ArrayBase[ScalarPoint1d, _ScalarPoint1dCp, float, float, float, ScalarPoint1d, drjit.scalar.Array1b]):
    pass

class ScalarPoint1f(drjit.ArrayBase[ScalarPoint1f, _ScalarPoint1fCp, float, float, float, ScalarPoint1f, drjit.scalar.Array1b]):
    pass

class ScalarPoint1i(drjit.ArrayBase[ScalarPoint1i, _ScalarPoint1iCp, int, int, int, ScalarPoint1i, drjit.scalar.Array1b]):
    pass

class ScalarPoint1u(drjit.ArrayBase[ScalarPoint1u, _ScalarPoint1uCp, int, int, int, ScalarPoint1u, drjit.scalar.Array1b]):
    pass

class ScalarPoint2d(drjit.ArrayBase[ScalarPoint2d, _ScalarPoint2dCp, float, float, float, ScalarPoint2d, drjit.scalar.Array2b]):
    pass

class ScalarPoint2f(drjit.ArrayBase[ScalarPoint2f, _ScalarPoint2fCp, float, float, float, ScalarPoint2f, drjit.scalar.Array2b]):
    pass

class ScalarPoint2i(drjit.ArrayBase[ScalarPoint2i, _ScalarPoint2iCp, int, int, int, ScalarPoint2i, drjit.scalar.Array2b]):
    pass

class ScalarPoint2u(drjit.ArrayBase[ScalarPoint2u, _ScalarPoint2uCp, int, int, int, ScalarPoint2u, drjit.scalar.Array2b]):
    pass

class ScalarPoint3d(drjit.ArrayBase[ScalarPoint3d, _ScalarPoint3dCp, float, float, float, ScalarPoint3d, drjit.scalar.Array3b]):
    pass

class ScalarPoint3f(drjit.ArrayBase[ScalarPoint3f, _ScalarPoint3fCp, float, float, float, ScalarPoint3f, drjit.scalar.Array3b]):
    pass

class ScalarPoint3i(drjit.ArrayBase[ScalarPoint3i, _ScalarPoint3iCp, int, int, int, ScalarPoint3i, drjit.scalar.Array3b]):
    pass

class ScalarPoint3u(drjit.ArrayBase[ScalarPoint3u, _ScalarPoint3uCp, int, int, int, ScalarPoint3u, drjit.scalar.Array3b]):
    pass

class ScalarPoint4d(drjit.ArrayBase[ScalarPoint4d, _ScalarPoint4dCp, float, float, float, ScalarPoint4d, drjit.scalar.Array4b]):
    pass

class ScalarPoint4f(drjit.ArrayBase[ScalarPoint4f, _ScalarPoint4fCp, float, float, float, ScalarPoint4f, drjit.scalar.Array4b]):
    pass

class ScalarPoint4i(drjit.ArrayBase[ScalarPoint4i, _ScalarPoint4iCp, int, int, int, ScalarPoint4i, drjit.scalar.Array4b]):
    pass

class ScalarPoint4u(drjit.ArrayBase[ScalarPoint4u, _ScalarPoint4uCp, int, int, int, ScalarPoint4u, drjit.scalar.Array4b]):
    pass

class ScalarTransform3d:
    """
    Encapsulates a 4x4 homogeneous coordinate transformation along with
    its inverse transpose

    The Transform class provides a set of overloaded matrix-vector
    multiplication operators for vectors, points, and normals (all of them
    behave differently under homogeneous coordinate transformations, hence
    the need to represent them using separate types)
    """

    @overload
    def __init__(self) -> None:
        """Initialize with the identity matrix"""

    @overload
    def __init__(self, arg: ScalarTransform3d) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, arg: Annotated[ArrayLike, dict(dtype='float64', shape=(3, 3), order='C', device='cpu')], /) -> None: ...

    @overload
    def __init__(self) -> None: ...

    @overload
    def __init__(self, arg: drjit.scalar.Matrix3f64, /) -> None:
        """
        Initialize the transformation from the given matrix (and compute its
        inverse transpose)
        """

    @overload
    def __init__(self, arg0: drjit.scalar.Matrix3f64, arg1: drjit.scalar.Matrix3f64, /) -> None:
        """Initialize from a matrix and its inverse transpose"""

    def __mul__(self, arg: ScalarTransform3d, /) -> None: ...

    @overload
    def __matmul__(self, arg: ScalarTransform3d, /) -> ScalarTransform3d: ...

    @overload
    def __matmul__(self, arg: ScalarPoint2d, /) -> ScalarPoint2d: ...

    @overload
    def __matmul__(self, arg: ScalarVector2d, /) -> ScalarVector2d: ...

    @overload
    def __matmul__(self, arg: "mitsuba::Ray<mitsuba::Point<double, 2ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >", /) -> "mitsuba::Ray<mitsuba::Point<double, 2ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >": ...

    @overload
    def transform_affine(self, p: ScalarPoint2d) -> ScalarPoint2d:
        """
        Transform a 3D vector/point/normal/ray by a transformation that is
        known to be an affine 3D transformation (i.e. no perspective)
        """

    @overload
    def transform_affine(self, v: ScalarVector2d) -> ScalarVector2d: ...

    @overload
    def transform_affine(self, ray: "mitsuba::Ray<mitsuba::Point<double, 2ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >") -> "mitsuba::Ray<mitsuba::Point<double, 2ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >": ...

    def translate(self, v: ScalarPoint2d) -> ScalarTransform3d:
        """Create a translation transformation"""

    def scale(self, v: ScalarPoint2d) -> ScalarTransform3d:
        """Create a scale transformation"""

    def rotate(self, angle: float) -> ScalarTransform3d:
        """
        Create a rotation transformation in 2D. The angle is specified in
        degrees
        """

    def inverse(self) -> ScalarTransform3d:
        """
        Compute the inverse of this transformation (involves just shuffles, no
        arithmetic)
        """

    def translation(self) -> ScalarVector2d:
        """Get the translation part of a matrix"""

    def has_scale(self) -> bool:
        """
        Test for a scale component in each transform matrix by checking
        whether ``M . M^T == I`` (where ``M`` is the matrix in question and
        ``I`` is the identity).
        """

    @property
    def matrix(self) -> drjit.scalar.Matrix3f64: ...

    @matrix.setter
    def matrix(self, arg: drjit.scalar.Matrix3f64, /) -> None: ...

    @property
    def inverse_transpose(self) -> drjit.scalar.Matrix3f64: ...

    @inverse_transpose.setter
    def inverse_transpose(self, arg: drjit.scalar.Matrix3f64, /) -> None: ...

    def __repr__(self) -> str: ...

    def assign(self, arg: ScalarTransform3d, /) -> None: ...

    def __setitem__(self, arg0: bool, arg1: ScalarTransform3d, /) -> None: ...

class ScalarTransform3f:
    """
    Encapsulates a 4x4 homogeneous coordinate transformation along with
    its inverse transpose

    The Transform class provides a set of overloaded matrix-vector
    multiplication operators for vectors, points, and normals (all of them
    behave differently under homogeneous coordinate transformations, hence
    the need to represent them using separate types)
    """

    @overload
    def __init__(self) -> None:
        """Initialize with the identity matrix"""

    @overload
    def __init__(self, arg: ScalarTransform3f) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, arg: Annotated[ArrayLike, dict(dtype='float32', shape=(3, 3), order='C', device='cpu')], /) -> None: ...

    @overload
    def __init__(self) -> None: ...

    @overload
    def __init__(self, arg: drjit.scalar.Matrix3f, /) -> None:
        """
        Initialize the transformation from the given matrix (and compute its
        inverse transpose)
        """

    @overload
    def __init__(self, arg0: drjit.scalar.Matrix3f, arg1: drjit.scalar.Matrix3f, /) -> None:
        """Initialize from a matrix and its inverse transpose"""

    def __mul__(self, arg: ScalarTransform3f, /) -> None: ...

    @overload
    def __matmul__(self, arg: ScalarTransform3f, /) -> ScalarTransform3f: ...

    @overload
    def __matmul__(self, arg: ScalarPoint2f, /) -> ScalarPoint2f: ...

    @overload
    def __matmul__(self, arg: ScalarVector2f, /) -> ScalarVector2f: ...

    @overload
    def __matmul__(self, arg: "mitsuba::Ray<mitsuba::Point<float, 2ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >", /) -> "mitsuba::Ray<mitsuba::Point<float, 2ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >": ...

    @overload
    def transform_affine(self, p: ScalarPoint2f) -> ScalarPoint2f:
        """
        Transform a 3D vector/point/normal/ray by a transformation that is
        known to be an affine 3D transformation (i.e. no perspective)
        """

    @overload
    def transform_affine(self, v: ScalarVector2f) -> ScalarVector2f: ...

    @overload
    def transform_affine(self, ray: "mitsuba::Ray<mitsuba::Point<float, 2ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >") -> "mitsuba::Ray<mitsuba::Point<float, 2ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >": ...

    def translate(self, v: ScalarPoint2f) -> ScalarTransform3f:
        """Create a translation transformation"""

    def scale(self, v: ScalarPoint2f) -> ScalarTransform3f:
        """Create a scale transformation"""

    def rotate(self, angle: float) -> ScalarTransform3f:
        """
        Create a rotation transformation in 2D. The angle is specified in
        degrees
        """

    def inverse(self) -> ScalarTransform3f:
        """
        Compute the inverse of this transformation (involves just shuffles, no
        arithmetic)
        """

    def translation(self) -> ScalarVector2f:
        """Get the translation part of a matrix"""

    def has_scale(self) -> bool:
        """
        Test for a scale component in each transform matrix by checking
        whether ``M . M^T == I`` (where ``M`` is the matrix in question and
        ``I`` is the identity).
        """

    @property
    def matrix(self) -> drjit.scalar.Matrix3f: ...

    @matrix.setter
    def matrix(self, arg: drjit.scalar.Matrix3f, /) -> None: ...

    @property
    def inverse_transpose(self) -> drjit.scalar.Matrix3f: ...

    @inverse_transpose.setter
    def inverse_transpose(self, arg: drjit.scalar.Matrix3f, /) -> None: ...

    def __repr__(self) -> str: ...

    def assign(self, arg: ScalarTransform3f, /) -> None: ...

    def __setitem__(self, arg0: bool, arg1: ScalarTransform3f, /) -> None: ...

class ScalarTransform4d:
    """
    Encapsulates a 4x4 homogeneous coordinate transformation along with
    its inverse transpose

    The Transform class provides a set of overloaded matrix-vector
    multiplication operators for vectors, points, and normals (all of them
    behave differently under homogeneous coordinate transformations, hence
    the need to represent them using separate types)
    """

    @overload
    def __init__(self) -> None:
        """Initialize with the identity matrix"""

    @overload
    def __init__(self, arg: ScalarTransform4d) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, arg: Annotated[ArrayLike, dict(dtype='float64', shape=(4, 4), order='C', device='cpu')], /) -> None: ...

    @overload
    def __init__(self, arg: list, /) -> None: ...

    @overload
    def __init__(self, arg: drjit.scalar.Matrix4f64, /) -> None:
        """
        Initialize the transformation from the given matrix (and compute its
        inverse transpose)
        """

    @overload
    def __init__(self, arg0: drjit.scalar.Matrix4f64, arg1: drjit.scalar.Matrix4f64, /) -> None:
        """Initialize from a matrix and its inverse transpose"""

    def translation(self) -> ScalarVector3d:
        """Get the translation part of a matrix"""

    def extract(self) -> ScalarTransform3d:
        """Extract a lower-dimensional submatrix"""

    def __mul__(self, arg: ScalarTransform4d, /) -> None: ...

    @overload
    def __matmul__(self, arg: ScalarTransform4d, /) -> ScalarTransform4d: ...

    @overload
    def __matmul__(self, arg: ScalarPoint3d, /) -> ScalarPoint3d: ...

    @overload
    def __matmul__(self, arg: ScalarVector3d, /) -> ScalarVector3d: ...

    @overload
    def __matmul__(self, arg: ScalarNormal3d, /) -> ScalarNormal3d: ...

    @overload
    def __matmul__(self, arg: "mitsuba::Ray<mitsuba::Point<double, 3ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >", /) -> "mitsuba::Ray<mitsuba::Point<double, 3ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >": ...

    @overload
    def transform_affine(self, p: ScalarPoint3d) -> ScalarPoint3d:
        """
        Transform a 3D vector/point/normal/ray by a transformation that is
        known to be an affine 3D transformation (i.e. no perspective)
        """

    @overload
    def transform_affine(self, ray: "mitsuba::Ray<mitsuba::Point<double, 3ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >") -> "mitsuba::Ray<mitsuba::Point<double, 3ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >": ...

    @overload
    def transform_affine(self, v: ScalarVector3d) -> ScalarVector3d: ...

    @overload
    def transform_affine(self, n: ScalarNormal3d) -> ScalarNormal3d: ...

    def translate(self, v: ScalarPoint3d) -> ScalarTransform4d:
        """Create a translation transformation"""

    def scale(self, v: ScalarPoint3d) -> ScalarTransform4d:
        """Create a scale transformation"""

    def rotate(self, axis: ScalarPoint3d, angle: float) -> ScalarTransform4d:
        """
        Create a rotation transformation around an arbitrary axis in 3D. The
        angle is specified in degrees
        """

    def perspective(self, fov: float, near: float, far: float) -> ScalarTransform4d:
        """
        Create a perspective transformation. (Maps [near, far] to [0, 1])

        Projects vectors in camera space onto a plane at z=1:

        x_proj = x / z y_proj = y / z z_proj = (far * (z - near)) / (z * (far-
        near))

        Camera-space depths are not mapped linearly!

        Parameter ``fov``:
            Field of view in degrees

        Parameter ``near``:
            Near clipping plane

        Parameter ``far``:
            Far clipping plane
        """

    def orthographic(self, near: float, far: float) -> ScalarTransform4d:
        """
        Create an orthographic transformation, which maps Z to [0,1] and
        leaves the X and Y coordinates untouched.

        Parameter ``near``:
            Near clipping plane

        Parameter ``far``:
            Far clipping plane
        """

    def look_at(self, origin: ScalarPoint3d, target: ScalarPoint3d, up: ScalarPoint3d) -> ScalarTransform4d:
        """
        Create a look-at camera transformation

        Parameter ``origin``:
            Camera position

        Parameter ``target``:
            Target vector

        Parameter ``up``:
            Up vector
        """

    def from_frame(self, frame: "mitsuba::Frame<double>") -> ScalarTransform4d:
        """
        Creates a transformation that converts from 'frame' to the standard
        basis
        """

    def to_frame(self, frame: "mitsuba::Frame<double>") -> ScalarTransform4d:
        """
        Creates a transformation that converts from the standard basis to
        'frame'
        """

    def inverse(self) -> ScalarTransform4d:
        """
        Compute the inverse of this transformation (involves just shuffles, no
        arithmetic)
        """

    def has_scale(self) -> bool:
        """
        Test for a scale component in each transform matrix by checking
        whether ``M . M^T == I`` (where ``M`` is the matrix in question and
        ``I`` is the identity).
        """

    @property
    def matrix(self) -> drjit.scalar.Matrix4f64: ...

    @matrix.setter
    def matrix(self, arg: drjit.scalar.Matrix4f64, /) -> None: ...

    @property
    def inverse_transpose(self) -> drjit.scalar.Matrix4f64: ...

    @inverse_transpose.setter
    def inverse_transpose(self, arg: drjit.scalar.Matrix4f64, /) -> None: ...

    def __repr__(self) -> str: ...

    def assign(self, arg: ScalarTransform4d, /) -> None: ...

    def __setitem__(self, arg0: bool, arg1: ScalarTransform4d, /) -> None: ...

class ScalarTransform4f:
    """
    Encapsulates a 4x4 homogeneous coordinate transformation along with
    its inverse transpose

    The Transform class provides a set of overloaded matrix-vector
    multiplication operators for vectors, points, and normals (all of them
    behave differently under homogeneous coordinate transformations, hence
    the need to represent them using separate types)
    """

    @overload
    def __init__(self) -> None:
        """Initialize with the identity matrix"""

    @overload
    def __init__(self, arg: ScalarTransform4f) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, arg: Annotated[ArrayLike, dict(dtype='float32', shape=(4, 4), order='C', device='cpu')], /) -> None: ...

    @overload
    def __init__(self, arg: list, /) -> None: ...

    @overload
    def __init__(self, arg: drjit.scalar.Matrix4f, /) -> None:
        """
        Initialize the transformation from the given matrix (and compute its
        inverse transpose)
        """

    @overload
    def __init__(self, arg0: drjit.scalar.Matrix4f, arg1: drjit.scalar.Matrix4f, /) -> None:
        """Initialize from a matrix and its inverse transpose"""

    def translation(self) -> ScalarVector3f:
        """Get the translation part of a matrix"""

    def extract(self) -> ScalarTransform3f:
        """Extract a lower-dimensional submatrix"""

    def __mul__(self, arg: ScalarTransform4f, /) -> None: ...

    @overload
    def __matmul__(self, arg: ScalarTransform4f, /) -> ScalarTransform4f: ...

    @overload
    def __matmul__(self, arg: ScalarPoint3f, /) -> ScalarPoint3f: ...

    @overload
    def __matmul__(self, arg: ScalarVector3f, /) -> ScalarVector3f: ...

    @overload
    def __matmul__(self, arg: ScalarNormal3f, /) -> ScalarNormal3f: ...

    @overload
    def __matmul__(self, arg: "mitsuba::Ray<mitsuba::Point<float, 3ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >", /) -> "mitsuba::Ray<mitsuba::Point<float, 3ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >": ...

    @overload
    def transform_affine(self, p: ScalarPoint3f) -> ScalarPoint3f:
        """
        Transform a 3D vector/point/normal/ray by a transformation that is
        known to be an affine 3D transformation (i.e. no perspective)
        """

    @overload
    def transform_affine(self, ray: "mitsuba::Ray<mitsuba::Point<float, 3ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >") -> "mitsuba::Ray<mitsuba::Point<float, 3ul>, drjit::Matrix<mitsuba::Spectrum<float, 4ul>, 4ul> >": ...

    @overload
    def transform_affine(self, v: ScalarVector3f) -> ScalarVector3f: ...

    @overload
    def transform_affine(self, n: ScalarNormal3f) -> ScalarNormal3f: ...

    def translate(self, v: ScalarPoint3f) -> ScalarTransform4f:
        """Create a translation transformation"""

    def scale(self, v: ScalarPoint3f) -> ScalarTransform4f:
        """Create a scale transformation"""

    def rotate(self, axis: ScalarPoint3f, angle: float) -> ScalarTransform4f:
        """
        Create a rotation transformation around an arbitrary axis in 3D. The
        angle is specified in degrees
        """

    def perspective(self, fov: float, near: float, far: float) -> ScalarTransform4f:
        """
        Create a perspective transformation. (Maps [near, far] to [0, 1])

        Projects vectors in camera space onto a plane at z=1:

        x_proj = x / z y_proj = y / z z_proj = (far * (z - near)) / (z * (far-
        near))

        Camera-space depths are not mapped linearly!

        Parameter ``fov``:
            Field of view in degrees

        Parameter ``near``:
            Near clipping plane

        Parameter ``far``:
            Far clipping plane
        """

    def orthographic(self, near: float, far: float) -> ScalarTransform4f:
        """
        Create an orthographic transformation, which maps Z to [0,1] and
        leaves the X and Y coordinates untouched.

        Parameter ``near``:
            Near clipping plane

        Parameter ``far``:
            Far clipping plane
        """

    def look_at(self, origin: ScalarPoint3f, target: ScalarPoint3f, up: ScalarPoint3f) -> ScalarTransform4f:
        """
        Create a look-at camera transformation

        Parameter ``origin``:
            Camera position

        Parameter ``target``:
            Target vector

        Parameter ``up``:
            Up vector
        """

    def from_frame(self, frame: Frame3f) -> ScalarTransform4f:
        """
        Creates a transformation that converts from 'frame' to the standard
        basis
        """

    def to_frame(self, frame: Frame3f) -> ScalarTransform4f:
        """
        Creates a transformation that converts from the standard basis to
        'frame'
        """

    def inverse(self) -> ScalarTransform4f:
        """
        Compute the inverse of this transformation (involves just shuffles, no
        arithmetic)
        """

    def has_scale(self) -> bool:
        """
        Test for a scale component in each transform matrix by checking
        whether ``M . M^T == I`` (where ``M`` is the matrix in question and
        ``I`` is the identity).
        """

    @property
    def matrix(self) -> drjit.scalar.Matrix4f: ...

    @matrix.setter
    def matrix(self, arg: drjit.scalar.Matrix4f, /) -> None: ...

    @property
    def inverse_transpose(self) -> drjit.scalar.Matrix4f: ...

    @inverse_transpose.setter
    def inverse_transpose(self, arg: drjit.scalar.Matrix4f, /) -> None: ...

    def __repr__(self) -> str: ...

    def assign(self, arg: ScalarTransform4f, /) -> None: ...

    def __setitem__(self, arg0: bool, arg1: ScalarTransform4f, /) -> None: ...

class ScalarVector0d(drjit.ArrayBase[ScalarVector0d, _ScalarVector0dCp, float, float, float, ScalarVector0d, drjit.scalar.Array0b]):
    pass

class ScalarVector0f(drjit.ArrayBase[ScalarVector0f, _ScalarVector0fCp, float, float, float, ScalarVector0f, drjit.scalar.Array0b]):
    pass

class ScalarVector0i(drjit.ArrayBase[ScalarVector0i, _ScalarVector0iCp, int, int, int, ScalarVector0i, drjit.scalar.Array0b]):
    pass

class ScalarVector0u(drjit.ArrayBase[ScalarVector0u, _ScalarVector0uCp, int, int, int, ScalarVector0u, drjit.scalar.Array0b]):
    pass

class ScalarVector1d(drjit.ArrayBase[ScalarVector1d, _ScalarVector1dCp, float, float, float, ScalarVector1d, drjit.scalar.Array1b]):
    pass

class ScalarVector1f(drjit.ArrayBase[ScalarVector1f, _ScalarVector1fCp, float, float, float, ScalarVector1f, drjit.scalar.Array1b]):
    pass

class ScalarVector1i(drjit.ArrayBase[ScalarVector1i, _ScalarVector1iCp, int, int, int, ScalarVector1i, drjit.scalar.Array1b]):
    pass

class ScalarVector1u(drjit.ArrayBase[ScalarVector1u, _ScalarVector1uCp, int, int, int, ScalarVector1u, drjit.scalar.Array1b]):
    pass

class ScalarVector2d(drjit.ArrayBase[ScalarVector2d, _ScalarVector2dCp, float, float, float, ScalarVector2d, drjit.scalar.Array2b]):
    pass

class ScalarVector2f(drjit.ArrayBase[ScalarVector2f, _ScalarVector2fCp, float, float, float, ScalarVector2f, drjit.scalar.Array2b]):
    pass

class ScalarVector2i(drjit.ArrayBase[ScalarVector2i, _ScalarVector2iCp, int, int, int, ScalarVector2i, drjit.scalar.Array2b]):
    pass

class ScalarVector2u(drjit.ArrayBase[ScalarVector2u, _ScalarVector2uCp, int, int, int, ScalarVector2u, drjit.scalar.Array2b]):
    pass

class ScalarVector3d(drjit.ArrayBase[ScalarVector3d, _ScalarVector3dCp, float, float, float, ScalarVector3d, drjit.scalar.Array3b]):
    pass

class ScalarVector3f(drjit.ArrayBase[ScalarVector3f, _ScalarVector3fCp, float, float, float, ScalarVector3f, drjit.scalar.Array3b]):
    pass

class ScalarVector3i(drjit.ArrayBase[ScalarVector3i, _ScalarVector3iCp, int, int, int, ScalarVector3i, drjit.scalar.Array3b]):
    pass

class ScalarVector3u(drjit.ArrayBase[ScalarVector3u, _ScalarVector3uCp, int, int, int, ScalarVector3u, drjit.scalar.Array3b]):
    pass

class ScalarVector4d(drjit.ArrayBase[ScalarVector4d, _ScalarVector4dCp, float, float, float, ScalarVector4d, drjit.scalar.Array4b]):
    pass

class ScalarVector4f(drjit.ArrayBase[ScalarVector4f, _ScalarVector4fCp, float, float, float, ScalarVector4f, drjit.scalar.Array4b]):
    pass

class ScalarVector4i(drjit.ArrayBase[ScalarVector4i, _ScalarVector4iCp, int, int, int, ScalarVector4i, drjit.scalar.Array4b]):
    pass

class ScalarVector4u(drjit.ArrayBase[ScalarVector4u, _ScalarVector4uCp, int, int, int, ScalarVector4u, drjit.scalar.Array4b]):
    pass

class Scene(Object):
    r"""
    Central scene data structure

    Mitsuba's scene class encapsulates a tree of mitsuba Object instances
    including emitters, sensors, shapes, materials, participating media,
    the integrator (i.e. the method used to render the image) etc.

    It organizes these objects into groups that can be accessed through
    getters (see shapes(), emitters(), sensors(), etc.), and it provides
    three key abstractions implemented on top of these groups,
    specifically:

    * Ray intersection queries and shadow ray tests (See
    \ray_intersect_preliminary(), ray_intersect(), and ray_test()).

    * Sampling rays approximately proportional to the emission profile of
    light sources in the scene (see sample_emitter_ray())

    * Sampling directions approximately proportional to the direct
    radiance from emitters received at a given scene location (see
    sample_emitter_direction()).
    """

    def __init__(self, arg: Properties, /) -> None: ...

    def ray_intersect_preliminary(self, ray: Ray3f, coherent: bool = False, active: bool = True) -> PreliminaryIntersection3f:
        """
        Intersect a ray with the shapes comprising the scene and return
        preliminary information, if one is found

        This function invokes the ray tracing backend underlying the current
        variant (i.e., Mitsuba's builtin kd-tree, Embree, or OptiX) and
        returns preliminary intersection information consisting of

        * the ray distance up to the intersection (if one is found).

        * the intersected shape and primitive index.

        * local UV coordinates of the intersection within the primitive.

        * A pointer to the intersected shape or instance.

        The information is only preliminary at this point, because it lacks
        various other information (geometric and shading frame, texture
        coordinates, curvature, etc.) that is generally needed by shading
        models. In variants of Mitsuba that perform automatic differentiation,
        it is important to know that computation done by the ray tracing
        backend is not reflected in Dr.Jit's computation graph. The
        ray_intersect() method will re-evaluate certain parts of the
        computation with derivative tracking to rectify this.

        In vectorized variants of Mitsuba (``cuda_*`` or ``llvm_*``), the
        function processes arrays of rays and returns arrays of preliminary
        intersection records following the usual conventions.

        The ``coherent`` flag is a hint that can improve performance if the
        input set of rays is coherent (e.g., when they are generated by
        Sensor::sample_ray(), which means that adjacent rays will traverse
        essentially the same region of space). This flag is currently only
        used by the combination of ``llvm_*`` variants and the Embree ray
        intersector.

        Parameter ``ray``:
            A 3D ray including maximum extent (Ray::maxt) and time (Ray::time)
            information, which matters when the shapes are in motion

        Parameter ``coherent``:
            Setting this flag to ``True`` can noticeably improve performance
            when ``ray`` contains a coherent set of rays (e.g. primary camera
            rays), and when using ``llvm_*`` variants of the renderer along
            with Embree. It has no effect in scalar or CUDA/OptiX variants.

        Returns:
            A preliminary surface interaction record. Its ``is_valid()``
            method should be queried to check if an intersection was actually
            found.
        """

    @overload
    def ray_intersect(self, ray: Ray3f, active: bool = True) -> SurfaceInteraction3f:
        """
        Intersect a ray with the shapes comprising the scene and return a
        detailed data structure describing the intersection, if one is found.

        In vectorized variants of Mitsuba (``cuda_*`` or ``llvm_*``), the
        function processes arrays of rays and returns arrays of surface
        interactions following the usual conventions.

        This method is a convenience wrapper of the generalized version of
        ``ray_intersect``() below. It assumes that incoherent rays are being
        traced, and that the user desires access to all fields of the
        SurfaceInteraction. In other words, it simply invokes the general
        ``ray_intersect``() overload with ``coherent=false`` and ``ray_flags``
        equal to RayFlags::All.

        Parameter ``ray``:
            A 3D ray including maximum extent (Ray::maxt) and time (Ray::time)
            information, which matters when the shapes are in motion

        Returns:
            A detailed surface interaction record. Its ``is_valid()`` method
            should be queried to check if an intersection was actually found.
        """

    @overload
    def ray_intersect(self, ray: Ray3f, ray_flags: int, coherent: bool, active: bool = True) -> SurfaceInteraction3f:
        """
        Intersect a ray with the shapes comprising the scene and return a
        detailed data structure describing the intersection, if one is found

        In vectorized variants of Mitsuba (``cuda_*`` or ``llvm_*``), the
        function processes arrays of rays and returns arrays of surface
        interactions following the usual conventions.

        This generalized ray intersection method exposes two additional flags
        to control the intersection process. Internally, it is split into two
        steps:

        <ol>

        * Finding a PreliminaryInteraction using the ray tracing backend
        underlying the current variant (i.e., Mitsuba's builtin kd-tree,
        Embree, or OptiX). This is done using the ray_intersect_preliminary()
        function that is also available directly below (and preferable if a
        full SurfaceInteraction is not needed.).

        * Expanding the PreliminaryInteraction into a full SurfaceInteraction
        (this part happens within Mitsuba/Dr.Jit and tracks derivative
        information in AD variants of the system).

        </ol>

        The SurfaceInteraction data structure is large, and computing its
        contents in the second step requires a non-trivial amount of
        computation and sequence of memory accesses. The ``ray_flags``
        parameter can be used to specify that only a sub-set of the full
        intersection data structure actually needs to be computed, which can
        improve performance.

        In the context of differentiable rendering, the ``ray_flags``
        parameter also influences how derivatives propagate between the input
        ray, the shape parameters, and the computed intersection (see
        RayFlags::FollowShape and RayFlags::DetachShape for details on this).
        The default, RayFlags::All, propagates derivatives through all steps
        of the intersection computation.

        The ``coherent`` flag is a hint that can improve performance in the
        first step of finding the PreliminaryInteraction if the input set of
        rays is coherent (e.g., when they are generated by
        Sensor::sample_ray(), which means that adjacent rays will traverse
        essentially the same region of space). This flag is currently only
        used by the combination of ``llvm_*`` variants and the Embree ray
        tracing backend.

        Parameter ``ray``:
            A 3D ray including maximum extent (Ray::maxt) and time (Ray::time)
            information, which matters when the shapes are in motion

        Parameter ``ray_flags``:
            An integer combining flag bits from RayFlags (merged using binary
            or).

        Parameter ``coherent``:
            Setting this flag to ``True`` can noticeably improve performance
            when ``ray`` contains a coherent set of rays (e.g. primary camera
            rays), and when using ``llvm_*`` variants of the renderer along
            with Embree. It has no effect in scalar or CUDA/OptiX variants.

        Returns:
            A detailed surface interaction record. Its ``is_valid()`` method
            should be queried to check if an intersection was actually found.
        """

    @overload
    def ray_test(self, ray: Ray3f, active: bool = True) -> bool:
        """
        Intersect a ray with the shapes comprising the scene and return a
        boolean specifying whether or not an intersection was found.

        In vectorized variants of Mitsuba (``cuda_*`` or ``llvm_*``), the
        function processes arrays of rays and returns arrays of booleans
        following the usual conventions.

        Testing for the mere presence of intersections is considerably faster
        than finding an actual intersection, hence this function should be
        preferred over ray_intersect() when geometric information about the
        first visible intersection is not needed.

        This method is a convenience wrapper of the generalized version of
        ``ray_test``() below, which assumes that incoherent rays are being
        traced. In other words, it simply invokes the general ``ray_test``()
        overload with ``coherent=false``.

        Parameter ``ray``:
            A 3D ray including maximum extent (Ray::maxt) and time (Ray::time)
            information, which matters when the shapes are in motion

        Returns:
            ``True`` if an intersection was found
        """

    @overload
    def ray_test(self, ray: Ray3f, coherent: bool, active: bool = True) -> bool:
        """
        Intersect a ray with the shapes comprising the scene and return a
        boolean specifying whether or not an intersection was found.

        In vectorized variants of Mitsuba (``cuda_*`` or ``llvm_*``), the
        function processes arrays of rays and returns arrays of booleans
        following the usual conventions.

        Testing for the mere presence of intersections is considerably faster
        than finding an actual intersection, hence this function should be
        preferred over ray_intersect() when geometric information about the
        first visible intersection is not needed.

        The ``coherent`` flag is a hint that can improve performance in the
        first step of finding the PreliminaryInteraction if the input set of
        rays is coherent, which means that adjacent rays will traverse
        essentially the same region of space. This flag is currently only used
        by the combination of ``llvm_*`` variants and the Embree ray tracing
        backend.

        Parameter ``ray``:
            A 3D ray including maximum extent (Ray::maxt) and time (Ray::time)
            information, which matters when the shapes are in motion

        Parameter ``coherent``:
            Setting this flag to ``True`` can noticeably improve performance
            when ``ray`` contains a coherent set of rays (e.g. primary camera
            rays), and when using ``llvm_*`` variants of the renderer along
            with Embree. It has no effect in scalar or CUDA/OptiX variants.

        Returns:
            ``True`` if an intersection was found
        """

    def sample_emitter(self, sample: float, active: bool = True) -> tuple[int, float, float]:
        """
        Sample one emitter in the scene and rescale the input sample for
        reuse.

        Currently, the sampling scheme implemented by the Scene class is very
        simplistic (uniform).

        Parameter ``sample``:
            A uniformly distributed number in [0, 1).

        Returns:
            The index of the chosen emitter along with the sampling weight
            (equal to the inverse PDF), and the transformed random sample for
            reuse.
        """

    def pdf_emitter(self, index: int, active: bool = True) -> float:
        """
        Evaluate the discrete probability of the sample_emitter() technique
        for the given a emitter index.
        """

    def sample_emitter_direction(self, ref: Interaction3f, sample: ScalarPoint2f, test_visibility: bool = True, active: bool = True) -> tuple[DirectionSample3f, ScalarColor3f]:
        """
        Direct illumination sampling routine

        This method implements stochastic connections to emitters, which is
        variously known as *emitter sampling*, *direct illumination sampling*,
        or *next event estimation*.

        The function expects a 3D reference location ``ref`` as input, which
        may influence the sampling process. Normally, this would be the
        location of a surface position being shaded. Ideally, the
        implementation of this function should then draw samples proportional
        to the scene's emission profile and the inverse square distance
        between the reference point and the sampled emitter position. However,
        approximations are acceptable as long as these are reflected in the
        returned Monte Carlo sampling weight.

        Parameter ``ref``:
            A 3D reference location within the scene, which may influence the
            sampling process.

        Parameter ``sample``:
            A uniformly distributed 2D random variate

        Parameter ``test_visibility``:
            When set to ``True``, a shadow ray will be cast to ensure that the
            sampled emitter position and the reference point are mutually
            visible.

        Returns:
            A tuple ``(ds, spec)`` where

        * ``ds`` is a fully populated DirectionSample3f data structure, which
        provides further detail about the sampled emitter position (e.g. its
        surface normal, solid angle density, whether Dirac delta distributions
        were involved, etc.)

        *

        * ``spec`` is a Monte Carlo sampling weight specifying the ratio of
        the radiance incident from the emitter and the sample probability per
        unit solid angle.
        """

    def pdf_emitter_direction(self, ref: Interaction3f, ds: DirectionSample3f, active: bool = True) -> float:
        """
        Evaluate the PDF of direct illumination sampling

        This function evaluates the probability density (per unit solid angle)
        of the sampling technique implemented by the sample_emitter_direct()
        function. The returned probability will always be zero when the
        emission profile contains a Dirac delta term (e.g. point or
        directional emitters/sensors).

        Parameter ``ref``:
            A 3D reference location within the scene, which may influence the
            sampling process.

        Parameter ``ds``:
            A direction sampling record, which specifies the query location.

        Returns:
            The solid angle density of the sample
        """

    def eval_emitter_direction(self, ref: Interaction3f, ds: DirectionSample3f, active: bool = True) -> ScalarColor3f:
        """
        Re-evaluate the incident direct radiance of the
        sample_emitter_direction() method.

        This function re-evaluates the incident direct radiance and sample
        probability due to the emitter *so that division by * ``ds.pdf``
        equals the sampling weight returned by sample_emitter_direction().
        This may appear redundant, and indeed such a function would not find
        use in "normal" rendering algorithms.

        However, the ability to re-evaluate the contribution of a direct
        illumination sample is important for differentiable rendering. For
        example, we might want to track derivatives in the sampled direction
        (``ds.d``) without also differentiating the sampling technique.

        In contrast to pdf_emitter_direction(), evaluating this function can
        yield a nonzero result in the case of emission profiles containing a
        Dirac delta term (e.g. point or directional lights).

        Parameter ``ref``:
            A 3D reference location within the scene, which may influence the
            sampling process.

        Parameter ``ds``:
            A direction sampling record, which specifies the query location.

        Returns:
            The incident radiance and discrete or solid angle density of the
            sample.
        """

    def sample_emitter_ray(self, time: float, sample1: float, sample2: ScalarPoint2f, sample3: ScalarPoint2f, active: bool) -> tuple[Ray3f, ScalarColor3f, Emitter]:
        """
        Sample a ray according to the emission profile of scene emitters

        This function combines both steps of choosing a ray origin on a light
        source and an outgoing ray direction. It does not return any auxiliary
        sampling information and is mainly meant to be used by unidirectional
        rendering techniques like particle tracing.

        Sampling is ideally perfectly proportional to the emission profile,
        though approximations are acceptable as long as these are reflected in
        the returned Monte Carlo sampling weight.

        Parameter ``time``:
            The scene time associated with the ray to be sampled.

        Parameter ``sample1``:
            A uniformly distributed 1D value that is used to sample the
            spectral dimension of the emission profile.

        Parameter ``sample2``:
            A uniformly distributed sample on the domain ``[0,1]^2``.

        Parameter ``sample3``:
            A uniformly distributed sample on the domain ``[0,1]^2``.

        Returns:
            A tuple ``(ray, weight, emitter, radiance)``, where

        * ``ray`` is the sampled ray (e.g. starting on the surface of an area
        emitter)

        * ``weight`` returns the emitted radiance divided by the spatio-
        directional sampling density

        * ``emitter`` is a pointer specifying the sampled emitter
        """

    def sample_silhouette(self, sample: ScalarPoint3f, flags: int, active: bool = True) -> SilhouetteSample3f:
        """
        Map a point sample in boundary sample space to a silhouette segment

        This method will sample a SilhouetteSample3f object from all the
        shapes in the scene that are being differentiated and have non-zero
        sampling weight (see Shape::silhouette_sampling_weight).

        Parameter ``sample``:
            The boundary space sample (a point in the unit cube).

        Parameter ``flags``:
            Flags to select the type of silhouettes to sample from (see
            DiscontinuityFlags). Multiple types of discontinuities can be
            sampled in a single call. If a single type of silhouette is
            specified, shapes that do not have that types might still be
            sampled. In which case, the SilhouetteSample3f field
            ``discontinuity_type`` will be DiscontinuityFlags::Empty.

        Returns:
            Silhouette sample record.
        """

    def invert_silhouette_sample(self, ss: SilhouetteSample3f, active: bool = True) -> ScalarPoint3f:
        """
        Map a silhouette segment to a point in boundary sample space

        This method is the inverse of sample_silhouette(). The mapping from
        boundary sample space to boundary segments is bijective.

        Parameter ``ss``:
            The sampled boundary segment

        Returns:
            The corresponding boundary sample space point
        """

    def bbox(self) -> ScalarBoundingBox3f:
        """Return a bounding box surrounding the scene"""

    def sensors(self) -> list:
        """Return the list of sensors"""

    def sensors_dr(self) -> "drjit::DynamicArray<mitsuba::Sensor<float, mitsuba::Color<float, 3ul> > const*>":
        """Return the list of sensors as a Dr.Jit array"""

    def emitters(self) -> list[Emitter]:
        """Return the list of emitters"""

    def emitters_dr(self) -> "drjit::DynamicArray<mitsuba::Emitter<float, mitsuba::Color<float, 3ul> > const*>":
        """Return the list of emitters as a Dr.Jit array"""

    def environment(self) -> Emitter:
        """Return the environment emitter (if any)"""

    def shapes(self) -> list:
        """Return the list of shapes"""

    def shapes_dr(self) -> "drjit::DynamicArray<mitsuba::Shape<float, mitsuba::Color<float, 3ul> > const*>":
        """Return the list of shapes as a Dr.Jit array"""

    def silhouette_shapes(self) -> list:
        """Return the list of shapes that can have their silhouette sampled"""

    def integrator(self) -> object:
        """Return the scene's integrator"""

    def shapes_grad_enabled(self) -> bool:
        """
        Specifies whether any of the scene's shape parameters have gradient
        tracking enabled
        """

    def __repr__(self) -> str: ...

class ScopedSetThreadEnvironment:
    """
    RAII-style class to temporarily switch to another thread's logger/file
    resolver
    """

    def __init__(self, arg: ThreadEnvironment, /) -> None: ...

    def __enter__(self) -> None: ...

    def __exit__(self, exc_type: object | None, exc_val: object | None, exc_tb: object | None) -> None: ...

class Sensor(Endpoint):
    def __init__(self, arg: Properties, /) -> None: ...

    def shutter_open(self) -> float:
        """Return the time value of the shutter opening event"""

    def shutter_open_time(self) -> float:
        """Return the length, for which the shutter remains open"""

    def needs_aperture_sample(self) -> bool:
        """
        Does the sampling technique require a sample for the aperture
        position?
        """

    def film(self) -> Film:
        """Return the Film instance associated with this sensor"""

    def sampler(self) -> Sampler:
        """
        Return the sensor's sample generator

        This is the *root* sampler, which will later be forked a number of
        times to provide each participating worker thread with its own
        instance (see Scene::sampler()). Therefore, this sampler should never
        be used for anything except creating forks.
        """

    @property
    def m_needs_sample_2(self) -> bool: ...

    @m_needs_sample_2.setter
    def m_needs_sample_2(self, arg: bool, /) -> None: ...

    @property
    def m_needs_sample_3(self) -> bool: ...

    @m_needs_sample_3.setter
    def m_needs_sample_3(self, arg: bool, /) -> None: ...

    @property
    def m_film(self) -> Film: ...

    @m_film.setter
    def m_film(self, arg: Film, /) -> None: ...

    def sample_ray(self, time: float, sample1: float, sample2: ScalarPoint2f, sample3: ScalarPoint2f, active: bool = True) -> tuple[Ray3f, ScalarColor3f]:
        """
        Importance sample a ray proportional to the endpoint's
        sensitivity/emission profile.

        The endpoint profile is a six-dimensional quantity that depends on
        time, wavelength, surface position, and direction. This function takes
        a given time value and five uniformly distributed samples on the
        interval [0, 1] and warps them so that the returned ray follows the
        profile. Any discrepancies between ideal and actual sampled profile
        are absorbed into a spectral importance weight that is returned along
        with the ray.

        Parameter ``time``:
            The scene time associated with the ray to be sampled

        Parameter ``sample1``:
            A uniformly distributed 1D value that is used to sample the
            spectral dimension of the emission profile.

        Parameter ``sample2``:
            A uniformly distributed sample on the domain ``[0,1]^2``. For
            sensor endpoints, this argument corresponds to the sample position
            in fractional pixel coordinates relative to the crop window of the
            underlying film. This argument is ignored if ``needs_sample_2() ==
            false``.

        Parameter ``sample3``:
            A uniformly distributed sample on the domain ``[0,1]^2``. For
            sensor endpoints, this argument determines the position on the
            aperture of the sensor. This argument is ignored if
            ``needs_sample_3() == false``.

        Returns:
            The sampled ray and (potentially spectrally varying) importance
            weights. The latter account for the difference between the profile
            and the actual used sampling density function.
        """

    def sample_ray_differential(self, time: float, sample1: float, sample2: ScalarPoint2f, sample3: ScalarPoint2f, active: bool = True) -> tuple[RayDifferential3f, ScalarColor3f]:
        """
        Importance sample a ray differential proportional to the sensor's
        sensitivity profile.

        The sensor profile is a six-dimensional quantity that depends on time,
        wavelength, surface position, and direction. This function takes a
        given time value and five uniformly distributed samples on the
        interval [0, 1] and warps them so that the returned ray the profile.
        Any discrepancies between ideal and actual sampled profile are
        absorbed into a spectral importance weight that is returned along with
        the ray.

        In contrast to Endpoint::sample_ray(), this function returns
        differentials with respect to the X and Y axis in screen space.

        Parameter ``time``:
            The scene time associated with the ray_differential to be sampled

        Parameter ``sample1``:
            A uniformly distributed 1D value that is used to sample the
            spectral dimension of the sensitivity profile.

        Parameter ``sample2``:
            This argument corresponds to the sample position in fractional
            pixel coordinates relative to the crop window of the underlying
            film.

        Parameter ``sample3``:
            A uniformly distributed sample on the domain ``[0,1]^2``. This
            argument determines the position on the aperture of the sensor.
            This argument is ignored if ``needs_sample_3() == false``.

        Returns:
            The sampled ray differential and (potentially spectrally varying)
            importance weights. The latter account for the difference between
            the sensor profile and the actual used sampling density function.
        """

    def sample_direction(self, it: Interaction3f, sample: ScalarPoint2f, active: bool = True) -> tuple[DirectionSample3f, ScalarColor3f]:
        """
        Given a reference point in the scene, sample a direction from the
        reference point towards the endpoint (ideally proportional to the
        emission/sensitivity profile)

        This operation is a generalization of direct illumination techniques
        to both emitters *and* sensors. A direction sampling method is given
        an arbitrary reference position in the scene and samples a direction
        from the reference point towards the endpoint (ideally proportional to
        the emission/sensitivity profile). This reduces the sampling domain
        from 4D to 2D, which often enables the construction of smarter
        specialized sampling techniques.

        Ideally, the implementation should importance sample the product of
        the emission profile and the geometry term between the reference point
        and the position on the endpoint.

        The default implementation throws an exception.

        Parameter ``ref``:
            A reference position somewhere within the scene.

        Parameter ``sample``:
            A uniformly distributed 2D point on the domain ``[0,1]^2``.

        Returns:
            A DirectionSample instance describing the generated sample along
            with a spectral importance weight.
        """

    def pdf_direction(self, it: Interaction3f, ds: DirectionSample3f, active: bool = True) -> float:
        """
        Evaluate the probability density of the *direct* sampling method
        implemented by the sample_direction() method.

        The returned probability will always be zero when the
        emission/sensitivity profile contains a Dirac delta term (e.g. point
        or directional emitters/sensors).

        Parameter ``ds``:
            A direct sampling record, which specifies the query location.
        """

    def eval_direction(self, it: Interaction3f, ds: DirectionSample3f, active: bool = True) -> ScalarColor3f:
        """
        Re-evaluate the incident direct radiance/importance of the
        sample_direction() method.

        This function re-evaluates the incident direct radiance or importance
        and sample probability due to the endpoint so that division by
        ``ds.pdf`` equals the sampling weight returned by sample_direction().
        This may appear redundant, and indeed such a function would not find
        use in "normal" rendering algorithms.

        However, the ability to re-evaluate the contribution of a generated
        sample is important for differentiable rendering. For example, we
        might want to track derivatives in the sampled direction (``ds.d``)
        without also differentiating the sampling technique.

        In contrast to pdf_direction(), evaluating this function can yield a
        nonzero result in the case of emission profiles containing a Dirac
        delta term (e.g. point or directional lights).

        Parameter ``ref``:
            A 3D reference location within the scene, which may influence the
            sampling process.

        Parameter ``ds``:
            A direction sampling record, which specifies the query location.

        Returns:
            The incident direct radiance/importance associated with the
            sample.
        """

    def sample_position(self, time: float, sample: ScalarPoint2f, active: bool = True) -> tuple[PositionSample3f, float]:
        """
        Importance sample the spatial component of the emission or importance
        profile of the endpoint.

        The default implementation throws an exception.

        Parameter ``time``:
            The scene time associated with the position to be sampled.

        Parameter ``sample``:
            A uniformly distributed 2D point on the domain ``[0,1]^2``.

        Returns:
            A PositionSample instance describing the generated sample along
            with an importance weight.
        """

    def pdf_position(self, ps: PositionSample3f, active: bool = True) -> float:
        """
        Evaluate the probability density of the position sampling method
        implemented by sample_position().

        In simple cases, this will be the reciprocal of the endpoint's surface
        area.

        Parameter ``ps``:
            The sampled position record.

        Returns:
            The corresponding sampling density.
        """

    def eval(self, si: SurfaceInteraction3f, active: bool = True) -> ScalarColor3f:
        """
        Given a ray-surface intersection, return the emitted radiance or
        importance traveling along the reverse direction

        This function is e.g. used when an area light source has been hit by a
        ray in a path tracing-style integrator, and it subsequently needs to
        be queried for the emitted radiance along the negative ray direction.
        The default implementation throws an exception, which states that the
        method is not implemented.

        Parameter ``si``:
            An intersect record that specifies both the query position and
            direction (using the ``si.wi`` field)

        Returns:
            The emitted radiance or importance
        """

    def sample_wavelengths(self, si: SurfaceInteraction3f, sample: float, active: bool = True) -> tuple[ScalarColor0f, ScalarColor3f]:
        """
        Importance sample a set of wavelengths according to the endpoint's
        sensitivity/emission spectrum.

        This function takes a uniformly distributed 1D sample and generates a
        sample that is approximately distributed according to the endpoint's
        spectral sensitivity/emission profile.

        For this, the input 1D sample is first replicated into
        ``Spectrum::Size`` separate samples using simple arithmetic
        transformations (see math::sample_shifted()), which can be interpreted
        as a type of Quasi-Monte-Carlo integration scheme. Following this, a
        standard technique (e.g. inverse transform sampling) is used to find
        the corresponding wavelengths. Any discrepancies between ideal and
        actual sampled profile are absorbed into a spectral importance weight
        that is returned along with the wavelengths.

        This function should not be called in RGB or monochromatic modes.

        Parameter ``si``:
            In the case of a spatially-varying spectral sensitivity/emission
            profile, this parameter conditions sampling on a specific spatial
            position. The ``si.uv`` field must be specified in this case.

        Parameter ``sample``:
            A 1D uniformly distributed random variate

        Returns:
            The set of sampled wavelengths and (potentially spectrally
            varying) importance weights. The latter account for the difference
            between the profile and the actual used sampling density function.
            In the case of emitters, the weight will include the emitted
            radiance.
        """

    def get_shape(self) -> Shape:
        """Return the shape, to which the emitter is currently attached"""

class SensorPtr(drjit.ArrayBase[SensorPtr, _SensorPtrCp, Sensor, Sensor, SensorPtr, SensorPtr, drjit.auto.ad.Bool]):
    Variant: str = 'llvm_ad_spectral_polarized'

    @overload
    def sample_ray(self, time: drjit.auto.ad.Float, sample1: drjit.auto.ad.Float, sample2: Point2f, sample3: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[Ray3f, Spectrum]:
        """
        Importance sample a ray proportional to the endpoint's
        sensitivity/emission profile.

        The endpoint profile is a six-dimensional quantity that depends on
        time, wavelength, surface position, and direction. This function takes
        a given time value and five uniformly distributed samples on the
        interval [0, 1] and warps them so that the returned ray follows the
        profile. Any discrepancies between ideal and actual sampled profile
        are absorbed into a spectral importance weight that is returned along
        with the ray.

        Parameter ``time``:
            The scene time associated with the ray to be sampled

        Parameter ``sample1``:
            A uniformly distributed 1D value that is used to sample the
            spectral dimension of the emission profile.

        Parameter ``sample2``:
            A uniformly distributed sample on the domain ``[0,1]^2``. For
            sensor endpoints, this argument corresponds to the sample position
            in fractional pixel coordinates relative to the crop window of the
            underlying film. This argument is ignored if ``needs_sample_2() ==
            false``.

        Parameter ``sample3``:
            A uniformly distributed sample on the domain ``[0,1]^2``. For
            sensor endpoints, this argument determines the position on the
            aperture of the sensor. This argument is ignored if
            ``needs_sample_3() == false``.

        Returns:
            The sampled ray and (potentially spectrally varying) importance
            weights. The latter account for the difference between the profile
            and the actual used sampling density function.
        """

    @overload
    def sample_ray(self, time: drjit.auto.ad.Float, sample1: drjit.auto.ad.Float, sample2: Point2f, sample3: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[Ray3f, Spectrum]: ...

    @overload
    def sample_ray_differential(self, time: drjit.auto.ad.Float, sample1: drjit.auto.ad.Float, sample2: Point2f, sample3: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[RayDifferential3f, Spectrum]:
        """
        Importance sample a ray differential proportional to the sensor's
        sensitivity profile.

        The sensor profile is a six-dimensional quantity that depends on time,
        wavelength, surface position, and direction. This function takes a
        given time value and five uniformly distributed samples on the
        interval [0, 1] and warps them so that the returned ray the profile.
        Any discrepancies between ideal and actual sampled profile are
        absorbed into a spectral importance weight that is returned along with
        the ray.

        In contrast to Endpoint::sample_ray(), this function returns
        differentials with respect to the X and Y axis in screen space.

        Parameter ``time``:
            The scene time associated with the ray_differential to be sampled

        Parameter ``sample1``:
            A uniformly distributed 1D value that is used to sample the
            spectral dimension of the sensitivity profile.

        Parameter ``sample2``:
            This argument corresponds to the sample position in fractional
            pixel coordinates relative to the crop window of the underlying
            film.

        Parameter ``sample3``:
            A uniformly distributed sample on the domain ``[0,1]^2``. This
            argument determines the position on the aperture of the sensor.
            This argument is ignored if ``needs_sample_3() == false``.

        Returns:
            The sampled ray differential and (potentially spectrally varying)
            importance weights. The latter account for the difference between
            the sensor profile and the actual used sampling density function.
        """

    @overload
    def sample_ray_differential(self, time: drjit.auto.ad.Float, sample1: drjit.auto.ad.Float, sample2: Point2f, sample3: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[RayDifferential3f, Spectrum]: ...

    @overload
    def sample_direction(self, it: Interaction3f, sample: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[DirectionSample3f, Spectrum]:
        """
        Given a reference point in the scene, sample a direction from the
        reference point towards the endpoint (ideally proportional to the
        emission/sensitivity profile)

        This operation is a generalization of direct illumination techniques
        to both emitters *and* sensors. A direction sampling method is given
        an arbitrary reference position in the scene and samples a direction
        from the reference point towards the endpoint (ideally proportional to
        the emission/sensitivity profile). This reduces the sampling domain
        from 4D to 2D, which often enables the construction of smarter
        specialized sampling techniques.

        Ideally, the implementation should importance sample the product of
        the emission profile and the geometry term between the reference point
        and the position on the endpoint.

        The default implementation throws an exception.

        Parameter ``ref``:
            A reference position somewhere within the scene.

        Parameter ``sample``:
            A uniformly distributed 2D point on the domain ``[0,1]^2``.

        Returns:
            A DirectionSample instance describing the generated sample along
            with a spectral importance weight.
        """

    @overload
    def sample_direction(self, it: Interaction3f, sample: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[DirectionSample3f, Spectrum]: ...

    @overload
    def pdf_direction(self, it: Interaction3f, ds: DirectionSample3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the probability density of the *direct* sampling method
        implemented by the sample_direction() method.

        The returned probability will always be zero when the
        emission/sensitivity profile contains a Dirac delta term (e.g. point
        or directional emitters/sensors).

        Parameter ``ds``:
            A direct sampling record, which specifies the query location.
        """

    @overload
    def pdf_direction(self, it: Interaction3f, ds: DirectionSample3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float: ...

    @overload
    def eval_direction(self, it: Interaction3f, ds: DirectionSample3f, active: drjit.auto.ad.Bool = True) -> Spectrum:
        """
        Re-evaluate the incident direct radiance/importance of the
        sample_direction() method.

        This function re-evaluates the incident direct radiance or importance
        and sample probability due to the endpoint so that division by
        ``ds.pdf`` equals the sampling weight returned by sample_direction().
        This may appear redundant, and indeed such a function would not find
        use in "normal" rendering algorithms.

        However, the ability to re-evaluate the contribution of a generated
        sample is important for differentiable rendering. For example, we
        might want to track derivatives in the sampled direction (``ds.d``)
        without also differentiating the sampling technique.

        In contrast to pdf_direction(), evaluating this function can yield a
        nonzero result in the case of emission profiles containing a Dirac
        delta term (e.g. point or directional lights).

        Parameter ``ref``:
            A 3D reference location within the scene, which may influence the
            sampling process.

        Parameter ``ds``:
            A direction sampling record, which specifies the query location.

        Returns:
            The incident direct radiance/importance associated with the
            sample.
        """

    @overload
    def eval_direction(self, it: Interaction3f, ds: DirectionSample3f, active: drjit.auto.ad.Bool = True) -> Spectrum: ...

    @overload
    def sample_position(self, time: drjit.auto.ad.Float, sample: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[PositionSample3f, drjit.auto.ad.Float]:
        """
        Importance sample the spatial component of the emission or importance
        profile of the endpoint.

        The default implementation throws an exception.

        Parameter ``time``:
            The scene time associated with the position to be sampled.

        Parameter ``sample``:
            A uniformly distributed 2D point on the domain ``[0,1]^2``.

        Returns:
            A PositionSample instance describing the generated sample along
            with an importance weight.
        """

    @overload
    def sample_position(self, time: drjit.auto.ad.Float, sample: Point2f, active: drjit.auto.ad.Bool = True) -> tuple[PositionSample3f, drjit.auto.ad.Float]: ...

    @overload
    def pdf_position(self, ps: PositionSample3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Evaluate the probability density of the position sampling method
        implemented by sample_position().

        In simple cases, this will be the reciprocal of the endpoint's surface
        area.

        Parameter ``ps``:
            The sampled position record.

        Returns:
            The corresponding sampling density.
        """

    @overload
    def pdf_position(self, ps: PositionSample3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float: ...

    @overload
    def eval(self, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> Spectrum:
        """
        Given a ray-surface intersection, return the emitted radiance or
        importance traveling along the reverse direction

        This function is e.g. used when an area light source has been hit by a
        ray in a path tracing-style integrator, and it subsequently needs to
        be queried for the emitted radiance along the negative ray direction.
        The default implementation throws an exception, which states that the
        method is not implemented.

        Parameter ``si``:
            An intersect record that specifies both the query position and
            direction (using the ``si.wi`` field)

        Returns:
            The emitted radiance or importance
        """

    @overload
    def eval(self, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> Spectrum: ...

    @overload
    def sample_wavelengths(self, si: SurfaceInteraction3f, sample: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> tuple[UnpolarizedSpectrum, Spectrum]:
        """
        Importance sample a set of wavelengths according to the endpoint's
        sensitivity/emission spectrum.

        This function takes a uniformly distributed 1D sample and generates a
        sample that is approximately distributed according to the endpoint's
        spectral sensitivity/emission profile.

        For this, the input 1D sample is first replicated into
        ``Spectrum::Size`` separate samples using simple arithmetic
        transformations (see math::sample_shifted()), which can be interpreted
        as a type of Quasi-Monte-Carlo integration scheme. Following this, a
        standard technique (e.g. inverse transform sampling) is used to find
        the corresponding wavelengths. Any discrepancies between ideal and
        actual sampled profile are absorbed into a spectral importance weight
        that is returned along with the wavelengths.

        This function should not be called in RGB or monochromatic modes.

        Parameter ``si``:
            In the case of a spatially-varying spectral sensitivity/emission
            profile, this parameter conditions sampling on a specific spatial
            position. The ``si.uv`` field must be specified in this case.

        Parameter ``sample``:
            A 1D uniformly distributed random variate

        Returns:
            The set of sampled wavelengths and (potentially spectrally
            varying) importance weights. The latter account for the difference
            between the profile and the actual used sampling density function.
            In the case of emitters, the weight will include the emitted
            radiance.
        """

    @overload
    def sample_wavelengths(self, si: SurfaceInteraction3f, sample: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> tuple[UnpolarizedSpectrum, Spectrum]: ...

    @overload
    def get_shape(self) -> ShapePtr:
        """Return the shape, to which the emitter is currently attached"""

    @overload
    def get_shape(self) -> ShapePtr: ...

class Shape(Object):
    """Forward declaration for `SilhouetteSample`"""

    @overload
    def bbox(self) -> ScalarBoundingBox3f:
        """
        Return an axis aligned box that bounds all shape primitives (including
        any transformations that may have been applied to them)
        """

    @overload
    def bbox(self, index: int) -> ScalarBoundingBox3f:
        """
        Return an axis aligned box that bounds a single shape primitive
        (including any transformations that may have been applied to it)

        Remark:
            The default implementation simply calls bbox()
        """

    @overload
    def bbox(self, index: int, clip: ScalarBoundingBox3f) -> ScalarBoundingBox3f:
        """
        Return an axis aligned box that bounds a single shape primitive after
        it has been clipped to another bounding box.

        This is extremely important to construct high-quality kd-trees. The
        default implementation just takes the bounding box returned by
        bbox(ScalarIndex index) and clips it to *clip*.
        """

    def id(self) -> str:
        """Return a string identifier"""

    @overload
    def is_mesh(self) -> bool:
        """Is this shape a triangle mesh?"""

    @overload
    def is_mesh(self) -> bool: ...

    def parameters_grad_enabled(self) -> bool:
        """
        Return whether any shape's parameters that introduce visibility
        discontinuities require gradients (default return false)
        """

    def primitive_count(self) -> int:
        """
        Returns the number of sub-primitives that make up this shape

        Remark:
            The default implementation simply returns ``1``
        """

    def effective_primitive_count(self) -> int:
        """
        Return the number of primitives (triangles, hairs, ..) contributed to
        the scene by this shape

        Includes instanced geometry. The default implementation simply returns
        the same value as primitive_count().
        """

    def precompute_silhouette(self, viewpoint: ScalarPoint3f) -> tuple[drjit.scalar.ArrayXu, drjit.scalar.ArrayXf]:
        """
        Precompute the visible silhouette of this shape for a given viewpoint.

        This method is meant to be used for silhouettes that are shared
        between all threads, as is the case for primarily visible derivatives.

        The return values are respectively a list of indices and their
        corresponding weights. The semantic meaning of these indices is
        different for each shape. For example, a triangle mesh will return the
        indices of all of its edges that constitute its silhouette. These
        indices are meant to be re-used as an argument when calling
        sample_precomputed_silhouette.

        This method's behavior is undefined when used in non-JIT variants or
        when the shape is not being differentiated.

        Parameter ``viewpoint``:
            The viewpoint which defines the silhouette of the shape

        Returns:
            A list of indices used by the shape internally to represent
            silhouettes, and a list of the same length containing the
            (unnormalized) weights associated to each index.
        """

    def is_emitter(self) -> bool:
        """Is this shape also an area emitter?"""

    def is_sensor(self) -> bool:
        """Is this shape also an area sensor?"""

    def is_medium_transition(self) -> bool:
        """Does the surface of this shape mark a medium transition?"""

    def shape_type(self) -> int:
        """Returns the shape type ShapeType of this shape"""

    def interior_medium(self) -> Medium:
        """Return the medium that lies on the interior of this shape"""

    def exterior_medium(self) -> Medium:
        """Return the medium that lies on the exterior of this shape"""

    def bsdf(self) -> BSDF:
        """Return the shape's BSDF"""

    def sensor(self) -> Sensor:
        """Return the area sensor associated with this shape (if any)"""

    def emitter(self) -> Emitter:
        """Return the area emitter associated with this shape (if any)"""

    def compute_surface_interaction(self, ray: Ray3f, pi: PreliminaryIntersection3f, ray_flags: int = 14, active: bool = True) -> SurfaceInteraction3f:
        """
        Compute and return detailed information related to a surface
        interaction

        The implementation should at most compute the fields ``p``, ``uv``,
        ``n``, ``sh_frame``.n, ``dp_du``, ``dp_dv``, ``dn_du`` and ``dn_dv``.
        The ``flags`` parameter specifies which of those fields should be
        computed.

        The fields ``t``, ``time``, ``wavelengths``, ``shape``,
        ``prim_index``, ``instance``, will already have been initialized by
        the caller. The field ``wi`` is initialized by the caller following
        the call to compute_surface_interaction(), and ``duv_dx``, and
        ``duv_dy`` are left uninitialized.

        Parameter ``ray``:
            Ray associated with the ray intersection

        Parameter ``pi``:
            Data structure carrying information about the ray intersection

        Parameter ``ray_flags``:
            Flags specifying which information should be computed

        Parameter ``recursion_depth``:
            Integer specifying the recursion depth for nested virtual function
            call to this method (e.g. used for instancing).

        Returns:
            A data structure containing the detailed information
        """

    def has_attribute(self, name: str, active: bool = True) -> bool:
        """
        Returns whether this shape contains the specified attribute.

        Parameter ``name``:
            Name of the attribute
        """

    def eval_attribute(self, name: str, si: SurfaceInteraction3f, active: bool = True) -> ScalarColor3f:
        """
        Evaluate a specific shape attribute at the given surface interaction.

        Shape attributes are user-provided fields that provide extra
        information at an intersection. An example of this would be a per-
        vertex or per-face color on a triangle mesh.

        Parameter ``name``:
            Name of the attribute to evaluate

        Parameter ``si``:
            Surface interaction associated with the query

        Returns:
            An unpolarized spectral power distribution or reflectance value
        """

    def eval_attribute_1(self, name: str, si: SurfaceInteraction3f, active: bool = True) -> float:
        """
        Monochromatic evaluation of a shape attribute at the given surface
        interaction

        This function differs from eval_attribute() in that it provided raw
        access to scalar intensity/reflectance values without any color
        processing (e.g. spectral upsampling).

        Parameter ``name``:
            Name of the attribute to evaluate

        Parameter ``si``:
            Surface interaction associated with the query

        Returns:
            An scalar intensity or reflectance value
        """

    def eval_attribute_3(self, name: str, si: SurfaceInteraction3f, active: bool = True) -> ScalarColor3f:
        """
        Trichromatic evaluation of a shape attribute at the given surface
        interaction

        This function differs from eval_attribute() in that it provided raw
        access to RGB intensity/reflectance values without any additional
        color processing (e.g. RGB-to-spectral upsampling).

        Parameter ``name``:
            Name of the attribute to evaluate

        Parameter ``si``:
            Surface interaction associated with the query

        Returns:
            An trichromatic intensity or reflectance value
        """

    def ray_intersect_preliminary(self, ray: Ray3f, prim_index: int = 0, active: bool = True) -> PreliminaryIntersection3f:
        """
        Fast ray intersection

        Efficiently test whether the shape is intersected by the given ray,
        and return preliminary information about the intersection if that is
        the case.

        If the intersection is deemed relevant (e.g. the closest to the ray
        origin), detailed intersection information can later be obtained via
        the create_surface_interaction() method.

        Parameter ``ray``:
            The ray to be tested for an intersection

        Parameter ``prim_index``:
            Index of the primitive to be intersected. This index is ignored by
            a shape that contains a single primitive. Otherwise, if no index
            is provided, the ray intersection will be performed on the shape's
            first primitive at index 0.
        """

    def ray_intersect(self, ray: Ray3f, ray_flags: int = 14, active: bool = True) -> SurfaceInteraction3f:
        """
        Test for an intersection and return detailed information

        This operation combines the prior ray_intersect_preliminary() and
        compute_surface_interaction() operations.

        Parameter ``ray``:
            The ray to be tested for an intersection

        Parameter ``flags``:
            Describe how the detailed information should be computed
        """

    def ray_test(self, ray: Ray3f, active: bool = True) -> bool:
        """
        Fast ray shadow test

        Efficiently test whether the shape is intersected by the given ray.

        No details about the intersection are returned, hence the function is
        only useful for visibility queries. For most shapes, the
        implementation will simply forward the call to
        ray_intersect_preliminary(). When the shape actually contains a nested
        kd-tree, some optimizations are possible.

        Parameter ``ray``:
            The ray to be tested for an intersection

        Parameter ``prim_index``:
            Index of the primitive to be intersected
        """

    def sample_position(self, time: float, sample: ScalarPoint2f, active: bool = True) -> PositionSample3f:
        """
        Sample a point on the surface of this shape

        The sampling strategy is ideally uniform over the surface, though
        implementations are allowed to deviate from a perfectly uniform
        distribution as long as this is reflected in the returned probability
        density.

        Parameter ``time``:
            The scene time associated with the position sample

        Parameter ``sample``:
            A uniformly distributed 2D point on the domain ``[0,1]^2``

        Returns:
            A PositionSample instance describing the generated sample
        """

    def pdf_position(self, ps: PositionSample3f, active: bool = True) -> float:
        """
        Query the probability density of sample_position() for a particular
        point on the surface.

        Parameter ``ps``:
            A position record describing the sample in question

        Returns:
            The probability density per unit area
        """

    def sample_direction(self, it: Interaction3f, sample: ScalarPoint2f, active: bool = True) -> DirectionSample3f:
        """
        Sample a direction towards this shape with respect to solid angles
        measured at a reference position within the scene

        An ideal implementation of this interface would achieve a uniform
        solid angle density within the surface region that is visible from the
        reference position ``it.p`` (though such an ideal implementation is
        usually neither feasible nor advisable due to poor efficiency).

        The function returns the sampled position and the inverse probability
        per unit solid angle associated with the sample.

        When the Shape subclass does not supply a custom implementation of
        this function, the Shape class reverts to a fallback approach that
        piggybacks on sample_position(). This will generally lead to a
        suboptimal sample placement and higher variance in Monte Carlo
        estimators using the samples.

        Parameter ``it``:
            A reference position somewhere within the scene.

        Parameter ``sample``:
            A uniformly distributed 2D point on the domain ``[0,1]^2``

        Returns:
            A DirectionSample instance describing the generated sample
        """

    def pdf_direction(self, it: Interaction3f, ps: DirectionSample3f, active: bool = True) -> float:
        """
        Query the probability density of sample_direction()

        Parameter ``it``:
            A reference position somewhere within the scene.

        Parameter ``ps``:
            A position record describing the sample in question

        Returns:
            The probability density per unit solid angle
        """

    def silhouette_discontinuity_types(self) -> int:
        r"""//! @{ \name Silhouette sampling routines and other utilities"""

    def silhouette_sampling_weight(self) -> float:
        """Return this shape's sampling weight w.r.t. all shapes in the scene"""

    def sample_silhouette(self, sample: ScalarPoint3f, flags: int, active: bool = True) -> SilhouetteSample3f:
        """
        Map a point sample in boundary sample space to a silhouette segment

        This method's behavior is undefined when used in non-JIT variants or
        when the shape is not being differentiated.

        Parameter ``sample``:
            The boundary space sample (a point in the unit cube).

        Parameter ``flags``:
            Flags to select the type of silhouettes to sample from (see
            DiscontinuityFlags). Only one type of discontinuity can be sampled
            per call.

        Returns:
            Silhouette sample record.
        """

    def invert_silhouette_sample(self, ss: SilhouetteSample3f, active: bool = True) -> ScalarPoint3f:
        """
        Map a silhouette segment to a point in boundary sample space

        This method is the inverse of sample_silhouette(). The mapping from/to
        boundary sample space to/from boundary segments is bijective.

        This method's behavior is undefined when used in non-JIT variants or
        when the shape is not being differentiated.

        Parameter ``ss``:
            The sampled boundary segment

        Returns:
            The corresponding boundary sample space point
        """

    def differential_motion(self, si: SurfaceInteraction3f, active: bool = True) -> ScalarPoint3f:
        r"""
        Return the attached (AD) point on the shape's surface

        This method is only useful when using automatic differentiation. The
        immediate/primal return value of this method is exactly equal to
        \`si.p\`.

        The input `si` does not need to be explicitly detached, it is done by
        the method itself.

        If the shape cannot be differentiated, this method will return the
        detached input point.

        note:: The returned attached point is exactly the same as a point
        which is computed by calling compute_surface_interaction with the
        RayFlags::FollowShape flag.

        Parameter ``si``:
            The surface point for which the function will be evaluated.

        Not all fields of the object need to be filled. Only the `prim_index`,
        `p` and `uv` fields are required. Certain shapes will only use a
        subset of these.

        Returns:
            The same surface point as the input but attached (AD) to the
            shape's parameters.
        """

    def primitive_silhouette_projection(self, viewpoint: ScalarPoint3f, si: SurfaceInteraction3f, flags: int, sample: float, active: bool = True) -> SilhouetteSample3f:
        """
        Projects a point on the surface of the shape to its silhouette as seen
        from a specified viewpoint.

        This method only projects the `si.p` point within its primitive.

        Not all of the fields of the SilhouetteSample3f might be filled by
        this method. Each shape will at the very least fill its return value
        with enough information for it to be used by invert_silhouette_sample.

        The projection operation might not find the closest silhouette point
        to the given surface point. For example, it can be guided by a random
        number ``sample``. Not all shapes types need this random number, each
        shape implementation is free to define its own algorithm and
        guarantees about the projection operation.

        This method's behavior is undefined when used in non-JIT variants or
        when the shape is not being differentiated.

        Parameter ``viewpoint``:
            The viewpoint which defines the silhouette to project the point
            to.

        Parameter ``si``:
            The surface point which will be projected.

        Parameter ``flags``:
            Flags to select the type of SilhouetteSample3f to generate from
            the projection. Only one type of discontinuity can be used per
            call.

        Parameter ``sample``:
            A random number that can be used to define the projection
            operation.

        Returns:
            A boundary segment on the silhouette of the shape as seen from
            ``viewpoint``.
        """

    def sample_precomputed_silhouette(self, viewpoint: ScalarPoint3f, sample1: int, sample2: float, active: bool = True) -> SilhouetteSample3f:
        """
        Samples a boundary segement on the shape's silhouette using
        precomputed information computed in precompute_silhouette.

        This method is meant to be used for silhouettes that are shared
        between all threads, as is the case for primarily visible derivatives.

        This method's behavior is undefined when used in non-JIT variants or
        when the shape is not being differentiated.

        Parameter ``viewpoint``:
            The viewpoint that was used for the precomputed silhouette
            information

        Parameter ``sample1``:
            A sampled index from the return values of precompute_silhouette

        Parameter ``sample2``:
            A uniformly distributed sample in ``[0,1]``

        Returns:
            A boundary segment on the silhouette of the shape as seen from
            ``viewpoint``.
        """

    def eval_parameterization(self, uv: ScalarPoint2f, ray_flags: int = 14, active: bool = True) -> SurfaceInteraction3f:
        """
        Parameterize the mesh using UV values

        This function maps a 2D UV value to a surface interaction data
        structure. Its behavior is only well-defined in regions where this
        mapping is bijective. The default implementation throws.
        """

    def surface_area(self) -> float:
        """
        Return the shape's surface area.

        The function assumes that the object is not undergoing some kind of
        time-dependent scaling.

        The default implementation throws an exception.
        """

class ShapePtr(drjit.ArrayBase[ShapePtr, _ShapePtrCp, Shape, Shape, ShapePtr, ShapePtr, drjit.auto.ad.Bool]):
    Variant: str = 'llvm_ad_spectral_polarized'

    @overload
    def is_emitter(self) -> drjit.auto.ad.Bool:
        """Is this shape also an area emitter?"""

    @overload
    def is_emitter(self) -> drjit.auto.ad.Bool: ...

    @overload
    def is_sensor(self) -> drjit.auto.ad.Bool:
        """Is this shape also an area sensor?"""

    @overload
    def is_sensor(self) -> drjit.auto.ad.Bool: ...

    @overload
    def is_mesh(self) -> drjit.auto.ad.Bool:
        """Is this shape a triangle mesh?"""

    @overload
    def is_mesh(self) -> drjit.auto.ad.Bool: ...

    @overload
    def is_medium_transition(self) -> drjit.auto.ad.Bool:
        """Does the surface of this shape mark a medium transition?"""

    @overload
    def is_medium_transition(self) -> drjit.auto.ad.Bool: ...

    @overload
    def shape_type(self) -> drjit.auto.ad.UInt:
        """Returns the shape type ShapeType of this shape"""

    @overload
    def shape_type(self) -> drjit.auto.ad.UInt: ...

    @overload
    def interior_medium(self) -> MediumPtr:
        """Return the medium that lies on the interior of this shape"""

    @overload
    def interior_medium(self) -> MediumPtr: ...

    @overload
    def exterior_medium(self) -> MediumPtr:
        """Return the medium that lies on the exterior of this shape"""

    @overload
    def exterior_medium(self) -> MediumPtr: ...

    @overload
    def bsdf(self) -> BSDFPtr:
        """Return the shape's BSDF"""

    @overload
    def bsdf(self) -> BSDFPtr: ...

    @overload
    def sensor(self) -> SensorPtr:
        """Return the area sensor associated with this shape (if any)"""

    @overload
    def sensor(self) -> SensorPtr: ...

    @overload
    def emitter(self) -> EmitterPtr:
        """Return the area emitter associated with this shape (if any)"""

    @overload
    def emitter(self) -> EmitterPtr: ...

    @overload
    def compute_surface_interaction(self, ray: Ray3f, pi: PreliminaryIntersection3f, ray_flags: int = 14, active: drjit.auto.ad.Bool = True) -> SurfaceInteraction3f:
        """
        Compute and return detailed information related to a surface
        interaction

        The implementation should at most compute the fields ``p``, ``uv``,
        ``n``, ``sh_frame``.n, ``dp_du``, ``dp_dv``, ``dn_du`` and ``dn_dv``.
        The ``flags`` parameter specifies which of those fields should be
        computed.

        The fields ``t``, ``time``, ``wavelengths``, ``shape``,
        ``prim_index``, ``instance``, will already have been initialized by
        the caller. The field ``wi`` is initialized by the caller following
        the call to compute_surface_interaction(), and ``duv_dx``, and
        ``duv_dy`` are left uninitialized.

        Parameter ``ray``:
            Ray associated with the ray intersection

        Parameter ``pi``:
            Data structure carrying information about the ray intersection

        Parameter ``ray_flags``:
            Flags specifying which information should be computed

        Parameter ``recursion_depth``:
            Integer specifying the recursion depth for nested virtual function
            call to this method (e.g. used for instancing).

        Returns:
            A data structure containing the detailed information
        """

    @overload
    def compute_surface_interaction(self, ray: Ray3f, pi: PreliminaryIntersection3f, ray_flags: int = 14, active: drjit.auto.ad.Bool = True) -> SurfaceInteraction3f: ...

    @overload
    def has_attribute(self, name: str, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Bool:
        """
        Returns whether this shape contains the specified attribute.

        Parameter ``name``:
            Name of the attribute
        """

    @overload
    def has_attribute(self, name: str, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Bool: ...

    @overload
    def eval_attribute(self, name: str, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> UnpolarizedSpectrum:
        """
        Evaluate a specific shape attribute at the given surface interaction.

        Shape attributes are user-provided fields that provide extra
        information at an intersection. An example of this would be a per-
        vertex or per-face color on a triangle mesh.

        Parameter ``name``:
            Name of the attribute to evaluate

        Parameter ``si``:
            Surface interaction associated with the query

        Returns:
            An unpolarized spectral power distribution or reflectance value
        """

    @overload
    def eval_attribute(self, name: str, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> UnpolarizedSpectrum: ...

    @overload
    def eval_attribute_1(self, name: str, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Monochromatic evaluation of a shape attribute at the given surface
        interaction

        This function differs from eval_attribute() in that it provided raw
        access to scalar intensity/reflectance values without any color
        processing (e.g. spectral upsampling).

        Parameter ``name``:
            Name of the attribute to evaluate

        Parameter ``si``:
            Surface interaction associated with the query

        Returns:
            An scalar intensity or reflectance value
        """

    @overload
    def eval_attribute_1(self, name: str, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float: ...

    @overload
    def eval_attribute_3(self, name: str, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> Color3f:
        """
        Trichromatic evaluation of a shape attribute at the given surface
        interaction

        This function differs from eval_attribute() in that it provided raw
        access to RGB intensity/reflectance values without any additional
        color processing (e.g. RGB-to-spectral upsampling).

        Parameter ``name``:
            Name of the attribute to evaluate

        Parameter ``si``:
            Surface interaction associated with the query

        Returns:
            An trichromatic intensity or reflectance value
        """

    @overload
    def eval_attribute_3(self, name: str, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> Color3f: ...

    @overload
    def ray_intersect_preliminary(self, ray: Ray3f, prim_index: int = 0, active: drjit.auto.ad.Bool = True) -> PreliminaryIntersection3f:
        """
        Fast ray intersection

        Efficiently test whether the shape is intersected by the given ray,
        and return preliminary information about the intersection if that is
        the case.

        If the intersection is deemed relevant (e.g. the closest to the ray
        origin), detailed intersection information can later be obtained via
        the create_surface_interaction() method.

        Parameter ``ray``:
            The ray to be tested for an intersection

        Parameter ``prim_index``:
            Index of the primitive to be intersected. This index is ignored by
            a shape that contains a single primitive. Otherwise, if no index
            is provided, the ray intersection will be performed on the shape's
            first primitive at index 0.
        """

    @overload
    def ray_intersect_preliminary(self, ray: Ray3f, prim_index: int = 0, active: drjit.auto.ad.Bool = True) -> PreliminaryIntersection3f: ...

    @overload
    def ray_intersect(self, ray: Ray3f, ray_flags: int = 14, active: drjit.auto.ad.Bool = True) -> SurfaceInteraction3f:
        """
        Test for an intersection and return detailed information

        This operation combines the prior ray_intersect_preliminary() and
        compute_surface_interaction() operations.

        Parameter ``ray``:
            The ray to be tested for an intersection

        Parameter ``flags``:
            Describe how the detailed information should be computed
        """

    @overload
    def ray_intersect(self, ray: Ray3f, ray_flags: int = 14, active: drjit.auto.ad.Bool = True) -> SurfaceInteraction3f: ...

    @overload
    def ray_test(self, ray: Ray3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Bool:
        """
        Fast ray shadow test

        Efficiently test whether the shape is intersected by the given ray.

        No details about the intersection are returned, hence the function is
        only useful for visibility queries. For most shapes, the
        implementation will simply forward the call to
        ray_intersect_preliminary(). When the shape actually contains a nested
        kd-tree, some optimizations are possible.

        Parameter ``ray``:
            The ray to be tested for an intersection

        Parameter ``prim_index``:
            Index of the primitive to be intersected
        """

    @overload
    def ray_test(self, ray: Ray3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Bool: ...

    @overload
    def sample_position(self, time: drjit.auto.ad.Float, sample: Point2f, active: drjit.auto.ad.Bool = True) -> PositionSample3f:
        """
        Sample a point on the surface of this shape

        The sampling strategy is ideally uniform over the surface, though
        implementations are allowed to deviate from a perfectly uniform
        distribution as long as this is reflected in the returned probability
        density.

        Parameter ``time``:
            The scene time associated with the position sample

        Parameter ``sample``:
            A uniformly distributed 2D point on the domain ``[0,1]^2``

        Returns:
            A PositionSample instance describing the generated sample
        """

    @overload
    def sample_position(self, time: drjit.auto.ad.Float, sample: Point2f, active: drjit.auto.ad.Bool = True) -> PositionSample3f: ...

    @overload
    def pdf_position(self, ps: PositionSample3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Query the probability density of sample_position() for a particular
        point on the surface.

        Parameter ``ps``:
            A position record describing the sample in question

        Returns:
            The probability density per unit area
        """

    @overload
    def pdf_position(self, ps: PositionSample3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float: ...

    @overload
    def sample_direction(self, it: Interaction3f, sample: Point2f, active: drjit.auto.ad.Bool = True) -> DirectionSample3f:
        """
        Sample a direction towards this shape with respect to solid angles
        measured at a reference position within the scene

        An ideal implementation of this interface would achieve a uniform
        solid angle density within the surface region that is visible from the
        reference position ``it.p`` (though such an ideal implementation is
        usually neither feasible nor advisable due to poor efficiency).

        The function returns the sampled position and the inverse probability
        per unit solid angle associated with the sample.

        When the Shape subclass does not supply a custom implementation of
        this function, the Shape class reverts to a fallback approach that
        piggybacks on sample_position(). This will generally lead to a
        suboptimal sample placement and higher variance in Monte Carlo
        estimators using the samples.

        Parameter ``it``:
            A reference position somewhere within the scene.

        Parameter ``sample``:
            A uniformly distributed 2D point on the domain ``[0,1]^2``

        Returns:
            A DirectionSample instance describing the generated sample
        """

    @overload
    def sample_direction(self, it: Interaction3f, sample: Point2f, active: drjit.auto.ad.Bool = True) -> DirectionSample3f: ...

    @overload
    def pdf_direction(self, it: Interaction3f, ps: DirectionSample3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float:
        """
        Query the probability density of sample_direction()

        Parameter ``it``:
            A reference position somewhere within the scene.

        Parameter ``ps``:
            A position record describing the sample in question

        Returns:
            The probability density per unit solid angle
        """

    @overload
    def pdf_direction(self, it: Interaction3f, ps: DirectionSample3f, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float: ...

    @overload
    def silhouette_discontinuity_types(self) -> drjit.auto.ad.UInt:
        r"""//! @{ \name Silhouette sampling routines and other utilities"""

    @overload
    def silhouette_discontinuity_types(self) -> drjit.auto.ad.UInt: ...

    @overload
    def silhouette_sampling_weight(self) -> drjit.auto.ad.Float:
        """Return this shape's sampling weight w.r.t. all shapes in the scene"""

    @overload
    def silhouette_sampling_weight(self) -> drjit.auto.ad.Float: ...

    @overload
    def sample_silhouette(self, sample: Point3f, flags: int, active: drjit.auto.ad.Bool = True) -> SilhouetteSample3f:
        """
        Map a point sample in boundary sample space to a silhouette segment

        This method's behavior is undefined when used in non-JIT variants or
        when the shape is not being differentiated.

        Parameter ``sample``:
            The boundary space sample (a point in the unit cube).

        Parameter ``flags``:
            Flags to select the type of silhouettes to sample from (see
            DiscontinuityFlags). Only one type of discontinuity can be sampled
            per call.

        Returns:
            Silhouette sample record.
        """

    @overload
    def sample_silhouette(self, sample: Point3f, flags: int, active: drjit.auto.ad.Bool = True) -> SilhouetteSample3f: ...

    @overload
    def invert_silhouette_sample(self, ss: SilhouetteSample3f, active: drjit.auto.ad.Bool = True) -> Point3f:
        """
        Map a silhouette segment to a point in boundary sample space

        This method is the inverse of sample_silhouette(). The mapping from/to
        boundary sample space to/from boundary segments is bijective.

        This method's behavior is undefined when used in non-JIT variants or
        when the shape is not being differentiated.

        Parameter ``ss``:
            The sampled boundary segment

        Returns:
            The corresponding boundary sample space point
        """

    @overload
    def invert_silhouette_sample(self, ss: SilhouetteSample3f, active: drjit.auto.ad.Bool = True) -> Point3f: ...

    @overload
    def differential_motion(self, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> Point3f:
        r"""
        Return the attached (AD) point on the shape's surface

        This method is only useful when using automatic differentiation. The
        immediate/primal return value of this method is exactly equal to
        \`si.p\`.

        The input `si` does not need to be explicitly detached, it is done by
        the method itself.

        If the shape cannot be differentiated, this method will return the
        detached input point.

        note:: The returned attached point is exactly the same as a point
        which is computed by calling compute_surface_interaction with the
        RayFlags::FollowShape flag.

        Parameter ``si``:
            The surface point for which the function will be evaluated.

        Not all fields of the object need to be filled. Only the `prim_index`,
        `p` and `uv` fields are required. Certain shapes will only use a
        subset of these.

        Returns:
            The same surface point as the input but attached (AD) to the
            shape's parameters.
        """

    @overload
    def differential_motion(self, si: SurfaceInteraction3f, active: drjit.auto.ad.Bool = True) -> Point3f: ...

    @overload
    def primitive_silhouette_projection(self, viewpoint: Point3f, si: SurfaceInteraction3f, flags: int, sample: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> SilhouetteSample3f:
        """
        Projects a point on the surface of the shape to its silhouette as seen
        from a specified viewpoint.

        This method only projects the `si.p` point within its primitive.

        Not all of the fields of the SilhouetteSample3f might be filled by
        this method. Each shape will at the very least fill its return value
        with enough information for it to be used by invert_silhouette_sample.

        The projection operation might not find the closest silhouette point
        to the given surface point. For example, it can be guided by a random
        number ``sample``. Not all shapes types need this random number, each
        shape implementation is free to define its own algorithm and
        guarantees about the projection operation.

        This method's behavior is undefined when used in non-JIT variants or
        when the shape is not being differentiated.

        Parameter ``viewpoint``:
            The viewpoint which defines the silhouette to project the point
            to.

        Parameter ``si``:
            The surface point which will be projected.

        Parameter ``flags``:
            Flags to select the type of SilhouetteSample3f to generate from
            the projection. Only one type of discontinuity can be used per
            call.

        Parameter ``sample``:
            A random number that can be used to define the projection
            operation.

        Returns:
            A boundary segment on the silhouette of the shape as seen from
            ``viewpoint``.
        """

    @overload
    def primitive_silhouette_projection(self, viewpoint: Point3f, si: SurfaceInteraction3f, flags: int, sample: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> SilhouetteSample3f: ...

    @overload
    def sample_precomputed_silhouette(self, viewpoint: Point3f, sample1: drjit.auto.ad.UInt, sample2: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> SilhouetteSample3f:
        """
        Samples a boundary segement on the shape's silhouette using
        precomputed information computed in precompute_silhouette.

        This method is meant to be used for silhouettes that are shared
        between all threads, as is the case for primarily visible derivatives.

        This method's behavior is undefined when used in non-JIT variants or
        when the shape is not being differentiated.

        Parameter ``viewpoint``:
            The viewpoint that was used for the precomputed silhouette
            information

        Parameter ``sample1``:
            A sampled index from the return values of precompute_silhouette

        Parameter ``sample2``:
            A uniformly distributed sample in ``[0,1]``

        Returns:
            A boundary segment on the silhouette of the shape as seen from
            ``viewpoint``.
        """

    @overload
    def sample_precomputed_silhouette(self, viewpoint: Point3f, sample1: drjit.auto.ad.UInt, sample2: drjit.auto.ad.Float, active: drjit.auto.ad.Bool = True) -> SilhouetteSample3f: ...

    @overload
    def eval_parameterization(self, uv: Point2f, ray_flags: int = 14, active: drjit.auto.ad.Bool = True) -> SurfaceInteraction3f:
        """
        Parameterize the mesh using UV values

        This function maps a 2D UV value to a surface interaction data
        structure. Its behavior is only well-defined in regions where this
        mapping is bijective. The default implementation throws.
        """

    @overload
    def eval_parameterization(self, uv: Point2f, ray_flags: int = 14, active: drjit.auto.ad.Bool = True) -> SurfaceInteraction3f: ...

    @overload
    def surface_area(self) -> drjit.auto.ad.Float:
        """
        Return the shape's surface area.

        The function assumes that the object is not undergoing some kind of
        time-dependent scaling.

        The default implementation throws an exception.
        """

    @overload
    def surface_area(self) -> drjit.auto.ad.Float: ...

class ShapeType(enum.IntEnum):
    """Enumeration of all shape types in Mitsuba"""

    Mesh = 0
    """Meshes (`ply`, `obj`, `serialized`)"""

    BSplineCurve = 1
    """B-Spline curves (`bsplinecurve`)"""

    Cylinder = 2
    """Cylinders (`cylinder`)"""

    Disk = 3
    """Disks (`disk`)"""

    LinearCurve = 4
    """Linear curves (`linearcurve`)"""

    Rectangle = 5
    """Rectangles (`rectangle`)"""

    SDFGrid = 6
    """SDF Grids (`sdfgrid`)"""

    Sphere = 7
    """Spheres (`sphere`)"""

    Other = 9
    """Other shapes"""

class SilhouetteSample3f(PositionSample3f):
    """
    Data structure holding the result of visibility silhouette sampling
    operations on geometry.
    """

    @overload
    def __init__(self) -> None:
        """Construct an uninitialized silhouette sample"""

    @overload
    def __init__(self, other: SilhouetteSample3f) -> None:
        """Copy constructor"""

    @property
    def discontinuity_type(self) -> int:
        """Type of discontinuity (DiscontinuityFlags)"""

    @discontinuity_type.setter
    def discontinuity_type(self, arg: int, /) -> None: ...

    @property
    def d(self) -> ScalarVector3f:
        """Direction of the boundary segment sample"""

    @d.setter
    def d(self, arg: ScalarVector3f, /) -> None: ...

    @property
    def silhouette_d(self) -> ScalarVector3f:
        """Direction of the silhouette curve at the boundary point"""

    @silhouette_d.setter
    def silhouette_d(self, arg: ScalarVector3f, /) -> None: ...

    @property
    def prim_index(self) -> int:
        """Primitive index, e.g. the triangle ID (if applicable)"""

    @prim_index.setter
    def prim_index(self, arg: int, /) -> None: ...

    @property
    def scene_index(self) -> int:
        """Index of the shape in the scene (if applicable)"""

    @scene_index.setter
    def scene_index(self, arg: int, /) -> None: ...

    @property
    def flags(self) -> int:
        """
        The set of ``DiscontinuityFlags`` that were used to generate this
        sample
        """

    @flags.setter
    def flags(self, arg: int, /) -> None: ...

    @property
    def projection_index(self) -> int:
        """
        Projection index indicator

        For primitives like triangle meshes, a boundary segment is defined not
        only by the triangle index but also the edge index of the selected
        triangle. A value larger than 3 indicates a failed projection. For
        other primitives, zero indicates a failed projection.

        For triangle meshes, index 0 stands for the directed edge p0->p1 (not
        the opposite edge p1->p2), index 1 stands for the edge p1->p2, and
        index 2 for p2->p0.
        """

    @projection_index.setter
    def projection_index(self, arg: int, /) -> None: ...

    @property
    def shape(self) -> Shape:
        """Pointer to the associated shape"""

    @shape.setter
    def shape(self, arg: Shape, /) -> None: ...

    @property
    def foreshortening(self) -> float:
        """
        Local-form boundary foreshortening term.

        It stores `sin_phi_B` for perimeter silhouettes or the normal
        curvature for interior silhouettes.
        """

    @foreshortening.setter
    def foreshortening(self, arg: float, /) -> None: ...

    @property
    def offset(self) -> float:
        """
        Offset along the boundary segment direction (`d`) to avoid self-
        intersections.
        """

    @offset.setter
    def offset(self, arg: float, /) -> None: ...

    def is_valid(self) -> bool:
        """Is the current boundary segment valid="""

    def spawn_ray(self) -> Ray3f:
        """
        Spawn a ray on the silhouette point in the direction of d

        The ray origin is offset in the direction of the segment (d) aswell as
        in the in the direction of the silhouette normal (n). Without this
        offsetting, during a ray intersection, the ray could potentially find
        an intersection point at its origin due to numerical instabilities in
        the intersection routines.
        """

    def __repr__(self) -> str: ...

    def assign(self, arg: SilhouetteSample3f, /) -> None: ...

    def __setitem__(self, arg0: bool, arg1: SilhouetteSample3f, /) -> None: ...

class Spiral(Object):
    """
    Generates a spiral of blocks to be rendered.

    Author:
        Adam Arbree Aug 25, 2005 RayTracer.java Used with permission.
        Copyright 2005 Program of Computer Graphics, Cornell University
    """

    def __init__(self, size: ScalarVector2u, offset: ScalarVector2u, block_size: int = 32, passes: int = 1) -> None:
        """
        Create a new spiral generator for the given size, offset into a larger
        frame, and block size
        """

    def max_block_size(self) -> int:
        """Return the maximum block size"""

    def block_count(self) -> int:
        """Return the total number of blocks"""

    def reset(self) -> None:
        """
        Reset the spiral to its initial state. Does not affect the number of
        passes.
        """

    def next_block(self) -> tuple[ScalarVector2i, ScalarVector2u, int]:
        """
        Return the offset, size, and unique identifier of the next block.

        A size of zero indicates that the spiral traversal is done.
        """

class Stream(Object):
    """
    Abstract seekable stream class

    Specifies all functions to be implemented by stream subclasses and
    provides various convenience functions layered on top of on them.

    All ``read*()`` and ``write*()`` methods support transparent
    conversion based on the endianness of the underlying system and the
    value passed to set_byte_order(). Whenever host_byte_order() and
    byte_order() disagree, the endianness is swapped.

    See also:
        FileStream, MemoryStream, DummyStream
    """

    class EByteOrder(enum.Enum):
        """Defines the byte order (endianness) to use in this Stream"""

        EBigEndian = 0

        ELittleEndian = 1
        """PowerPC, SPARC, Motorola 68K"""

        ENetworkByteOrder = 0
        """x86, x86_64"""

    EBigEndian: Stream.EByteOrder = Stream.EByteOrder.EBigEndian

    ELittleEndian: Stream.EByteOrder = Stream.EByteOrder.ELittleEndian

    def close(self) -> None:
        """
        Closes the stream.

        No further read or write operations are permitted.

        This function is idempotent. It may be called automatically by the
        destructor.
        """

    def set_byte_order(self, arg: Stream.EByteOrder, /) -> None:
        """
        Sets the byte order to use in this stream.

        Automatic conversion will be performed on read and write operations to
        match the system's native endianness.

        No consistency is guaranteed if this method is called after performing
        some read and write operations on the system using a different
        endianness.
        """

    def byte_order(self) -> Stream.EByteOrder:
        """Returns the byte order of this stream."""

    def seek(self, arg: int, /) -> None:
        """
        Seeks to a position inside the stream.

        Seeking beyond the size of the buffer will not modify the length of
        its contents. However, a subsequent write should start at the sought
        position and update the size appropriately.
        """

    def truncate(self, arg: int, /) -> None:
        """
        Truncates the stream to a given size.

        The position is updated to ``min(old_position, size)``. Throws an
        exception if in read-only mode.
        """

    def tell(self) -> int:
        """Gets the current position inside the stream"""

    def size(self) -> int:
        """Returns the size of the stream"""

    def flush(self) -> None:
        """Flushes the stream's buffers, if any"""

    def can_read(self) -> bool:
        """Can we read from the stream?"""

    def can_write(self) -> bool:
        """Can we write to the stream?"""

    @staticmethod
    def host_byte_order() -> Stream.EByteOrder:
        """Returns the byte order of the underlying machine."""

    def write(self, arg: bytes, /) -> None:
        r"""
        Writes a specified amount of data into the stream. \note This does
        **not** handle endianness swapping.

        Throws an exception when not all data could be written.
        Implementations need to handle endianness swap when appropriate.
        """

    def read(self, arg: int, /) -> bytes:
        r"""
        Writes a specified amount of data into the stream. \note This does
        **not** handle endianness swapping.

        Throws an exception when not all data could be written.
        Implementations need to handle endianness swap when appropriate.
        """

    def skip(self, arg: int, /) -> None:
        """Skip ahead by a given number of bytes"""

    def read_line(self) -> str:
        """Convenience function for reading a line of text from an ASCII file"""

    def write_line(self, arg: str, /) -> None:
        """Convenience function for writing a line of text to an ASCII file"""

    def read_int8(self) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def write_int8(self, arg: int, /) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def read_uint8(self) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def write_uint8(self, arg: int, /) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def read_int16(self) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def write_int16(self, arg: int, /) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def read_uint16(self) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def write_uint16(self, arg: int, /) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def read_int32(self) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def write_int32(self, arg: int, /) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def read_uint32(self) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def write_uint32(self, arg: int, /) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def read_int64(self) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def write_int64(self, arg: int, /) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def read_uint64(self) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def write_uint64(self, arg: int, /) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def read_single(self) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def write_single(self, arg: float, /) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def read_double(self) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def write_double(self, arg: float, /) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def read_float(self) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def write_float(self, arg: float, /) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def read_bool(self) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def write_bool(self, arg: bool, /) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def read_string(self) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

    def write_string(self, arg: str, /) -> object:
        """
        Reads one object of type T from the stream at the current position by
        delegating to the appropriate ``serialization_helper``.

        Endianness swapping is handled automatically if needed.
        """

class StreamAppender(Appender):
    """
    %Appender implementation, which writes to an arbitrary C++ output
    stream
    """

    def __init__(self, arg: str, /) -> None:
        """
        Create a new stream appender

        Remark:
            This constructor is not exposed in the Python bindings
        """

    def logs_to_file(self) -> bool:
        """Does this appender log to a file"""

    def read_log(self) -> str:
        """Return the contents of the log file as a string"""

class Struct(Object):
    """
    Descriptor for specifying the contents and in-memory layout of a POD-
    style data record

    Remark:
        The python API provides an additional ``dtype()`` method, which
        returns the NumPy ``dtype`` equivalent of a given ``Struct``
        instance.
    """

    def __init__(self, pack: bool = False, byte_order: Struct.ByteOrder = Struct.ByteOrder.HostByteOrder) -> None:
        """
        Create a new ``Struct`` and indicate whether the contents are packed
        or aligned
        """

    class Field:
        """Field specifier with size and offset"""

        def is_float(self) -> bool: ...

        def is_integer(self) -> bool: ...

        def is_signed(self) -> bool: ...

        def is_unsigned(self) -> bool: ...

        def range(self) -> tuple[float, float]: ...

        def __hash__(self) -> int: ...

        @property
        def type(self) -> Struct.Type:
            """Type identifier"""

        @type.setter
        def type(self, arg: Struct.Type, /) -> None: ...

        @property
        def size(self) -> int:
            """Size in bytes"""

        @size.setter
        def size(self, arg: int, /) -> None: ...

        @property
        def offset(self) -> int:
            """Offset within the ``Struct`` (in bytes)"""

        @offset.setter
        def offset(self, arg: int, /) -> None: ...

        @property
        def flags(self) -> int:
            """Additional flags"""

        @flags.setter
        def flags(self, arg: int, /) -> None: ...

        @property
        def name(self) -> str:
            """Name of the field"""

        @name.setter
        def name(self, arg: str, /) -> None: ...

        @property
        def blend(self) -> list[tuple[float, str]]:
            """
            For use with StructConverter::convert()

            Specifies a pair of weights and source field names that will be
            linearly blended to obtain the output field value. Note that this only
            works for floating point fields or integer fields with the
            Flags::Normalized flag. Gamma-corrected fields will be blended in
            linear space.
            """

        @blend.setter
        def blend(self, arg: Sequence[tuple[float, str]], /) -> None: ...

    class Type(enum.Enum):
        Int8 = 2

        UInt8 = 1

        Int16 = 4

        UInt16 = 3

        Int32 = 6

        UInt32 = 5

        Int64 = 8

        UInt64 = 7

        Float16 = 9

        Float32 = 10

        Float64 = 11

        Invalid = 0

    class Flags(enum.IntEnum):
        Empty = 0
        """No flags set (default value)"""

        Normalized = 1
        """
        Specifies whether an integer field encodes a normalized value in the
        range [0, 1]. The flag is ignored if specified for floating point
        valued fields.
        """

        Gamma = 2
        """
        Specifies whether the field encodes a sRGB gamma-corrected value.
        Assumes ``Normalized`` is also specified.
        """

        Weight = 16
        """
        In FieldConverter::convert, when an input structure contains a weight
        field, the value of all entries are considered to be expressed
        relative to its value. Converting to an un-weighted structure entails
        a division by the weight.
        """

        Assert = 4
        """
        In FieldConverter::convert, check that the field value matches the
        specified default value. Otherwise, return a failure
        """

        Alpha = 64
        """Specifies whether the field encodes an alpha value"""

        PremultipliedAlpha = 32
        """Specifies whether the field encodes an alpha premultiplied value"""

        Default = 8
        """
        In FieldConverter::convert, when the field is missing in the source
        record, replace it by the specified default value
        """

    class ByteOrder(enum.Enum):
        LittleEndian = 0

        BigEndian = 1

        HostByteOrder = 2

    def append(self, name: str, type: Struct.Type, flags: int = Flags.Empty, default: float = 0.0) -> Struct:
        """
        Append a new field to the ``Struct``; determines size and offset
        automatically
        """

    def field(self, arg: str, /) -> Struct.Field:
        """Look up a field by name (throws an exception if not found)"""

    def __getitem__(self, arg: int, /) -> Struct.Field: ...

    def __len__(self) -> int: ...

    def __hash__(self) -> int: ...

    def size(self) -> int:
        """Return the size (in bytes) of the data structure, including padding"""

    def alignment(self) -> int:
        """Return the alignment (in bytes) of the data structure"""

    def byte_order(self) -> Struct.ByteOrder:
        """Return the byte order of the ``Struct``"""

    def field_count(self) -> int:
        """Return the number of fields"""

    def has_field(self, arg: str, /) -> bool:
        """Check if the ``Struct`` has a field of the specified name"""

    @staticmethod
    def is_float(arg: Struct.Type, /) -> bool:
        """Check whether the given type is a floating point type"""

    @staticmethod
    def is_integer(arg: Struct.Type, /) -> bool:
        """Check whether the given type is an integer type"""

    @staticmethod
    def is_signed(arg: Struct.Type, /) -> bool:
        """Check whether the given type is a signed type"""

    @staticmethod
    def is_unsigned(arg: Struct.Type, /) -> bool:
        """Check whether the given type is an unsigned type"""

    @staticmethod
    def range(arg: Struct.Type, /) -> tuple[float, float]:
        """Return the representable range of the given type"""

class StructConverter(Object):
    """
    This class solves the any-to-any problem: efficiently converting from
    one kind of structured data representation to another

    Graphics applications often need to convert from one kind of
    structured representation to another, for instance when loading/saving
    image or mesh data. Consider the following data records which both
    describe positions tagged with color data.

    ```
    struct Source { // <-- Big endian! :(
       uint8_t r, g, b; // in sRGB
       half x, y, z;
    };

    struct Target { // <-- Little endian!
       float x, y, z;
       float r, g, b, a; // in linear space
    };
    ```

    The record ``Source`` may represent what is stored in a file on disk,
    while ``Target`` represents the expected input of the implementation.
    Not only are the formats (e.g. float vs half or uint8_t, incompatible
    endianness) and encodings different (e.g. gamma correction vs linear
    space), but the second record even has a different order and extra
    fields that don't exist in the first one.

    This class provides a routine convert() which <ol>

    * reorders entries

    * converts between many different formats (u[int]8-64, float16-64)

    * performs endianness conversion

    * applies or removes gamma correction

    * optionally checks that certain entries have expected default values

    * substitutes missing values with specified defaults

    * performs linear transformations of groups of fields (e.g. between
    different RGB color spaces)

    * applies dithering to avoid banding artifacts when converting 2D
    images

    </ol>

    The above operations can be arranged in countless ways, which makes it
    hard to provide an efficient generic implementation of this
    functionality. For this reason, the implementation of this class
    relies on a JIT compiler that generates fast conversion code on demand
    for each specific conversion. The function is cached and reused in
    case the same conversion is needed later on. Note that JIT compilation
    only works on x86_64 processors; other platforms use a slow generic
    fallback implementation.
    """

    def __init__(self, source: Struct, target: Struct, dither: bool = False) -> None: ...

    def source(self) -> Struct:
        """Return the source ``Struct`` descriptor"""

    def target(self) -> Struct:
        """Return the target ``Struct`` descriptor"""

    def convert(self, arg: bytes, /) -> bytes: ...

class SurfaceInteraction3f(Interaction3f):
    """Stores information related to a surface scattering interaction"""

    @overload
    def __init__(self) -> None:
        """
        Construct from a position sample. Unavailable fields such as `wi` and
        the partial derivatives are left uninitialized. The `shape` pointer is
        left uninitialized because we can't guarantee that the given
        PositionSample::object points to a Shape instance.
        """

    @overload
    def __init__(self, arg: SurfaceInteraction3f) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, ps: PositionSample3f, wavelengths: ScalarColor0f) -> None:
        """
        Construct from a position sample. Unavailable fields such as `wi` and
        the partial derivatives are left uninitialized. The `shape` pointer is
        left uninitialized because we can't guarantee that the given
        PositionSample::object points to a Shape instance.
        """

    @property
    def shape(self) -> Shape:
        """Pointer to the associated shape"""

    @shape.setter
    def shape(self, shape: Shape | None) -> None: ...

    @property
    def uv(self) -> ScalarPoint2f:
        """UV surface coordinates"""

    @uv.setter
    def uv(self, arg: ScalarPoint2f, /) -> None: ...

    @property
    def sh_frame(self) -> Frame3f:
        """Shading frame"""

    @sh_frame.setter
    def sh_frame(self, arg: Frame3f, /) -> None: ...

    @property
    def dp_du(self) -> ScalarVector3f:
        """Position partials wrt. the UV parameterization"""

    @dp_du.setter
    def dp_du(self, arg: ScalarVector3f, /) -> None: ...

    @property
    def dp_dv(self) -> ScalarVector3f:
        """Position partials wrt. the UV parameterization"""

    @dp_dv.setter
    def dp_dv(self, arg: ScalarVector3f, /) -> None: ...

    @property
    def dn_du(self) -> ScalarVector3f:
        """Normal partials wrt. the UV parameterization"""

    @dn_du.setter
    def dn_du(self, arg: ScalarVector3f, /) -> None: ...

    @property
    def dn_dv(self) -> ScalarVector3f:
        """Normal partials wrt. the UV parameterization"""

    @dn_dv.setter
    def dn_dv(self, arg: ScalarVector3f, /) -> None: ...

    @property
    def duv_dx(self) -> ScalarVector2f:
        """UV partials wrt. changes in screen-space"""

    @duv_dx.setter
    def duv_dx(self, arg: ScalarVector2f, /) -> None: ...

    @property
    def duv_dy(self) -> ScalarVector2f:
        """UV partials wrt. changes in screen-space"""

    @duv_dy.setter
    def duv_dy(self, arg: ScalarVector2f, /) -> None: ...

    @property
    def wi(self) -> ScalarVector3f:
        """Incident direction in the local shading frame"""

    @wi.setter
    def wi(self, arg: ScalarVector3f, /) -> None: ...

    @property
    def prim_index(self) -> int:
        """Primitive index, e.g. the triangle ID (if applicable)"""

    @prim_index.setter
    def prim_index(self, arg: int, /) -> None: ...

    @property
    def instance(self) -> Shape:
        """Stores a pointer to the parent instance (if applicable)"""

    @instance.setter
    def instance(self, instance: Shape | None) -> None: ...

    def initialize_sh_frame(self) -> None:
        """Initialize local shading frame using Gram-schmidt orthogonalization"""

    def to_world(self, v: ScalarVector3f) -> ScalarVector3f:
        """Convert a local shading-space vector into world space"""

    def to_local(self, v: ScalarVector3f) -> ScalarVector3f:
        """Convert a world-space vector into local shading coordinates"""

    def to_world_mueller(self, M_local: ScalarColor3f, wi_local: ScalarVector3f, wo_local: ScalarVector3f) -> ScalarColor3f:
        """
        Converts a Mueller matrix defined in a local frame to world space

        A Mueller matrix operates from the (implicitly) defined frame
        stokes_basis(in_forward) to the frame stokes_basis(out_forward). This
        method converts a Mueller matrix defined on directions in the local
        frame to a Mueller matrix defined on world-space directions.

        This expands to a no-op in non-polarized modes.

        Parameter ``M_local``:
            The Mueller matrix in local space, e.g. returned by a BSDF.

        Parameter ``in_forward_local``:
            Incident direction (along propagation direction of light), given
            in local frame coordinates.

        Parameter ``wo_local``:
            Outgoing direction (along propagation direction of light), given
            in local frame coordinates.

        Returns:
            Equivalent Mueller matrix that operates in world-space
            coordinates.
        """

    def to_local_mueller(self, M_world: ScalarColor3f, wi_world: ScalarVector3f, wo_world: ScalarVector3f) -> ScalarColor3f:
        """
        Converts a Mueller matrix defined in world space to a local frame

        A Mueller matrix operates from the (implicitly) defined frame
        stokes_basis(in_forward) to the frame stokes_basis(out_forward). This
        method converts a Mueller matrix defined on directions in world-space
        to a Mueller matrix defined in the local frame.

        This expands to a no-op in non-polarized modes.

        Parameter ``in_forward_local``:
            Incident direction (along propagation direction of light), given
            in world-space coordinates.

        Parameter ``wo_local``:
            Outgoing direction (along propagation direction of light), given
            in world-space coordinates.

        Returns:
            Equivalent Mueller matrix that operates in local frame
            coordinates.
        """

    def emitter(self, scene: Scene, active: bool = True) -> Emitter:
        r"""
        Return the emitter associated with the intersection (if any) \note
        Defined in scene.h
        """

    def is_sensor(self) -> bool:
        """Is the intersected shape also a sensor?"""

    def is_medium_transition(self) -> bool:
        """Does the surface mark a transition between two media?"""

    @overload
    def target_medium(self, d: ScalarVector3f) -> Medium:
        """
        Determine the target medium

        When ``is_medium_transition()`` = ``True``, determine the medium that
        contains the ``ray(this->p, d)``
        """

    @overload
    def target_medium(self, cos_theta: float) -> Medium:
        """
        Determine the target medium based on the cosine of the angle between
        the geometric normal and a direction

        Returns the exterior medium when ``cos_theta > 0`` and the interior
        medium when ``cos_theta <= 0``.
        """

    @overload
    def bsdf(self, ray: RayDifferential3f) -> BSDF:
        """
        Returns the BSDF of the intersected shape.

        The parameter ``ray`` must match the one used to create the
        interaction record. This function computes texture coordinate partials
        if this is required by the BSDF (e.g. for texture filtering).

        Implementation in 'bsdf.h'
        """

    @overload
    def bsdf(self) -> BSDF: ...

    def compute_uv_partials(self, ray: RayDifferential3f) -> None:
        """Computes texture coordinate partials"""

    def has_uv_partials(self) -> bool: ...

    def has_n_partials(self) -> bool: ...

    def __repr__(self) -> str: ...

class Texture(Object):
    """
    Base class of all surface texture implementations

    This class implements a generic texture map that supports evaluation
    at arbitrary surface positions and wavelengths (if compiled in
    spectral mode). It can be used to provide both intensities (e.g. for
    light sources) and unitless reflectance parameters (e.g. an albedo of
    a reflectance model).

    The spectrum can be evaluated at arbitrary (continuous) wavelengths,
    though the underlying function it is not required to be smooth or even
    continuous.
    """

    def __init__(self, props: Properties) -> None: ...

    @staticmethod
    def D65(scale: float = 1.0) -> Texture: ...

    def mean(self) -> float:
        """
        Return the mean value of the spectrum over the support
        (MI_WAVELENGTH_MIN..MI_WAVELENGTH_MAX)

        Not every implementation necessarily provides this function. The
        default implementation throws an exception.

        Even if the operation is provided, it may only return an
        approximation.
        """

    def max(self) -> float:
        """
        Return the maximum value of the spectrum

        Not every implementation necessarily provides this function. The
        default implementation throws an exception.

        Even if the operation is provided, it may only return an
        approximation.
        """

    def is_spatially_varying(self) -> bool:
        """Does this texture evaluation depend on the UV coordinates"""

    def eval(self, si: SurfaceInteraction3f, active: bool = True) -> ScalarColor3f:
        """
        Evaluate the texture at the given surface interaction

        Parameter ``si``:
            An interaction record describing the associated surface position

        Returns:
            An unpolarized spectral power distribution or reflectance value
        """

    def eval_1(self, si: SurfaceInteraction3f, active: bool = True) -> float:
        """
        Monochromatic evaluation of the texture at the given surface
        interaction

        This function differs from eval() in that it provided raw access to
        scalar intensity/reflectance values without any color processing (e.g.
        spectral upsampling). This is useful in parts of the renderer that
        encode scalar quantities using textures, e.g. a height field.

        Parameter ``si``:
            An interaction record describing the associated surface position

        Returns:
            An scalar intensity or reflectance value
        """

    def eval_1_grad(self, si: SurfaceInteraction3f, active: bool = True) -> ScalarVector2f:
        """
        Monochromatic evaluation of the texture gradient at the given surface
        interaction

        Parameter ``si``:
            An interaction record describing the associated surface position

        Returns:
            A (u,v) pair of intensity or reflectance value gradients
        """

    def eval_3(self, si: SurfaceInteraction3f, active: bool = True) -> ScalarColor3f:
        """
        Trichromatic evaluation of the texture at the given surface
        interaction

        This function differs from eval() in that it provided raw access to
        RGB intensity/reflectance values without any additional color
        processing (e.g. RGB-to-spectral upsampling). This is useful in parts
        of the renderer that encode 3D quantities using textures, e.g. a
        normal map.

        Parameter ``si``:
            An interaction record describing the associated surface position

        Returns:
            An trichromatic intensity or reflectance value
        """

    def sample_spectrum(self, si: SurfaceInteraction3f, sample: ScalarColor0f, active: bool = True) -> tuple[ScalarColor0f, ScalarColor3f]:
        """
        Importance sample a set of wavelengths proportional to the spectrum
        defined at the given surface position

        Not every implementation necessarily provides this function, and it is
        a no-op when compiling non-spectral variants of Mitsuba. The default
        implementation throws an exception.

        Parameter ``si``:
            An interaction record describing the associated surface position

        Parameter ``sample``:
            A uniform variate for each desired wavelength.

        Returns:
            1. Set of sampled wavelengths specified in nanometers

        2. The Monte Carlo importance weight (Spectral power distribution
        value divided by the sampling density)
        """

    def resolution(self) -> ScalarVector2i:
        """
        Returns the resolution of the texture, assuming that it is based on a
        discrete representation.

        The default implementation returns ``(1, 1)``
        """

    def pdf_spectrum(self, si: SurfaceInteraction3f, active: bool = True) -> ScalarColor0f:
        """
        Evaluate the density function of the sample_spectrum() method as a
        probability per unit wavelength (in units of 1/nm).

        Not every implementation necessarily overrides this function. The
        default implementation throws an exception.

        Parameter ``si``:
            An interaction record describing the associated surface position

        Returns:
            A density value for each wavelength in ``si.wavelengths`` (hence
            the Wavelength type).
        """

    def sample_position(self, sample: ScalarPoint2f, active: bool = True) -> tuple[ScalarPoint2f, float]:
        """
        Importance sample a surface position proportional to the overall
        spectral reflectance or intensity of the texture

        This function assumes that the texture is implemented as a mapping
        from 2D UV positions to texture values, which is not necessarily true
        for all textures (e.g. 3D noise functions, mesh attributes, etc.). For
        this reason, not every will plugin provide a specialized
        implementation, and the default implementation simply return the input
        sample (i.e. uniform sampling is used).

        Parameter ``sample``:
            A 2D vector of uniform variates

        Returns:
            1. A texture-space position in the range :math:`[0, 1]^2`

        2. The associated probability per unit area in UV space
        """

    def pdf_position(self, p: ScalarPoint2f, active: bool = True) -> float:
        """Returns the probability per unit area of sample_position()"""

    def spectral_resolution(self) -> float:
        """
        Returns the resolution of the spectrum in nanometers (if discretized)

        Not every implementation necessarily provides this function. The
        default implementation throws an exception.
        """

    def wavelength_range(self) -> ScalarVector2f:
        """
        Returns the range of wavelengths covered by the spectrum

        The default implementation returns ``(MI_CIE_MIN, MI_CIE_MAX)``
        """

class Thread(Object):
    """
    Cross-platform thread implementation

    Mitsuba threads are internally implemented via the ``std::thread``
    class defined in C++11. This wrapper class is needed to attach
    additional state (Loggers, Path resolvers, etc.) that is inherited
    when a thread launches another thread.
    """

    def __init__(self, name: str) -> None: ...

    class EPriority(enum.Enum):
        """Possible priority values for Thread::set_priority()"""

        EIdlePriority = 0

        ELowestPriority = 1

        ELowPriority = 2

        ENormalPriority = 3

        EHighPriority = 4

        EHighestPriority = 5

        ERealtimePriority = 6

    EIdlePriority: Thread.EPriority = Thread.EPriority.EIdlePriority

    ELowestPriority: Thread.EPriority = Thread.EPriority.ELowestPriority

    ELowPriority: Thread.EPriority = Thread.EPriority.ELowPriority

    ENormalPriority: Thread.EPriority = Thread.EPriority.ENormalPriority

    EHighPriority: Thread.EPriority = Thread.EPriority.EHighPriority

    EHighestPriority: Thread.EPriority = Thread.EPriority.EHighestPriority

    ERealtimePriority: Thread.EPriority = Thread.EPriority.ERealtimePriority

    def parent(self) -> Thread:
        """Return the parent thread"""

    def file_resolver(self) -> FileResolver:
        """Return the file resolver associated with the current thread"""

    def set_priority(self, arg: Thread.EPriority, /) -> bool:
        """
        Set the thread priority

        This does not always work -- for instance, Linux requires root
        privileges for this operation.

        Returns:
            ``True`` upon success.
        """

    def priority(self) -> Thread.EPriority:
        """Return the thread priority"""

    def set_core_affinity(self, arg: int, /) -> None:
        """
        Set the core affinity

        This function provides a hint to the operating system scheduler that
        the thread should preferably run on the specified processor core. By
        default, the parameter is set to -1, which means that there is no
        affinity.
        """

    def core_affinity(self) -> int:
        """Return the core affinity"""

    def set_critical(self, arg: bool, /) -> None:
        """
        Specify whether or not this thread is critical

        When an thread marked critical crashes from an uncaught exception, the
        whole process is brought down. The default is ``False``.
        """

    def is_critical(self) -> bool:
        """Return the value of the critical flag"""

    def set_name(self, arg: str, /) -> None:
        """Set the name of this thread"""

    def name(self) -> str:
        """Return the name of this thread"""

    @staticmethod
    def thread_id() -> int:
        """Return a unique ID that is associated with this thread"""

    def logger(self) -> Logger:
        """Return the thread's logger instance"""

    def set_logger(self, arg: Logger, /) -> None:
        """Set the logger instance used to process log messages from this thread"""

    def set_file_resolver(self, arg: FileResolver, /) -> None:
        """Set the file resolver associated with the current thread"""

    @staticmethod
    def thread() -> Thread:
        """Return the current thread"""

    @staticmethod
    def register_external_thread(arg: str, /) -> bool:
        """
        Register a new thread (e.g. Dr.Jit, Python) with Mitsuba thread
        system. Returns true upon success.
        """

    def start(self) -> None:
        """Start the thread"""

    def is_running(self) -> bool:
        """Is this thread still running?"""

    def detach(self) -> None:
        """
        Detach the thread and release resources

        After a call to this function, join() cannot be used anymore. This
        releases resources, which would otherwise be held until a call to
        join().
        """

    def join(self) -> None:
        """Wait until the thread finishes"""

    @staticmethod
    def sleep(arg: int, /) -> None:
        """Sleep for a certain amount of time (in milliseconds)"""

    @staticmethod
    def wait_for_tasks() -> None:
        """Wait for previously registered nanothread tasks to complete"""

class ThreadEnvironment:
    """
    Captures a thread environment (logger and file resolver). Used with
    ScopedSetThreadEnvironment
    """

    def __init__(self) -> None: ...

class Timer:
    def __init__(self) -> None: ...

    def value(self) -> int: ...

    def reset(self) -> int: ...

    def begin_stage(self, arg: str, /) -> None: ...

    def end_stage(self, arg: str, /) -> None: ...

class Transform3d:
    """
    Encapsulates a 4x4 homogeneous coordinate transformation along with
    its inverse transpose

    The Transform class provides a set of overloaded matrix-vector
    multiplication operators for vectors, points, and normals (all of them
    behave differently under homogeneous coordinate transformations, hence
    the need to represent them using separate types)
    """

    @overload
    def __init__(self) -> None:
        """Initialize with the identity matrix"""

    @overload
    def __init__(self, arg: Transform3d) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, arg: Annotated[ArrayLike, dict(dtype='float64', shape=(3, 3), order='C', device='cpu')], /) -> None: ...

    @overload
    def __init__(self) -> None: ...

    @overload
    def __init__(self, arg: drjit.auto.ad.Matrix3f64, /) -> None:
        """
        Initialize the transformation from the given matrix (and compute its
        inverse transpose)
        """

    @overload
    def __init__(self, arg0: drjit.auto.ad.Matrix3f64, arg1: drjit.auto.ad.Matrix3f64, /) -> None:
        """Initialize from a matrix and its inverse transpose"""

    @overload
    def __init__(self, arg: ScalarTransform3d, /) -> None:
        """Broadcast constructor"""

    def __mul__(self, arg: Transform3d, /) -> None: ...

    @overload
    def __matmul__(self, arg: Transform3d, /) -> Transform3d: ...

    @overload
    def __matmul__(self, arg: Point2d, /) -> Point2d: ...

    @overload
    def __matmul__(self, arg: Vector2d, /) -> Vector2d: ...

    @overload
    def __matmul__(self, arg: "mitsuba::Ray<mitsuba::Point<drjit::DiffArray<(JitBackend)2, double>, 2ul>, drjit::Matrix<mitsuba::Spectrum<drjit::DiffArray<(JitBackend)2, float>, 4ul>, 4ul> >", /) -> "mitsuba::Ray<mitsuba::Point<drjit::DiffArray<(JitBackend)2, double>, 2ul>, drjit::Matrix<mitsuba::Spectrum<drjit::DiffArray<(JitBackend)2, float>, 4ul>, 4ul> >": ...

    @overload
    def transform_affine(self, p: Point2d) -> Point2d:
        """
        Transform a 3D vector/point/normal/ray by a transformation that is
        known to be an affine 3D transformation (i.e. no perspective)
        """

    @overload
    def transform_affine(self, v: Vector2d) -> Vector2d: ...

    @overload
    def transform_affine(self, ray: "mitsuba::Ray<mitsuba::Point<drjit::DiffArray<(JitBackend)2, double>, 2ul>, drjit::Matrix<mitsuba::Spectrum<drjit::DiffArray<(JitBackend)2, float>, 4ul>, 4ul> >") -> "mitsuba::Ray<mitsuba::Point<drjit::DiffArray<(JitBackend)2, double>, 2ul>, drjit::Matrix<mitsuba::Spectrum<drjit::DiffArray<(JitBackend)2, float>, 4ul>, 4ul> >": ...

    def translate(self, v: Point2d) -> Transform3d:
        """Create a translation transformation"""

    def scale(self, v: Point2d) -> Transform3d:
        """Create a scale transformation"""

    def rotate(self, angle: drjit.auto.ad.Float64) -> Transform3d:
        """
        Create a rotation transformation in 2D. The angle is specified in
        degrees
        """

    def inverse(self) -> Transform3d:
        """
        Compute the inverse of this transformation (involves just shuffles, no
        arithmetic)
        """

    def translation(self) -> Vector2d:
        """Get the translation part of a matrix"""

    def has_scale(self) -> drjit.auto.ad.Bool:
        """
        Test for a scale component in each transform matrix by checking
        whether ``M . M^T == I`` (where ``M`` is the matrix in question and
        ``I`` is the identity).
        """

    @property
    def matrix(self) -> drjit.auto.ad.Matrix3f64: ...

    @matrix.setter
    def matrix(self, arg: drjit.auto.ad.Matrix3f64, /) -> None: ...

    @property
    def inverse_transpose(self) -> drjit.auto.ad.Matrix3f64: ...

    @inverse_transpose.setter
    def inverse_transpose(self, arg: drjit.auto.ad.Matrix3f64, /) -> None: ...

    def __repr__(self) -> str: ...

    def assign(self, arg: Transform3d, /) -> None: ...

    def __setitem__(self, arg0: drjit.auto.ad.Bool, arg1: Transform3d, /) -> None: ...

class Transform3f:
    """
    Encapsulates a 4x4 homogeneous coordinate transformation along with
    its inverse transpose

    The Transform class provides a set of overloaded matrix-vector
    multiplication operators for vectors, points, and normals (all of them
    behave differently under homogeneous coordinate transformations, hence
    the need to represent them using separate types)
    """

    @overload
    def __init__(self) -> None:
        """Initialize with the identity matrix"""

    @overload
    def __init__(self, arg: Transform3f) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, arg: Annotated[ArrayLike, dict(dtype='float32', shape=(3, 3), order='C', device='cpu')], /) -> None: ...

    @overload
    def __init__(self) -> None: ...

    @overload
    def __init__(self, arg: drjit.auto.ad.Matrix3f, /) -> None:
        """
        Initialize the transformation from the given matrix (and compute its
        inverse transpose)
        """

    @overload
    def __init__(self, arg0: drjit.auto.ad.Matrix3f, arg1: drjit.auto.ad.Matrix3f, /) -> None:
        """Initialize from a matrix and its inverse transpose"""

    @overload
    def __init__(self, arg: ScalarTransform3f, /) -> None:
        """Broadcast constructor"""

    def __mul__(self, arg: Transform3f, /) -> None: ...

    @overload
    def __matmul__(self, arg: Transform3f, /) -> Transform3f: ...

    @overload
    def __matmul__(self, arg: Point2f, /) -> Point2f: ...

    @overload
    def __matmul__(self, arg: Vector2f, /) -> Vector2f: ...

    @overload
    def __matmul__(self, arg: Ray2f, /) -> Ray2f: ...

    @overload
    def transform_affine(self, p: Point2f) -> Point2f:
        """
        Transform a 3D vector/point/normal/ray by a transformation that is
        known to be an affine 3D transformation (i.e. no perspective)
        """

    @overload
    def transform_affine(self, v: Vector2f) -> Vector2f: ...

    @overload
    def transform_affine(self, ray: Ray2f) -> Ray2f: ...

    def translate(self, v: Point2f) -> Transform3f:
        """Create a translation transformation"""

    def scale(self, v: Point2f) -> Transform3f:
        """Create a scale transformation"""

    def rotate(self, angle: drjit.auto.ad.Float) -> Transform3f:
        """
        Create a rotation transformation in 2D. The angle is specified in
        degrees
        """

    def inverse(self) -> Transform3f:
        """
        Compute the inverse of this transformation (involves just shuffles, no
        arithmetic)
        """

    def translation(self) -> Vector2f:
        """Get the translation part of a matrix"""

    def has_scale(self) -> drjit.auto.ad.Bool:
        """
        Test for a scale component in each transform matrix by checking
        whether ``M . M^T == I`` (where ``M`` is the matrix in question and
        ``I`` is the identity).
        """

    @property
    def matrix(self) -> drjit.auto.ad.Matrix3f: ...

    @matrix.setter
    def matrix(self, arg: drjit.auto.ad.Matrix3f, /) -> None: ...

    @property
    def inverse_transpose(self) -> drjit.auto.ad.Matrix3f: ...

    @inverse_transpose.setter
    def inverse_transpose(self, arg: drjit.auto.ad.Matrix3f, /) -> None: ...

    def __repr__(self) -> str: ...

    def assign(self, arg: Transform3f, /) -> None: ...

    def __setitem__(self, arg0: drjit.auto.ad.Bool, arg1: Transform3f, /) -> None: ...

class Transform4d:
    """
    Encapsulates a 4x4 homogeneous coordinate transformation along with
    its inverse transpose

    The Transform class provides a set of overloaded matrix-vector
    multiplication operators for vectors, points, and normals (all of them
    behave differently under homogeneous coordinate transformations, hence
    the need to represent them using separate types)
    """

    @overload
    def __init__(self) -> None:
        """Initialize with the identity matrix"""

    @overload
    def __init__(self, arg: Transform4d) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, arg: Annotated[ArrayLike, dict(dtype='float64', shape=(4, 4), order='C', device='cpu')], /) -> None: ...

    @overload
    def __init__(self, arg: list, /) -> None: ...

    @overload
    def __init__(self, arg: drjit.auto.ad.Matrix4f64, /) -> None:
        """
        Initialize the transformation from the given matrix (and compute its
        inverse transpose)
        """

    @overload
    def __init__(self, arg0: drjit.auto.ad.Matrix4f64, arg1: drjit.auto.ad.Matrix4f64, /) -> None:
        """Initialize from a matrix and its inverse transpose"""

    @overload
    def __init__(self, arg: ScalarTransform4d, /) -> None:
        """Broadcast constructor"""

    def translation(self) -> Vector3d:
        """Get the translation part of a matrix"""

    def extract(self) -> Transform3d:
        """Extract a lower-dimensional submatrix"""

    def __mul__(self, arg: Transform4d, /) -> None: ...

    @overload
    def __matmul__(self, arg: Transform4d, /) -> Transform4d: ...

    @overload
    def __matmul__(self, arg: Point3d, /) -> Point3d: ...

    @overload
    def __matmul__(self, arg: Vector3d, /) -> Vector3d: ...

    @overload
    def __matmul__(self, arg: Normal3d, /) -> Normal3d: ...

    @overload
    def __matmul__(self, arg: Ray3d, /) -> Ray3d: ...

    @overload
    def transform_affine(self, p: Point3d) -> Point3d:
        """
        Transform a 3D vector/point/normal/ray by a transformation that is
        known to be an affine 3D transformation (i.e. no perspective)
        """

    @overload
    def transform_affine(self, ray: Ray3d) -> Ray3d: ...

    @overload
    def transform_affine(self, v: Vector3d) -> Vector3d: ...

    @overload
    def transform_affine(self, n: Normal3d) -> Normal3d: ...

    def translate(self, v: Point3d) -> Transform4d:
        """Create a translation transformation"""

    def scale(self, v: Point3d) -> Transform4d:
        """Create a scale transformation"""

    def rotate(self, axis: Point3d, angle: drjit.auto.ad.Float64) -> Transform4d:
        """
        Create a rotation transformation around an arbitrary axis in 3D. The
        angle is specified in degrees
        """

    def perspective(self, fov: drjit.auto.ad.Float64, near: drjit.auto.ad.Float64, far: drjit.auto.ad.Float64) -> Transform4d:
        """
        Create a perspective transformation. (Maps [near, far] to [0, 1])

        Projects vectors in camera space onto a plane at z=1:

        x_proj = x / z y_proj = y / z z_proj = (far * (z - near)) / (z * (far-
        near))

        Camera-space depths are not mapped linearly!

        Parameter ``fov``:
            Field of view in degrees

        Parameter ``near``:
            Near clipping plane

        Parameter ``far``:
            Far clipping plane
        """

    def orthographic(self, near: drjit.auto.ad.Float64, far: drjit.auto.ad.Float64) -> Transform4d:
        """
        Create an orthographic transformation, which maps Z to [0,1] and
        leaves the X and Y coordinates untouched.

        Parameter ``near``:
            Near clipping plane

        Parameter ``far``:
            Far clipping plane
        """

    def look_at(self, origin: Point3d, target: Point3d, up: Point3d) -> Transform4d:
        """
        Create a look-at camera transformation

        Parameter ``origin``:
            Camera position

        Parameter ``target``:
            Target vector

        Parameter ``up``:
            Up vector
        """

    def from_frame(self, frame: "mitsuba::Frame<drjit::DiffArray<(JitBackend)2, double> >") -> Transform4d:
        """
        Creates a transformation that converts from 'frame' to the standard
        basis
        """

    def to_frame(self, frame: "mitsuba::Frame<drjit::DiffArray<(JitBackend)2, double> >") -> Transform4d:
        """
        Creates a transformation that converts from the standard basis to
        'frame'
        """

    def inverse(self) -> Transform4d:
        """
        Compute the inverse of this transformation (involves just shuffles, no
        arithmetic)
        """

    def has_scale(self) -> drjit.auto.ad.Bool:
        """
        Test for a scale component in each transform matrix by checking
        whether ``M . M^T == I`` (where ``M`` is the matrix in question and
        ``I`` is the identity).
        """

    @property
    def matrix(self) -> drjit.auto.ad.Matrix4f64: ...

    @matrix.setter
    def matrix(self, arg: drjit.auto.ad.Matrix4f64, /) -> None: ...

    @property
    def inverse_transpose(self) -> drjit.auto.ad.Matrix4f64: ...

    @inverse_transpose.setter
    def inverse_transpose(self, arg: drjit.auto.ad.Matrix4f64, /) -> None: ...

    def __repr__(self) -> str: ...

    def assign(self, arg: Transform4d, /) -> None: ...

    def __setitem__(self, arg0: drjit.auto.ad.Bool, arg1: Transform4d, /) -> None: ...

class Transform4f:
    """
    Encapsulates a 4x4 homogeneous coordinate transformation along with
    its inverse transpose

    The Transform class provides a set of overloaded matrix-vector
    multiplication operators for vectors, points, and normals (all of them
    behave differently under homogeneous coordinate transformations, hence
    the need to represent them using separate types)
    """

    @overload
    def __init__(self) -> None:
        """Initialize with the identity matrix"""

    @overload
    def __init__(self, arg: Transform4f) -> None:
        """Copy constructor"""

    @overload
    def __init__(self, arg: Annotated[ArrayLike, dict(dtype='float32', shape=(4, 4), order='C', device='cpu')], /) -> None: ...

    @overload
    def __init__(self, arg: list, /) -> None: ...

    @overload
    def __init__(self, arg: drjit.auto.ad.Matrix4f, /) -> None:
        """
        Initialize the transformation from the given matrix (and compute its
        inverse transpose)
        """

    @overload
    def __init__(self, arg0: drjit.auto.ad.Matrix4f, arg1: drjit.auto.ad.Matrix4f, /) -> None:
        """Initialize from a matrix and its inverse transpose"""

    @overload
    def __init__(self, arg: ScalarTransform4f, /) -> None:
        """Broadcast constructor"""

    def translation(self) -> Vector3f:
        """Get the translation part of a matrix"""

    def extract(self) -> Transform3f:
        """Extract a lower-dimensional submatrix"""

    def __mul__(self, arg: Transform4f, /) -> None: ...

    @overload
    def __matmul__(self, arg: Transform4f, /) -> Transform4f: ...

    @overload
    def __matmul__(self, arg: Point3f, /) -> Point3f: ...

    @overload
    def __matmul__(self, arg: Vector3f, /) -> Vector3f: ...

    @overload
    def __matmul__(self, arg: Normal3f, /) -> Normal3f: ...

    @overload
    def __matmul__(self, arg: Ray3f, /) -> Ray3f: ...

    @overload
    def transform_affine(self, p: Point3f) -> Point3f:
        """
        Transform a 3D vector/point/normal/ray by a transformation that is
        known to be an affine 3D transformation (i.e. no perspective)
        """

    @overload
    def transform_affine(self, ray: Ray3f) -> Ray3f: ...

    @overload
    def transform_affine(self, v: Vector3f) -> Vector3f: ...

    @overload
    def transform_affine(self, n: Normal3f) -> Normal3f: ...

    def translate(self, v: Point3f) -> Transform4f:
        """Create a translation transformation"""

    def scale(self, v: Point3f) -> Transform4f:
        """Create a scale transformation"""

    def rotate(self, axis: Point3f, angle: drjit.auto.ad.Float) -> Transform4f:
        """
        Create a rotation transformation around an arbitrary axis in 3D. The
        angle is specified in degrees
        """

    def perspective(self, fov: drjit.auto.ad.Float, near: drjit.auto.ad.Float, far: drjit.auto.ad.Float) -> Transform4f:
        """
        Create a perspective transformation. (Maps [near, far] to [0, 1])

        Projects vectors in camera space onto a plane at z=1:

        x_proj = x / z y_proj = y / z z_proj = (far * (z - near)) / (z * (far-
        near))

        Camera-space depths are not mapped linearly!

        Parameter ``fov``:
            Field of view in degrees

        Parameter ``near``:
            Near clipping plane

        Parameter ``far``:
            Far clipping plane
        """

    def orthographic(self, near: drjit.auto.ad.Float, far: drjit.auto.ad.Float) -> Transform4f:
        """
        Create an orthographic transformation, which maps Z to [0,1] and
        leaves the X and Y coordinates untouched.

        Parameter ``near``:
            Near clipping plane

        Parameter ``far``:
            Far clipping plane
        """

    def look_at(self, origin: Point3f, target: Point3f, up: Point3f) -> Transform4f:
        """
        Create a look-at camera transformation

        Parameter ``origin``:
            Camera position

        Parameter ``target``:
            Target vector

        Parameter ``up``:
            Up vector
        """

    def from_frame(self, frame: Frame3f) -> Transform4f:
        """
        Creates a transformation that converts from 'frame' to the standard
        basis
        """

    def to_frame(self, frame: Frame3f) -> Transform4f:
        """
        Creates a transformation that converts from the standard basis to
        'frame'
        """

    def inverse(self) -> Transform4f:
        """
        Compute the inverse of this transformation (involves just shuffles, no
        arithmetic)
        """

    def has_scale(self) -> drjit.auto.ad.Bool:
        """
        Test for a scale component in each transform matrix by checking
        whether ``M . M^T == I`` (where ``M`` is the matrix in question and
        ``I`` is the identity).
        """

    @property
    def matrix(self) -> drjit.auto.ad.Matrix4f: ...

    @matrix.setter
    def matrix(self, arg: drjit.auto.ad.Matrix4f, /) -> None: ...

    @property
    def inverse_transpose(self) -> drjit.auto.ad.Matrix4f: ...

    @inverse_transpose.setter
    def inverse_transpose(self, arg: drjit.auto.ad.Matrix4f, /) -> None: ...

    def __repr__(self) -> str: ...

    def assign(self, arg: Transform4f, /) -> None: ...

    def __setitem__(self, arg0: drjit.auto.ad.Bool, arg1: Transform4f, /) -> None: ...

class TransportMode(enum.Enum):
    """
    Specifies the transport mode when sampling or evaluating a scattering
    function
    """

    Radiance = 0
    """Radiance transport"""

    Importance = 1
    """Importance transport"""

class TraversalCallback:
    """
    Abstract class providing an interface for traversing scene graphs

    This interface can be implemented either in C++ or in Python, to be
    used in conjunction with Object::traverse() to traverse a scene graph.
    Mitsuba currently uses this mechanism to determine a scene's
    differentiable parameters.
    """

    def __init__(self) -> None: ...

    def put_parameter(self, name: str, value: object, flags: int) -> None:
        """Inform the traversal callback about an attribute of an instance"""

    def put_object(self, name: str, obj: Object, flags: int) -> None:
        """
        Inform the traversal callback that the instance references another
        Mitsuba object
        """

class Vector0d(drjit.ArrayBase[Vector0d, _Vector0dCp, drjit.auto.ad.Float64, drjit.auto.ad._Float64Cp, drjit.auto.ad.Float64, Vector0d, drjit.auto.ad.Array0b]):
    pass

class Vector0f(drjit.ArrayBase[Vector0f, _Vector0fCp, drjit.auto.ad.Float, drjit.auto.ad._FloatCp, drjit.auto.ad.Float, Vector0f, drjit.auto.ad.Array0b]):
    pass

class Vector0i(drjit.ArrayBase[Vector0i, _Vector0iCp, drjit.auto.ad.Int, drjit.auto.ad._IntCp, drjit.auto.ad.Int, Vector0i, drjit.auto.ad.Array0b]):
    pass

class Vector0u(drjit.ArrayBase[Vector0u, _Vector0uCp, drjit.auto.ad.UInt, drjit.auto.ad._UIntCp, drjit.auto.ad.UInt, Vector0u, drjit.auto.ad.Array0b]):
    pass

class Vector1d(drjit.ArrayBase[Vector1d, _Vector1dCp, drjit.auto.ad.Float64, drjit.auto.ad._Float64Cp, drjit.auto.ad.Float64, Vector1d, drjit.auto.ad.Array1b]):
    pass

class Vector1f(drjit.ArrayBase[Vector1f, _Vector1fCp, drjit.auto.ad.Float, drjit.auto.ad._FloatCp, drjit.auto.ad.Float, Vector1f, drjit.auto.ad.Array1b]):
    pass

class Vector1i(drjit.ArrayBase[Vector1i, _Vector1iCp, drjit.auto.ad.Int, drjit.auto.ad._IntCp, drjit.auto.ad.Int, Vector1i, drjit.auto.ad.Array1b]):
    pass

class Vector1u(drjit.ArrayBase[Vector1u, _Vector1uCp, drjit.auto.ad.UInt, drjit.auto.ad._UIntCp, drjit.auto.ad.UInt, Vector1u, drjit.auto.ad.Array1b]):
    pass

class Vector2d(drjit.ArrayBase[Vector2d, _Vector2dCp, drjit.auto.ad.Float64, drjit.auto.ad._Float64Cp, drjit.auto.ad.Float64, Vector2d, drjit.auto.ad.Array2b]):
    pass

class Vector2f(drjit.ArrayBase[Vector2f, _Vector2fCp, drjit.auto.ad.Float, drjit.auto.ad._FloatCp, drjit.auto.ad.Float, Vector2f, drjit.auto.ad.Array2b]):
    pass

class Vector2i(drjit.ArrayBase[Vector2i, _Vector2iCp, drjit.auto.ad.Int, drjit.auto.ad._IntCp, drjit.auto.ad.Int, Vector2i, drjit.auto.ad.Array2b]):
    pass

class Vector2u(drjit.ArrayBase[Vector2u, _Vector2uCp, drjit.auto.ad.UInt, drjit.auto.ad._UIntCp, drjit.auto.ad.UInt, Vector2u, drjit.auto.ad.Array2b]):
    pass

class Vector3d(drjit.ArrayBase[Vector3d, _Vector3dCp, drjit.auto.ad.Float64, drjit.auto.ad._Float64Cp, drjit.auto.ad.Float64, Vector3d, drjit.auto.ad.Array3b]):
    pass

class Vector3f(drjit.ArrayBase[Vector3f, _Vector3fCp, drjit.auto.ad.Float, drjit.auto.ad._FloatCp, drjit.auto.ad.Float, Vector3f, drjit.auto.ad.Array3b]):
    pass

class Vector3i(drjit.ArrayBase[Vector3i, _Vector3iCp, drjit.auto.ad.Int, drjit.auto.ad._IntCp, drjit.auto.ad.Int, Vector3i, drjit.auto.ad.Array3b]):
    pass

class Vector3u(drjit.ArrayBase[Vector3u, _Vector3uCp, drjit.auto.ad.UInt, drjit.auto.ad._UIntCp, drjit.auto.ad.UInt, Vector3u, drjit.auto.ad.Array3b]):
    pass

class Vector4d(drjit.ArrayBase[Vector4d, _Vector4dCp, drjit.auto.ad.Float64, drjit.auto.ad._Float64Cp, drjit.auto.ad.Float64, Vector4d, drjit.auto.ad.Array4b]):
    pass

class Vector4f(drjit.ArrayBase[Vector4f, _Vector4fCp, drjit.auto.ad.Float, drjit.auto.ad._FloatCp, drjit.auto.ad.Float, Vector4f, drjit.auto.ad.Array4b]):
    pass

class Vector4i(drjit.ArrayBase[Vector4i, _Vector4iCp, drjit.auto.ad.Int, drjit.auto.ad._IntCp, drjit.auto.ad.Int, Vector4i, drjit.auto.ad.Array4b]):
    pass

class Vector4u(drjit.ArrayBase[Vector4u, _Vector4uCp, drjit.auto.ad.UInt, drjit.auto.ad._UIntCp, drjit.auto.ad.UInt, Vector4u, drjit.auto.ad.Array4b]):
    pass

class Volume(Object):
    """Abstract base class for 3D volumes."""

    def __init__(self, props: Properties) -> None: ...

    def resolution(self) -> ScalarVector3i:
        """
        Returns the resolution of the volume, assuming that it is based on a
        discrete representation.

        The default implementation returns ``(1, 1, 1)``
        """

    def bbox(self) -> ScalarBoundingBox3f:
        """Returns the bounding box of the volume"""

    def channel_count(self) -> int:
        """
        Returns the number of channels stored in the volume

        When the channel count is zero, it indicates that the volume does not
        support per-channel queries.
        """

    def max(self) -> float:
        """Returns the maximum value of the volume over all dimensions."""

    def max_per_channel(self) -> list[float]:
        """
        In the case of a multi-channel volume, this function returns the
        maximum value for each channel.

        Pointer allocation/deallocation must be performed by the caller.
        """

    def eval(self, it: Interaction3f, active: bool = True) -> ScalarColor3f:
        """
        Evaluate the volume at the given surface interaction, with color
        processing.
        """

    def eval_1(self, it: Interaction3f, active: bool = True) -> float:
        """Evaluate this volume as a single-channel quantity."""

    def eval_3(self, it: Interaction3f, active: bool = True) -> ScalarVector3f:
        """
        Evaluate this volume as a three-channel quantity with no color
        processing (e.g. velocity field).
        """

    def eval_6(self, it: Interaction3f, active: bool = True) -> list[float]:
        """
        Evaluate this volume as a six-channel quantity with no color
        processing This interface is specifically intended to encode the
        parameters of an SGGX phase function.
        """

    def eval_gradient(self, it: Interaction3f, active: bool = True) -> tuple[ScalarColor3f, ScalarVector3f]:
        """
        Evaluate the volume at the given surface interaction, and compute the
        gradients of the linear interpolant as well.
        """

    def eval_n(self, it: Interaction3f, active: bool = True) -> list[float]:
        """
        Evaluate this volume as a n-channel float quantity

        This interface is specifically intended to encode a variable number of
        parameters. Pointer allocation/deallocation must be performed by the
        caller.
        """

class VolumeGrid(Object):
    @overload
    def __init__(self, path: str) -> None: ...

    @overload
    def __init__(self, stream: Stream) -> None: ...

    @overload
    def __init__(self, array: Annotated[ArrayLike, dict(dtype='float32', order='C', device='cpu')], compute_max: bool = True) -> None:
        """Initialize a VolumeGrid from a CPU-visible ndarray"""

    @overload
    def __init__(self, array: drjit.scalar.TensorXf, compute_max: bool = True) -> None:
        """Initialize a VolumeGrid from a drjit tensor"""

    def size(self) -> ScalarVector3u:
        """Return the resolution of the voxel grid"""

    def channel_count(self) -> int:
        """Return the number of channels"""

    def max(self) -> float:
        """Return the precomputed maximum over the volume grid"""

    def max_per_channel(self) -> list[float]:
        """
        Return the precomputed maximum over the volume grid per channel

        Pointer allocation/deallocation must be performed by the caller.
        """

    def set_max(self, arg: float, /) -> None:
        """Set the precomputed maximum over the volume grid"""

    def set_max_per_channel(self, arg: Sequence[float], /) -> None:
        """
        Set the precomputed maximum over the volume grid per channel

        Pointer allocation/deallocation must be performed by the caller.
        """

    def bytes_per_voxel(self) -> int:
        """Return the number bytes of storage used per voxel"""

    def buffer_size(self) -> int:
        """Return the volume grid size in bytes (excluding metadata)"""

    @overload
    def write(self, stream: Stream) -> None:
        """
        Write an encoded form of the bitmap to a binary volume file

        Parameter ``path``:
            Target file name (expected to end in ".vol")
        """

    @overload
    def write(self, path: str) -> None:
        """
        Write an encoded form of the volume grid to a stream

        Parameter ``stream``:
            Target stream that will receive the encoded output
        """

    @property
    def __array_interface__(self) -> object: ...

class ZStream(Stream):
    """
    Transparent compression/decompression stream based on ``zlib``.

    This class transparently decompresses and compresses reads and writes
    to a nested stream, respectively.
    """

    def __init__(self, child_stream: Stream, stream_type: ZStream.EStreamType = ZStream.EStreamType.EDeflateStream, level: int = -1) -> None:
        """
        Creates a new compression stream with the given underlying stream.
        This new instance takes ownership of the child stream. The child
        stream must outlive the ZStream.
        """

    class EStreamType(enum.Enum):
        EDeflateStream = 0

        EGZipStream = 1
        """A raw deflate stream"""

    EDeflateStream: ZStream.EStreamType = ZStream.EStreamType.EDeflateStream

    EGZipStream: ZStream.EStreamType = ZStream.EStreamType.EGZipStream

    def child_stream(self) -> object:
        """Returns the child stream of this compression stream"""

_BSDFPtrCp: TypeAlias = Union['BSDFPtr', BSDF, int, 'drjit.auto._UIntCp', 'drjit.auto.ad._IntCp']

_EmitterPtrCp: TypeAlias = Union['EmitterPtr', Emitter, int, 'drjit.auto._UIntCp', 'drjit.auto.ad._IntCp']

_MediumPtrCp: TypeAlias = Union['MediumPtr', Medium, int, 'drjit.auto._UIntCp', 'drjit.auto.ad._IntCp']

_MeshPtrCp: TypeAlias = Union['MeshPtr', Mesh, int, 'drjit.auto._UIntCp', 'drjit.auto.ad._IntCp']

_ObjectPtrCp: TypeAlias = Union['ObjectPtr', Object, int, 'drjit.auto._UIntCp', 'drjit.auto.ad._IntCp']

_PhaseFunctionPtrCp: TypeAlias = Union['PhaseFunctionPtr', PhaseFunction, int, 'drjit.auto._UIntCp', 'drjit.auto.ad._IntCp']

_SensorPtrCp: TypeAlias = Union['SensorPtr', Sensor, int, 'drjit.auto._UIntCp', 'drjit.auto.ad._IntCp']

_ShapePtrCp: TypeAlias = Union['ShapePtr', Shape, int, 'drjit.auto._UIntCp', 'drjit.auto.ad._IntCp']

def __getattr__(arg: object, /) -> object: ...

def cie1931_xyz(wavelength: drjit.auto.ad.Float) -> Color3f:
    """
    Evaluate the CIE 1931 XYZ color matching functions given a wavelength
    in nanometers
    """

def cie1931_y(wavelength: drjit.auto.ad.Float) -> drjit.auto.ad.Float:
    """
    Evaluate the CIE 1931 Y color matching function given a wavelength in
    nanometers
    """

def cie_d65(wavelength: drjit.auto.ad.Float) -> drjit.auto.ad.Float:
    """
    Evaluate the CIE D65 illuminant spectrum given a wavelength in
    nanometers, normalized to ensures that it integrates to a luminance of
    1.0.
    """

def coordinate_system(n: Vector3f) -> tuple[Vector3f, Vector3f]:
    """Complete the set {a} to an orthonormal basis {a, b, c}"""

def depolarizer(arg: Spectrum, /) -> Spectrum: ...

def eval_reflectance(type: MicrofacetType, alpha_u: float, alpha_v: float, wi: Vector3f, eta: float) -> drjit.auto.ad.Float: ...

def fresnel(cos_theta_i: drjit.auto.ad.Float, eta: drjit.auto.ad.Float) -> tuple[drjit.auto.ad.Float, drjit.auto.ad.Float, drjit.auto.ad.Float, drjit.auto.ad.Float]:
    """
    Calculates the unpolarized Fresnel reflection coefficient at a planar
    interface between two dielectrics

    Parameter ``cos_theta_i``:
        Cosine of the angle between the surface normal and the incident
        ray

    Parameter ``eta``:
        Relative refractive index of the interface. A value greater than
        1.0 means that the surface normal is pointing into the region of
        lower density.

    Returns:
        A tuple (F, cos_theta_t, eta_it, eta_ti) consisting of

    F Fresnel reflection coefficient.

    cos_theta_t Cosine of the angle between the surface normal and the
    transmitted ray

    eta_it Relative index of refraction in the direction of travel.

    eta_ti Reciprocal of the relative index of refraction in the direction
    of travel. This also happens to be equal to the scale factor that must
    be applied to the X and Y component of the refracted direction.
    """

def fresnel_conductor(cos_theta_i: drjit.auto.ad.Float, eta: drjit.auto.ad.Complex2f) -> drjit.auto.ad.Float:
    """
    Calculates the unpolarized Fresnel reflection coefficient at a planar
    interface of a conductor, i.e. a surface with a complex-valued
    relative index of refraction

    Remark:
        The implementation assumes that cos_theta_i > 0, i.e. light enters
        from *outside* of the conducting layer (generally a reasonable
        assumption unless very thin layers are being simulated)

    Parameter ``cos_theta_i``:
        Cosine of the angle between the surface normal and the incident
        ray

    Parameter ``eta``:
        Relative refractive index (complex-valued)

    Returns:
        The unpolarized Fresnel reflection coefficient.
    """

def fresnel_diffuse_reflectance(eta: drjit.auto.ad.Float) -> drjit.auto.ad.Float:
    """
    Computes the diffuse unpolarized Fresnel reflectance of a dielectric
    material (sometimes referred to as "Fdr").

    This value quantifies what fraction of diffuse incident illumination
    will, on average, be reflected at a dielectric material boundary

    Parameter ``eta``:
        Relative refraction coefficient

    Returns:
        F, the unpolarized Fresnel coefficient.
    """

def fresnel_polarized(cos_theta_i: drjit.auto.ad.Float, eta: drjit.auto.ad.Complex2f) -> tuple[drjit.auto.ad.Complex2f, drjit.auto.ad.Complex2f, drjit.auto.ad.Float, drjit.auto.ad.Complex2f, drjit.auto.ad.Complex2f]:
    """
    Calculates the polarized Fresnel reflection coefficient at a planar
    interface between two dielectrics or conductors. Returns complex
    values encoding the amplitude and phase shift of the s- and
    p-polarized waves.

    This is the most general version, which subsumes all others (at the
    cost of transcendental function evaluations in the complex-valued
    arithmetic)

    Parameter ``cos_theta_i``:
        Cosine of the angle between the surface normal and the incident
        ray

    Parameter ``eta``:
        Complex-valued relative refractive index of the interface. In the
        real case, a value greater than 1.0 case means that the surface
        normal points into the region of lower density.

    Returns:
        A tuple (a_s, a_p, cos_theta_t, eta_it, eta_ti) consisting of

    a_s Perpendicularly polarized wave amplitude and phase shift.

    a_p Parallel polarized wave amplitude and phase shift.

    cos_theta_t Cosine of the angle between the surface normal and the
    transmitted ray. Zero in the case of total internal reflection.

    eta_it Relative index of refraction in the direction of travel

    eta_ti Reciprocal of the relative index of refraction in the direction
    of travel. In the real-valued case, this also happens to be equal to
    the scale factor that must be applied to the X and Y component of the
    refracted direction.
    """

def get_property(ptr: object, type: object, parent: object) -> object: ...

@overload
def has_flag(arg0: int, arg1: EmitterFlags, /) -> bool: ...

@overload
def has_flag(arg0: drjit.auto.ad.UInt, arg1: EmitterFlags, /) -> drjit.auto.ad.Bool: ...

@overload
def has_flag(arg0: int, arg1: RayFlags, /) -> bool: ...

@overload
def has_flag(arg0: drjit.auto.ad.UInt, arg1: RayFlags, /) -> drjit.auto.ad.Bool: ...

@overload
def has_flag(arg0: int, arg1: DiscontinuityFlags, /) -> bool: ...

@overload
def has_flag(arg0: drjit.auto.ad.UInt, arg1: DiscontinuityFlags, /) -> drjit.auto.ad.Bool: ...

@overload
def has_flag(arg0: int, arg1: BSDFFlags, /) -> bool: ...

@overload
def has_flag(arg0: drjit.auto.ad.UInt, arg1: BSDFFlags, /) -> drjit.auto.ad.Bool: ...

@overload
def has_flag(arg0: int, arg1: FilmFlags, /) -> bool: ...

@overload
def has_flag(arg0: drjit.auto.ad.UInt, arg1: FilmFlags, /) -> drjit.auto.ad.Bool: ...

@overload
def has_flag(arg0: int, arg1: PhaseFunctionFlags, /) -> bool: ...

@overload
def has_flag(arg0: drjit.auto.ad.UInt, arg1: PhaseFunctionFlags, /) -> drjit.auto.ad.Bool: ...

def linear_rgb_rec(wavelength: drjit.auto.ad.Float) -> Color3f:
    """
    Evaluate the ITU-R Rec. BT.709 linear RGB color matching functions
    given a wavelength in nanometers
    """

def load_dict(dict: dict, parallel: bool = True) -> object:
    """
    Load a Mitsuba scene or object from an Python dictionary

    Parameter ``dict``:
        Python dictionary containing the object description

    Parameter ``parallel``:
        Whether the loading should be executed on multiple threads in parallel
    """

def load_file(path: str, update_scene: bool = False, parallel: bool = True, **kwargs) -> object:
    """
    Load a Mitsuba scene from an XML file

    Parameter ``path``:
        Filename of the scene XML file

    Parameter ``parameters``:
        Optional list of parameters that can be referenced as ``$varname``
        in the scene.

    Parameter ``variant``:
        Specifies the variant of plugins to instantiate (e.g.
        "scalar_rgb")

    Parameter ``update_scene``:
        When Mitsuba updates scene to a newer version, should the updated
        XML file be written back to disk?

    Parameter ``parallel``:
        Whether the loading should be executed on multiple threads in
        parallel
    """

def load_string(string: str, parallel: bool = True, **kwargs) -> object:
    """Load a Mitsuba scene from an XML string"""

def lookup_ior(properties: Properties, name: str, default: object) -> float:
    """Lookup IOR value in table."""

@overload
def luminance(value: UnpolarizedSpectrum, wavelengths: UnpolarizedSpectrum, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.Float: ...

@overload
def luminance(c: Color3f) -> drjit.auto.ad.Float: ...

def orthographic_projection(film_size: ScalarVector2i, crop_size: ScalarVector2i, crop_offset: ScalarVector2i, near_clip: drjit.auto.ad.Float, far_clip: drjit.auto.ad.Float) -> Transform4f:
    """
    Helper function to create a orthographic projection transformation
    matrix
    """

@overload
def pdf_rgb_spectrum(wavelengths: drjit.auto.ad.Float) -> drjit.auto.ad.Float:
    """
    PDF for the sample_rgb_spectrum strategy. It is valid to call this
    function for a single wavelength (Float), a set of wavelengths
    (Spectrumf), a packet of wavelengths (SpectrumfP), etc. In all cases,
    the PDF is returned per wavelength.
    """

@overload
def pdf_rgb_spectrum(wavelengths: Spectrum) -> Spectrum: ...

def permute(value: drjit.auto.ad.UInt, size: int, seed: drjit.auto.ad.UInt, rounds: int = 4) -> drjit.auto.ad.UInt:
    """
    Generate pseudorandom permutation vector using a shuffling network

    This algorithm repeatedly invokes sample_tea_32() internally and has
    O(log2(sample_count)) complexity. It only supports permutation
    vectors, whose lengths are a power of 2.

    Parameter ``index``:
        Input index to be permuted

    Parameter ``size``:
        Length of the permutation vector

    Parameter ``seed``:
        Seed value used as second input to the Tiny Encryption Algorithm.
        Can be used to generate different permutation vectors.

    Parameter ``rounds``:
        How many rounds should be executed by the Tiny Encryption
        Algorithm? The default is 2.

    Returns:
        The index corresponding to the input index in the pseudorandom
        permutation vector.
    """

def permute_kensler(i: drjit.auto.ad.UInt, l: int, p: drjit.auto.ad.UInt, active: drjit.auto.ad.Bool = True) -> drjit.auto.ad.UInt:
    """
    Generate pseudorandom permutation vector using the algorithm described
    in Pixar's technical memo "Correlated Multi-Jittered Sampling":

    https://graphics.pixar.com/library/MultiJitteredSampling/

    Unlike permute, this function supports permutation vectors of any
    length.

    Parameter ``index``:
        Input index to be mapped

    Parameter ``sample_count``:
        Length of the permutation vector

    Parameter ``seed``:
        Seed value used as second input to the Tiny Encryption Algorithm.
        Can be used to generate different permutation vectors.

    Returns:
        The index corresponding to the input index in the pseudorandom
        permutation vector.
    """

def perspective_projection(film_size: ScalarVector2i, crop_size: ScalarVector2i, crop_offset: ScalarVector2i, fov_x: drjit.auto.ad.Float, near_clip: drjit.auto.ad.Float, far_clip: drjit.auto.ad.Float) -> Transform4f:
    """
    Helper function to create a perspective projection transformation
    matrix
    """

@overload
def reflect(wi: Vector3f) -> Vector3f:
    """Reflection in local coordinates"""

@overload
def reflect(wi: Vector3f, m: Normal3f) -> Vector3f:
    """Reflect ``wi`` with respect to a given surface normal"""

@overload
def refract(wi: Vector3f, cos_theta_t: drjit.auto.ad.Float, eta_ti: drjit.auto.ad.Float) -> Vector3f:
    """
    Refraction in local coordinates

    The 'cos_theta_t' and 'eta_ti' parameters are given by the last two
    tuple entries returned by the fresnel and fresnel_polarized functions.
    """

@overload
def refract(wi: Vector3f, m: Normal3f, cos_theta_t: drjit.auto.ad.Float, eta_ti: drjit.auto.ad.Float) -> Vector3f:
    """
    Refract ``wi`` with respect to a given surface normal

    Parameter ``wi``:
        Direction to refract

    Parameter ``m``:
        Surface normal

    Parameter ``cos_theta_t``:
        Cosine of the angle between the normal the transmitted ray, as
        computed e.g. by fresnel.

    Parameter ``eta_ti``:
        Relative index of refraction (transmitted / incident)
    """

def register_bsdf(arg0: str, arg1: Callable[[Properties], object], /) -> None: ...

def register_emitter(arg0: str, arg1: Callable[[Properties], object], /) -> None: ...

def register_film(arg0: str, arg1: Callable[[Properties], object], /) -> None: ...

def register_integrator(arg0: str, arg1: Callable[[Properties], object], /) -> None: ...

def register_medium(arg0: str, arg1: Callable[[Properties], object], /) -> None: ...

def register_mesh(arg0: str, arg1: Callable[[Properties], object], /) -> None: ...

def register_phasefunction(arg0: str, arg1: Callable[[Properties], object], /) -> None: ...

def register_sampler(arg0: str, arg1: Callable[[Properties], object], /) -> None: ...

def register_sensor(arg0: str, arg1: Callable[[Properties], object], /) -> None: ...

def register_texture(arg0: str, arg1: Callable[[Properties], object], /) -> None: ...

def register_volume(arg0: str, arg1: Callable[[Properties], object], /) -> None: ...

@overload
def sample_rgb_spectrum(sample: drjit.auto.ad.Float) -> tuple[drjit.auto.ad.Float, drjit.auto.ad.Float]:
    """
    Importance sample a "importance spectrum" that concentrates the
    computation on wavelengths that are relevant for rendering of RGB data

    Based on "An Improved Technique for Full Spectral Rendering" by
    Radziszewski, Boryczko, and Alda

    Returns a tuple with the sampled wavelength and inverse PDF
    """

@overload
def sample_rgb_spectrum(sample: Spectrum) -> tuple[Spectrum, Spectrum]: ...

def sample_shifted(sample: drjit.auto.ad.Float) -> drjit.auto.ad.Array4f: ...

@overload
def sample_tea_32(v0: int, v1: int, rounds: int = 4) -> tuple[int, int]:
    """
    Generate fast and reasonably good pseudorandom numbers using the Tiny
    Encryption Algorithm (TEA) by David Wheeler and Roger Needham.

    For details, refer to "GPU Random Numbers via the Tiny Encryption
    Algorithm" by Fahad Zafar, Marc Olano, and Aaron Curtis.

    Parameter ``v0``:
        First input value to be encrypted (could be the sample index)

    Parameter ``v1``:
        Second input value to be encrypted (e.g. the requested random
        number dimension)

    Parameter ``rounds``:
        How many rounds should be executed? The default for random number
        generation is 4.

    Returns:
        Two uniformly distributed 32-bit integers
    """

@overload
def sample_tea_32(v0: drjit.auto.ad.UInt, v1: drjit.auto.ad.UInt, rounds: int = 4) -> tuple[drjit.auto.ad.UInt, drjit.auto.ad.UInt]: ...

@overload
def sample_tea_64(v0: int, v1: int, rounds: int = 4) -> int:
    """
    Generate fast and reasonably good pseudorandom numbers using the Tiny
    Encryption Algorithm (TEA) by David Wheeler and Roger Needham.

    For details, refer to "GPU Random Numbers via the Tiny Encryption
    Algorithm" by Fahad Zafar, Marc Olano, and Aaron Curtis.

    Parameter ``v0``:
        First input value to be encrypted (could be the sample index)

    Parameter ``v1``:
        Second input value to be encrypted (e.g. the requested random
        number dimension)

    Parameter ``rounds``:
        How many rounds should be executed? The default for random number
        generation is 4.

    Returns:
        A uniformly distributed 64-bit integer
    """

@overload
def sample_tea_64(v0: drjit.auto.ad.UInt, v1: drjit.auto.ad.UInt, rounds: int = 4) -> drjit.auto.ad.UInt64: ...

sample_tea_float = sample_tea_float32

@overload
def sample_tea_float32(v0: int, v1: int, rounds: int = 4) -> float:
    """
    Generate fast and reasonably good pseudorandom numbers using the Tiny
    Encryption Algorithm (TEA) by David Wheeler and Roger Needham.

    This function uses sample_tea to return single precision floating
    point numbers on the interval ``[0, 1)``

    Parameter ``v0``:
        First input value to be encrypted (could be the sample index)

    Parameter ``v1``:
        Second input value to be encrypted (e.g. the requested random
        number dimension)

    Parameter ``rounds``:
        How many rounds should be executed? The default for random number
        generation is 4.

    Returns:
        A uniformly distributed floating point number on the interval
        ``[0, 1)``
    """

@overload
def sample_tea_float32(v0: drjit.auto.ad.UInt, v1: drjit.auto.ad.UInt, rounds: int = 4) -> drjit.auto.ad.Float: ...

@overload
def sample_tea_float64(v0: int, v1: int, rounds: int = 4) -> float:
    """
    Generate fast and reasonably good pseudorandom numbers using the Tiny
    Encryption Algorithm (TEA) by David Wheeler and Roger Needham.

    This function uses sample_tea to return double precision floating
    point numbers on the interval ``[0, 1)``

    Parameter ``v0``:
        First input value to be encrypted (could be the sample index)

    Parameter ``v1``:
        Second input value to be encrypted (e.g. the requested random
        number dimension)

    Parameter ``rounds``:
        How many rounds should be executed? The default for random number
        generation is 4.

    Returns:
        A uniformly distributed floating point number on the interval
        ``[0, 1)``
    """

@overload
def sample_tea_float64(v0: drjit.auto.ad.UInt, v1: drjit.auto.ad.UInt, rounds: int = 4) -> drjit.auto.ad.Float64: ...

@overload
def set_property(ptr: object, type: object, value: object) -> None: ...

@overload
def set_property(dst: object, src: object) -> None: ...

def set_variant(*args) -> None: ...

def sggx_pdf(wm: Vector3f, s: SGGXPhaseFunctionParams) -> drjit.auto.ad.Float:
    """
    Evaluates the probability of sampling a given normal using the SGGX
    microflake distribution

    Parameter ``wm``:
        The microflake normal

    Parameter ``s``:
        The parameters of the SGGX phase function S_xx, S_yy, S_zz, S_xy,
        S_xz, and S_yz that describe the entries of a symmetric positive
        definite 3x3 matrix. The user needs to ensure that the parameters
        indeed represent a positive definite matrix.

    Returns:
        The probability of sampling a certain normal
    """

def sggx_projected_area(wi: Vector3f, s: SGGXPhaseFunctionParams) -> drjit.auto.ad.Float:
    """
    Evaluates the projected area of the SGGX microflake distribution

    Parameter ``wi``:
        A 3D direction

    Parameter ``s``:
        The parameters of the SGGX phase function S_xx, S_yy, S_zz, S_xy,
        S_xz, and S_yz that describe the entries of a symmetric positive
        definite 3x3 matrix. The user needs to ensure that the parameters
        indeed represent a positive definite matrix.

    Returns:
        The projected area of the SGGX microflake distribution
    """

@overload
def sggx_sample(sh_frame: Frame3f, sample: Point2f, s: SGGXPhaseFunctionParams) -> Normal3f:
    """
    Samples the visible normal distribution of the SGGX microflake
    distribution

    This function is based on the paper

    "The SGGX microflake distribution", Siggraph 2015 by Eric Heitz,
    Jonathan Dupuy, Cyril Crassin and Carsten Dachsbacher

    Parameter ``sh_frame``:
        Shading frame aligned with the incident direction, e.g.
        constructed as Frame3f(wi)

    Parameter ``sample``:
        A uniformly distributed 2D sample

    Parameter ``s``:
        The parameters of the SGGX phase function S_xx, S_yy, S_zz, S_xy,
        S_xz, and S_yz that describe the entries of a symmetric positive
        definite 3x3 matrix. The user needs to ensure that the parameters
        indeed represent a positive definite matrix.

    Returns:
        A normal (in world space) sampled from the distribution of visible
        normals
    """

@overload
def sggx_sample(sh_frame: Vector3f, sample: Point2f, s: SGGXPhaseFunctionParams) -> Normal3f: ...

def spectrum_from_file(filename: str) -> tuple[list[float], list[float]]:
    """
    Read a spectral power distribution from an ASCII file.

    The data should be arranged as follows: The file should contain a
    single measurement per line, with the corresponding wavelength in
    nanometers and the measured value separated by a space. Comments are
    allowed.

    Parameter ``path``:
        Path of the file to be read

    Parameter ``wavelengths``:
        Array that will be loaded with the wavelengths stored in the file

    Parameter ``values``:
        Array that will be loaded with the values stored in the file
    """

def spectrum_list_to_srgb(wavelengths: Sequence[float], values: Sequence[float], bounded: bool = True, d65: bool = False) -> ScalarColor3f: ...

def spectrum_to_file(filename: str, wavelengths: Sequence[float], values: Sequence[float]) -> None:
    """
    Write a spectral power distribution to an ASCII file.

    The format is identical to that parsed by spectrum_from_file().

    Parameter ``path``:
        Path to the file to be written to

    Parameter ``wavelengths``:
        Array with the wavelengths to be stored in the file

    Parameter ``values``:
        Array with the values to be stored in the file
    """

def spectrum_to_srgb(value: UnpolarizedSpectrum, wavelengths: UnpolarizedSpectrum, active: drjit.auto.ad.Bool = True) -> Color3f:
    """
    Spectral responses to sRGB normalized according to the CIE curves to
    ensure that a unit-valued spectrum integrates to a luminance of 1.0.
    """

def spectrum_to_xyz(value: UnpolarizedSpectrum, wavelengths: UnpolarizedSpectrum, active: drjit.auto.ad.Bool = True) -> Color3f:
    """
    Spectral responses to XYZ normalized according to the CIE curves to
    ensure that a unit-valued spectrum integrates to a luminance of 1.0.
    """

def srgb_model_eval(arg0: drjit.auto.ad.Array3f, arg1: UnpolarizedSpectrum, /) -> UnpolarizedSpectrum: ...

def srgb_model_fetch(arg: ScalarColor3f, /) -> drjit.scalar.Array3f:
    """
    Look up the model coefficients for a sRGB color value

    Parameter ``c``:
        An sRGB color value where all components are in [0, 1].

    Returns:
        Coefficients for use with srgb_model_eval
    """

def srgb_model_mean(arg: drjit.auto.ad.Array3f, /) -> drjit.auto.ad.Float: ...

def srgb_to_xyz(rgb: Color3f, active: drjit.auto.ad.Bool = True) -> Color3f:
    """Convert ITU-R Rec. BT.709 linear RGB to XYZ tristimulus values"""

def unpolarized_spectrum(arg: Spectrum, /) -> UnpolarizedSpectrum: ...

def variant() -> object: ...

def variants() -> object: ...

def xml_to_props(path: str) -> list[tuple[str, Properties]]:
    """
    Get the names and properties of the objects described in a Mitsuba XML file
    """

def xyz_to_srgb(rgb: Color3f, active: drjit.auto.ad.Bool = True) -> Color3f:
    """Convert XYZ tristimulus values to ITU-R Rec. BT.709 linear RGB"""
